% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learner_survivalmodels_surv_dnnsurv.R
\name{mlr_learners_surv.dnnsurv}
\alias{mlr_learners_surv.dnnsurv}
\alias{LearnerSurvDNNSurv}
\title{Survival DNNSurv Learner}
\description{
Fits a neural network based on pseudo-conditional survival probabilities.
Calls \code{\link[survivalmodels:dnnsurv]{survivalmodels::dnnsurv()}} from package 'survivalmodels'.
}
\details{
Custom nets can be used in this learner either using the
\link[survivalmodels:build_keras_net]{survivalmodels::build_keras_net} utility function or using \CRANpkg{keras}.
The number of output channels should be of length \code{1} and number of input channels is
the number of features plus number of cuts.
}
\section{Dictionary}{

This \link[mlr3:Learner]{Learner} can be instantiated via \link[mlr3:mlr_sugar]{lrn()}:

\if{html}{\out{<div class="sourceCode">}}\preformatted{lrn("surv.dnnsurv")
}\if{html}{\out{</div>}}
}

\section{Meta Information}{

\itemize{
\item Task type: \dQuote{surv}
\item Predict Types: \dQuote{crank}, \dQuote{distr}
\item Feature Types: \dQuote{integer}, \dQuote{numeric}
\item Required Packages: \CRANpkg{mlr3}, \CRANpkg{mlr3proba}, \CRANpkg{mlr3extralearners}, \CRANpkg{survivalmodels}, \CRANpkg{keras}, \CRANpkg{pseudo}, \CRANpkg{tensorflow}, \CRANpkg{distr6}
}
}

\section{Parameters}{
\tabular{lllll}{
   Id \tab Type \tab Default \tab Levels \tab Range \cr
   cuts \tab integer \tab 5 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   cutpoints \tab untyped \tab - \tab  \tab - \cr
   custom_model \tab untyped \tab - \tab  \tab - \cr
   optimizer \tab character \tab adam \tab adadelta, adagrad, adamax, adam, nadam, rmsprop, sgd \tab - \cr
   lr \tab numeric \tab 0.02 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   beta_1 \tab numeric \tab 0.9 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   beta_2 \tab numeric \tab 0.999 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   epsilon \tab numeric \tab - \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   decay \tab numeric \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   clipnorm \tab numeric \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   clipvalue \tab numeric \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   momentum \tab numeric \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   nesterov \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   loss_weights \tab untyped \tab - \tab  \tab - \cr
   weighted_metrics \tab untyped \tab - \tab  \tab - \cr
   early_stopping \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   min_delta \tab numeric \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   patience \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   verbose \tab integer \tab 0 \tab  \tab \eqn{[0, 2]}{[0, 2]} \cr
   baseline \tab numeric \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   restore_best_weights \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   batch_size \tab integer \tab 32 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   epochs \tab integer \tab 10 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   validation_split \tab numeric \tab 0 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   shuffle \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   sample_weight \tab untyped \tab - \tab  \tab - \cr
   initial_epoch \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   steps_per_epoch \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   validation_steps \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   steps \tab integer \tab - \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   callbacks \tab untyped \tab - \tab  \tab - \cr
   rho \tab numeric \tab 0.95 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   global_clipnorm \tab numeric \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   use_ema \tab logical \tab - \tab TRUE, FALSE \tab - \cr
   ema_momentum \tab numeric \tab 0.99 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   ema_overwrite_frequency \tab numeric \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   jit_compile \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   initial_accumultator_value \tab numeric \tab 0.1 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   amsgrad \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   lr_power \tab numeric \tab -0.5 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   l1_regularization_strength \tab numeric \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   l2_regularization_strength \tab numeric \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   l2_shrinkage_regularization_strength \tab numeric \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   beta \tab numeric \tab 0 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   centered \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
}
}

\section{Installation}{

Package 'survivalmodels' is not on CRAN and has to be install from GitHub via
\code{remotes::install_github("RaphaelS1/survivalmodels")}.
}

\section{Initial parameter values}{

\itemize{
\item \code{verbose} is initialized to 0.
}
}

\examples{
lrn("surv.dnnsurv")
}
\references{
Zhao, Lili, Feng, Dai (2019).
\dQuote{Dnnsurv: Deep neural networks for survival analysis using pseudo values.}
\emph{arXiv preprint arXiv:1908.02337}.
}
\seealso{
\itemize{
\item \link[mlr3misc:Dictionary]{Dictionary} of \link[mlr3:Learner]{Learners}: \link[mlr3:mlr_learners]{mlr3::mlr_learners}.
\item \code{as.data.table(mlr_learners)} for a table of available \link[mlr3:Learner]{Learners} in the running session (depending on the loaded packages).
\item Chapter in the \href{https://mlr3book.mlr-org.com/}{mlr3book}: \url{https://mlr3book.mlr-org.com/basics.html#learners}
\item \CRANpkg{mlr3learners} for a selection of recommended learners.
\item \CRANpkg{mlr3cluster} for unsupervised clustering learners.
\item \CRANpkg{mlr3pipelines} to combine learners with pre- and postprocessing steps.
\item \CRANpkg{mlr3tuning} for tuning of hyperparameters, \CRANpkg{mlr3tuningspaces} for established default tuning spaces.
}
}
\author{
RaphaelS1
}
\section{Super classes}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{\link[mlr3proba:LearnerSurv]{mlr3proba::LearnerSurv}} -> \code{LearnerSurvDNNSurv}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-LearnerSurvDNNSurv-new}{\code{LearnerSurvDNNSurv$new()}}
\item \href{#method-LearnerSurvDNNSurv-clone}{\code{LearnerSurvDNNSurv$clone()}}
}
}
\if{html}{\out{
<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerSurvDNNSurv-new"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerSurvDNNSurv-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerSurvDNNSurv$new()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerSurvDNNSurv-clone"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerSurvDNNSurv-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerSurvDNNSurv$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
