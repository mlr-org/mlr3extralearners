% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learner_catboost_regr_catboost.R
\name{mlr_learners_regr.catboost}
\alias{mlr_learners_regr.catboost}
\alias{LearnerRegrCatboost}
\title{Gradient Boosted Decision Trees Regression Learner}
\description{
Gradient boosting algorithm that also supports categorical data.
Calls \code{\link[catboost:catboost.train]{catboost::catboost.train()}} from package 'catboost'.
}
\section{Dictionary}{

This \link[mlr3:Learner]{Learner} can be instantiated via \link[mlr3:mlr_sugar]{lrn()}:

\if{html}{\out{<div class="sourceCode">}}\preformatted{lrn("regr.catboost")
}\if{html}{\out{</div>}}
}

\section{Meta Information}{

\itemize{
\item Task type: \dQuote{regr}
\item Predict Types: \dQuote{response}
\item Feature Types: \dQuote{numeric}, \dQuote{factor}, \dQuote{ordered}
\item Required Packages: \CRANpkg{mlr3}, \CRANpkg{mlr3extralearners}, \CRANpkg{catboost}
}
}

\section{Parameters}{
\tabular{lllll}{
   Id \tab Type \tab Default \tab Levels \tab Range \cr
   loss_function \tab character \tab RMSE \tab MAE, MAPE, Poisson, Quantile, RMSE, LogLinQuantile, Lq, Huber, Expectile, Tweedie \tab - \cr
   learning_rate \tab numeric \tab 0.03 \tab  \tab \eqn{[0.001, 1]}{[0.001, 1]} \cr
   random_seed \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   l2_leaf_reg \tab numeric \tab 3 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   bootstrap_type \tab character \tab - \tab Bayesian, Bernoulli, MVS, Poisson, No \tab - \cr
   bagging_temperature \tab numeric \tab 1 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   subsample \tab numeric \tab - \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   sampling_frequency \tab character \tab PerTreeLevel \tab PerTree, PerTreeLevel \tab - \cr
   sampling_unit \tab character \tab Object \tab Object, Group \tab - \cr
   mvs_reg \tab numeric \tab - \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   random_strength \tab numeric \tab 1 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   depth \tab integer \tab 6 \tab  \tab \eqn{[1, 16]}{[1, 16]} \cr
   grow_policy \tab character \tab SymmetricTree \tab SymmetricTree, Depthwise, Lossguide \tab - \cr
   min_data_in_leaf \tab integer \tab 1 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   max_leaves \tab integer \tab 31 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   has_time \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   rsm \tab numeric \tab 1 \tab  \tab \eqn{[0.001, 1]}{[0.001, 1]} \cr
   nan_mode \tab character \tab Min \tab Min, Max \tab - \cr
   fold_permutation_block \tab integer \tab - \tab  \tab \eqn{[1, 256]}{[1, 256]} \cr
   leaf_estimation_method \tab character \tab - \tab Newton, Gradient, Exact \tab - \cr
   leaf_estimation_iterations \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   leaf_estimation_backtracking \tab character \tab AnyImprovement \tab No, AnyImprovement, Armijo \tab - \cr
   fold_len_multiplier \tab numeric \tab 2 \tab  \tab \eqn{[1.001, \infty)}{[1.001, Inf)} \cr
   approx_on_full_history \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   boosting_type \tab character \tab - \tab Ordered, Plain \tab - \cr
   boost_from_average \tab logical \tab - \tab TRUE, FALSE \tab - \cr
   langevin \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   diffusion_temperature \tab numeric \tab 10000 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   score_function \tab character \tab Cosine \tab Cosine, L2, NewtonCosine, NewtonL2 \tab - \cr
   monotone_constraints \tab untyped \tab - \tab  \tab - \cr
   feature_weights \tab untyped \tab - \tab  \tab - \cr
   first_feature_use_penalties \tab untyped \tab - \tab  \tab - \cr
   penalties_coefficient \tab numeric \tab 1 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   per_object_feature_penalties \tab untyped \tab - \tab  \tab - \cr
   model_shrink_rate \tab numeric \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   model_shrink_mode \tab character \tab - \tab Constant, Decreasing \tab - \cr
   target_border \tab numeric \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   border_count \tab integer \tab - \tab  \tab \eqn{[1, 65535]}{[1, 65535]} \cr
   feature_border_type \tab character \tab GreedyLogSum \tab Median, Uniform, UniformAndQuantiles, MaxLogSum, MinEntropy, GreedyLogSum \tab - \cr
   per_float_feature_quantization \tab untyped \tab - \tab  \tab - \cr
   thread_count \tab integer \tab 1 \tab  \tab \eqn{[-1, \infty)}{[-1, Inf)} \cr
   task_type \tab character \tab CPU \tab CPU, GPU \tab - \cr
   devices \tab untyped \tab - \tab  \tab - \cr
   logging_level \tab character \tab Silent \tab Silent, Verbose, Info, Debug \tab - \cr
   metric_period \tab integer \tab 1 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   train_dir \tab untyped \tab "catboost_info" \tab  \tab - \cr
   model_size_reg \tab numeric \tab 0.5 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   allow_writing_files \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   save_snapshot \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   snapshot_file \tab untyped \tab - \tab  \tab - \cr
   snapshot_interval \tab integer \tab 600 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   simple_ctr \tab untyped \tab - \tab  \tab - \cr
   combinations_ctr \tab untyped \tab - \tab  \tab - \cr
   ctr_target_border_count \tab integer \tab - \tab  \tab \eqn{[1, 255]}{[1, 255]} \cr
   counter_calc_method \tab character \tab Full \tab SkipTest, Full \tab - \cr
   max_ctr_complexity \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   ctr_leaf_count_limit \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   store_all_simple_ctr \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   final_ctr_computation_mode \tab character \tab Default \tab Default, Skip \tab - \cr
   verbose \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   ntree_start \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   ntree_end \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   early_stopping_rounds \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   eval_metric \tab untyped \tab - \tab  \tab - \cr
   use_best_model \tab logical \tab - \tab TRUE, FALSE \tab - \cr
   iterations \tab integer \tab 1000 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
}
}

\section{Installation}{

See \url{https://catboost.ai/en/docs/concepts/r-installation}.
}

\section{Initial parameter values}{

\itemize{
\item \code{logging_level}:
\itemize{
\item Actual default: "Verbose"
\item Adjusted default: "Silent"
\item Reason for change: consistent with other mlr3 learners
}
\item \code{thread_count}:
\itemize{
\item Actual default: -1
\item Adjusted default: 1
\item Reason for change: consistent with other mlr3 learners
}
\item \code{allow_writing_files}:
\itemize{
\item Actual default: TRUE
\item Adjusted default: FALSE
\item Reason for change: consistent with other mlr3 learners
}
\item \code{save_snapshot}:
\itemize{
\item Actual default: TRUE
\item Adjusted default: FALSE
\item Reason for change: consistent with other mlr3 learners
}
}
}

\section{Early stopping}{

Early stopping can be used to find the optimal number of boosting rounds.
Set \code{early_stopping_rounds} to an integer value to monitor the performance of the model on the validation set while training.
For information on how to configure the validation set, see the \emph{Validation} section of \code{\link[mlr3:Learner]{mlr3::Learner}}.
}

\examples{
\dontshow{if (mlr3misc::require_namespaces(lrn("regr.catboost")$packages, quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
# Define the Learner
learner = mlr3::lrn("regr.catboost")
print(learner)

# Define a Task
task = mlr3::tsk("mtcars")

# Create train and test set
ids = mlr3::partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)

print(learner$model)
print(learner$importance)

# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()
\dontshow{\}) # examplesIf}
}
\references{
Dorogush, Veronika A, Ershov, Vasily, Gulin, Andrey (2018).
\dQuote{CatBoost: gradient boosting with categorical features support.}
\emph{arXiv preprint arXiv:1810.11363}.
}
\seealso{
\itemize{
\item \link[mlr3misc:Dictionary]{Dictionary} of \link[mlr3:Learner]{Learners}: \link[mlr3:mlr_learners]{mlr3::mlr_learners}.
\item \code{as.data.table(mlr_learners)} for a table of available \link[mlr3:Learner]{Learners} in the running session (depending on the loaded packages).
\item Chapter in the \href{https://mlr3book.mlr-org.com/}{mlr3book}: \url{https://mlr3book.mlr-org.com/basics.html#learners}
\item \CRANpkg{mlr3learners} for a selection of recommended learners.
\item \CRANpkg{mlr3cluster} for unsupervised clustering learners.
\item \CRANpkg{mlr3pipelines} to combine learners with pre- and postprocessing steps.
\item \CRANpkg{mlr3tuning} for tuning of hyperparameters, \CRANpkg{mlr3tuningspaces} for established default tuning spaces.
}
}
\author{
sumny
}
\section{Super classes}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{\link[mlr3:LearnerRegr]{mlr3::LearnerRegr}} -> \code{LearnerRegrCatboost}
}
\section{Active bindings}{
\if{html}{\out{<div class="r6-active-bindings">}}
\describe{
\item{\code{internal_valid_scores}}{The last observation of the validation scores for all metrics.
Extracted from \code{model$evaluation_log}}

\item{\code{internal_tuned_values}}{Returns the early stopped iterations if \code{early_stopping_rounds} was set during training.}

\item{\code{validate}}{How to construct the internal validation data. This parameter can be either \code{NULL}, a ratio, \code{"test"}, or \code{"predefined"}.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-LearnerRegrCatboost-new}{\code{LearnerRegrCatboost$new()}}
\item \href{#method-LearnerRegrCatboost-importance}{\code{LearnerRegrCatboost$importance()}}
\item \href{#method-LearnerRegrCatboost-clone}{\code{LearnerRegrCatboost$clone()}}
}
}
\if{html}{\out{
<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrCatboost-new"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrCatboost-new}{}}}
\subsection{Method \code{new()}}{
Create a \code{LearnerRegrCatboost} object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrCatboost$new()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrCatboost-importance"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrCatboost-importance}{}}}
\subsection{Method \code{importance()}}{
The importance scores are calculated using
\code{\link[catboost:catboost.get_feature_importance]{catboost.get_feature_importance}},
setting \code{type = "FeatureImportance"}, returned for 'all'.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrCatboost$importance()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
Named \code{numeric()}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrCatboost-clone"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrCatboost-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrCatboost$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
