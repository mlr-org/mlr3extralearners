% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learner_catboost_classif_catboost.R
\name{mlr_learners_classif.catboost}
\alias{mlr_learners_classif.catboost}
\alias{LearnerClassifCatboost}
\title{Gradient Boosted Decision Trees Classification Learner}
\description{
Gradient boosting algorithm that also supports categorical data.
Calls \code{\link[catboost:catboost.train]{catboost::catboost.train()}} from package 'catboost'.
}
\section{Dictionary}{

This \link{Learner} can be instantiated via the \link[mlr3misc:Dictionary]{dictionary} \link{mlr_learners} or with the associated sugar function \code{\link[=lrn]{lrn()}}:

\if{html}{\out{<div class="sourceCode">}}\preformatted{mlr_learners$get("classif.catboost")
lrn("classif.catboost")
}\if{html}{\out{</div>}}
}

\section{Meta Information}{

\itemize{
\item Task type: \dQuote{classif}
\item Predict Types: \dQuote{response}, \dQuote{prob}
\item Feature Types: \dQuote{numeric}, \dQuote{factor}, \dQuote{ordered}
\item Required Packages: \CRANpkg{mlr3}, \CRANpkg{mlr3extralearners}, \CRANpkg{catboost}
}
}

\section{Parameters}{
\tabular{lllll}{
   Id \tab Type \tab Default \tab Levels \tab Range \cr
   loss_function_twoclass \tab character \tab Logloss \tab Logloss, CrossEntropy \tab - \cr
   loss_function_multiclass \tab character \tab MultiClass \tab MultiClass, MultiClassOneVsAll \tab - \cr
   iterations \tab integer \tab 1000 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   learning_rate \tab numeric \tab 0.03 \tab  \tab \eqn{[0.001, 1]}{[0.001, 1]} \cr
   random_seed \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   l2_leaf_reg \tab numeric \tab 3 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   bootstrap_type \tab character \tab - \tab Bayesian, Bernoulli, MVS, Poisson, No \tab - \cr
   bagging_temperature \tab numeric \tab 1 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   subsample \tab numeric \tab - \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   sampling_frequency \tab character \tab PerTreeLevel \tab PerTree, PerTreeLevel \tab - \cr
   sampling_unit \tab character \tab Object \tab Object, Group \tab - \cr
   mvs_reg \tab numeric \tab - \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   random_strength \tab numeric \tab 1 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   depth \tab integer \tab 6 \tab  \tab \eqn{[1, 16]}{[1, 16]} \cr
   grow_policy \tab character \tab SymmetricTree \tab SymmetricTree, Depthwise, Lossguide \tab - \cr
   min_data_in_leaf \tab integer \tab 1 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   max_leaves \tab integer \tab 31 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   ignored_features \tab untyped \tab  \tab  \tab - \cr
   one_hot_max_size \tab untyped \tab FALSE \tab  \tab - \cr
   has_time \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   rsm \tab numeric \tab 1 \tab  \tab \eqn{[0.001, 1]}{[0.001, 1]} \cr
   nan_mode \tab character \tab Min \tab Min, Max \tab - \cr
   fold_permutation_block \tab integer \tab - \tab  \tab \eqn{[1, 256]}{[1, 256]} \cr
   leaf_estimation_method \tab character \tab - \tab Newton, Gradient, Exact \tab - \cr
   leaf_estimation_iterations \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   leaf_estimation_backtracking \tab character \tab AnyImprovement \tab No, AnyImprovement, Armijo \tab - \cr
   fold_len_multiplier \tab numeric \tab 2 \tab  \tab \eqn{[1.001, \infty)}{[1.001, Inf)} \cr
   approx_on_full_history \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   class_weights \tab untyped \tab - \tab  \tab - \cr
   auto_class_weights \tab character \tab None \tab None, Balanced, SqrtBalanced \tab - \cr
   boosting_type \tab character \tab - \tab Ordered, Plain \tab - \cr
   boost_from_average \tab logical \tab - \tab TRUE, FALSE \tab - \cr
   langevin \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   diffusion_temperature \tab numeric \tab 10000 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   score_function \tab character \tab Cosine \tab Cosine, L2, NewtonCosine, NewtonL2 \tab - \cr
   monotone_constraints \tab untyped \tab - \tab  \tab - \cr
   feature_weights \tab untyped \tab - \tab  \tab - \cr
   first_feature_use_penalties \tab untyped \tab - \tab  \tab - \cr
   penalties_coefficient \tab numeric \tab 1 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   per_object_feature_penalties \tab untyped \tab - \tab  \tab - \cr
   model_shrink_rate \tab numeric \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   model_shrink_mode \tab character \tab - \tab Constant, Decreasing \tab - \cr
   target_border \tab numeric \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   border_count \tab integer \tab - \tab  \tab \eqn{[1, 65535]}{[1, 65535]} \cr
   feature_border_type \tab character \tab GreedyLogSum \tab Median, Uniform, UniformAndQuantiles, MaxLogSum, MinEntropy, GreedyLogSum \tab - \cr
   per_float_feature_quantization \tab untyped \tab - \tab  \tab - \cr
   classes_count \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   thread_count \tab integer \tab 1 \tab  \tab \eqn{[-1, \infty)}{[-1, Inf)} \cr
   task_type \tab character \tab CPU \tab CPU, GPU \tab - \cr
   devices \tab untyped \tab - \tab  \tab - \cr
   logging_level \tab character \tab Silent \tab Silent, Verbose, Info, Debug \tab - \cr
   metric_period \tab integer \tab 1 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   train_dir \tab untyped \tab catboost_info \tab  \tab - \cr
   model_size_reg \tab numeric \tab 0.5 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   allow_writing_files \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   save_snapshot \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   snapshot_file \tab untyped \tab - \tab  \tab - \cr
   snapshot_interval \tab integer \tab 600 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   simple_ctr \tab untyped \tab - \tab  \tab - \cr
   combinations_ctr \tab untyped \tab - \tab  \tab - \cr
   ctr_target_border_count \tab integer \tab - \tab  \tab \eqn{[1, 255]}{[1, 255]} \cr
   counter_calc_method \tab character \tab Full \tab SkipTest, Full \tab - \cr
   max_ctr_complexity \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   ctr_leaf_count_limit \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   store_all_simple_ctr \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   final_ctr_computation_mode \tab character \tab Default \tab Default, Skip \tab - \cr
   verbose \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   ntree_start \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   ntree_end \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
}
}

\section{Installation}{

The easiest way to install catboost is with the helper function
\link{install_catboost}.
}

\section{Custom mlr3 defaults}{

\itemize{
\item \code{logging_level}:
\itemize{
\item Actual default: "Verbose"
\item Adjusted default: "Silent"
\item Reason for change: consistent with other mlr3 learners
}
\item \code{thread_count}:
\itemize{
\item Actual default: -1
\item Adjusted default: 1
\item Reason for change: consistent with other mlr3 learners
}
\item \code{allow_writing_files}:
\itemize{
\item Actual default: TRUE
\item Adjusted default: FALSE
\item Reason for change: consistent with other mlr3 learners
}
\item \code{save_snapshot}:
\itemize{
\item Actual default: TRUE
\item Adjusted default: FALSE
\item Reason for change: consistent with other mlr3 learners
}
}
}

\examples{
learner = mlr3::lrn("classif.catboost")
print(learner)

# available parameters:
learner$param_set$ids()
}
\references{
Dorogush, Veronika A, Ershov, Vasily, Gulin, Andrey (2018).
\dQuote{CatBoost: gradient boosting with categorical features support.}
\emph{arXiv preprint arXiv:1810.11363}.
}
\seealso{
\itemize{
\item \link[mlr3misc:Dictionary]{Dictionary} of \link[mlr3:Learner]{Learners}: \link[mlr3:mlr_learners]{mlr3::mlr_learners}.
\item \code{as.data.table(mlr_learners)} for a table of available \link[=Learner]{Learners} in the running session (depending on the loaded packages).
\item Chapter in the \href{https://mlr3book.mlr-org.com/}{mlr3book}: \url{https://mlr3book.mlr-org.com/basics.html#learners}
\item \CRANpkg{mlr3learners} for a selection of recommended learners.
\item \CRANpkg{mlr3cluster} for unsupervised clustering learners.
\item \CRANpkg{mlr3pipelines} to combine learners with pre- and postprocessing steps.
\item \CRANpkg{mlr3tuning} for tuning of hyperparameters, \CRANpkg{mlr3tuningspaces} for established default tuning spaces.
}
}
\author{
sumny
}
\section{Super classes}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{\link[mlr3:LearnerClassif]{mlr3::LearnerClassif}} -> \code{LearnerClassifCatboost}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-LearnerClassifCatboost-new}{\code{LearnerClassifCatboost$new()}}
\item \href{#method-LearnerClassifCatboost-importance}{\code{LearnerClassifCatboost$importance()}}
\item \href{#method-LearnerClassifCatboost-clone}{\code{LearnerClassifCatboost$clone()}}
}
}
\if{html}{\out{
<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerClassifCatboost-new"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerClassifCatboost-new}{}}}
\subsection{Method \code{new()}}{
Create a \code{LearnerClassifCatboost} object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerClassifCatboost$new()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerClassifCatboost-importance"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerClassifCatboost-importance}{}}}
\subsection{Method \code{importance()}}{
The importance scores are calculated using
\code{\link[catboost:catboost.get_feature_importance]{catboost.get_feature_importance}},
setting \code{type = "FeatureImportance"}, returned for 'all'.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerClassifCatboost$importance()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
Named \code{numeric()}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerClassifCatboost-clone"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerClassifCatboost-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerClassifCatboost$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
