% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learner_tabpfn_regr_tabpfn.R
\name{mlr_learners_regr.tabpfn}
\alias{mlr_learners_regr.tabpfn}
\alias{LearnerRegrTabPFN}
\title{TabPFN Regression Learner}
\description{
Foundation model for tabular data.
Uses \CRANpkg{reticulate} to interface with the \href{https://github.com/PriorLabs/TabPFN}{\code{tabpfn}} Python package.
}
\section{Installation}{

This learner relies on \CRANpkg{reticulate} to handle Python dependencies.
It is not necessary to install any Python package manually in advance or specify a Python environment
via \code{reticulate::use_python()}, \code{reticulate::use_virtualenv()}, \code{reticulate::use_condaenv()},
or \code{reticulate::use_miniconda()}.
By calling \verb{$train()} or \verb{$predict()}, the required Python packages (\code{tapfn}, \code{torch}, etc.) will be installed
automatically, if not already.
Reticulate will then configure and initialize an ephemeral environment satisfying those requirements,
unless an existing environment (e.g., \code{"r-reticulate"}) in reticulate's
\href{https://rstudio.github.io/reticulate/articles/versions.html#order-of-discovery}{Order of Discovery}
contains all the necessary packages.

You may also manually install \code{tabpfn} into a Python environment following the
\href{https://github.com/PriorLabs/TabPFN?tab=readme-ov-file#-quick-start}{official installation guide}
and specify the environment via \verb{reticulate::use_*()} before calling \verb{$train()} or \verb{$predict()}.
Note that the GPU version of PyTorch cannot be loaded by \code{reticulate::use_condaenv()} from a conda environment.
To use a conda environment, please install the CPU version of PyTorch.
}

\section{Saving a Learner}{

In order to save a \code{LearnerRegrTabPFN} for later usage,
it is necessary to call the \verb{$marshal()} method on the \code{Learner}
before writing it to disk, as the object will otherwise not be saved correctly.
After loading a marshaled \code{LearnerRegrTabPFN} into R again,
you then need to call \verb{$unmarshal()} to transform it into a useable state.
}

\section{Initial parameter values}{

\itemize{
\item \code{n_jobs} is initialized to 1 to avoid threading conflicts with \CRANpkg{future}.
}
}

\section{Custom mlr3 parameters}{

\itemize{
\item \code{output_type} corresponds to the same argument of the \code{.predict()} method of the \code{TabPFNRegressor} class,
but only supports the options \code{"mean"}, \code{"median"} and \code{"mode"}.
The point predictions are stored as \verb{$response} of the prediction object.
\item \code{categorical_feature_indices} uses R indexing instead of zero-based Python indexing.
\item \code{device} must be a string.
If set to \code{"auto"}, the behavior is the same as original.
Otherwise, the string is passed as argument to \code{torch.device()} to create a device.
\item \code{inference_precision} must be \code{"auto"}, \code{"autocast"},
or a \href{https://docs.pytorch.org/docs/stable/tensor_attributes.html}{\code{torch.dtype}} string,
e.g., \code{"torch.float32"}, \code{"torch.float64"}, etc.
Non-float dtypes are not supported.
\item \code{inference_config} is currently not supported.
\item \code{random_state} accepts either an integer or the special value \code{"None"}
which corresponds to \code{None} in Python.
Following the original Python implementation, the default \code{random_state} is \code{0}.
}
}

\section{Dictionary}{

This \link[mlr3:Learner]{Learner} can be instantiated via \link[mlr3:mlr_sugar]{lrn()}:

\if{html}{\out{<div class="sourceCode">}}\preformatted{lrn("regr.tabpfn")
}\if{html}{\out{</div>}}
}

\section{Meta Information}{

\itemize{
\item Task type: \dQuote{regr}
\item Predict Types: \dQuote{response}, \dQuote{quantiles}
\item Feature Types: \dQuote{logical}, \dQuote{integer}, \dQuote{numeric}
\item Required Packages: \CRANpkg{mlr3}, \CRANpkg{reticulate}
}
}

\section{Parameters}{
\tabular{lllll}{
   Id \tab Type \tab Default \tab Levels \tab Range \cr
   output_type \tab character \tab mean \tab mean, median, mode \tab - \cr
   n_estimators \tab integer \tab 4 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   categorical_features_indices \tab untyped \tab - \tab  \tab - \cr
   softmax_temperature \tab numeric \tab 0.9 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   average_before_softmax \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   model_path \tab untyped \tab "auto" \tab  \tab - \cr
   device \tab untyped \tab "auto" \tab  \tab - \cr
   ignore_pretraining_limits \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   inference_precision \tab character \tab auto \tab auto, autocast, torch.float32, torch.float, torch.float64, torch.double, torch.float16, torch.half, torch.bfloat16 \tab - \cr
   fit_mode \tab character \tab fit_preprocessors \tab low_memory, fit_preprocessors, fit_with_cache \tab - \cr
   memory_saving_mode \tab untyped \tab "auto" \tab  \tab - \cr
   random_state \tab integer \tab 0 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   n_jobs \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
}
}

\references{
Hollmann, Noah, Müller, Samuel, Purucker, Lennart, Krishnakumar, Arjun, Körfer, Max, Hoo, Bin S, Schirrmeister, Tibor R, Hutter, Frank (2025).
\dQuote{Accurate predictions on small data with a tabular foundation model.}
\emph{Nature}.
\doi{10.1038/s41586-024-08328-6}, \url{https://www.nature.com/articles/s41586-024-08328-6}.

Hollmann, Noah, Müller, Samuel, Eggensperger, Katharina, Hutter, Frank (2023).
\dQuote{TabPFN: A transformer that solves small tabular classification problems in a second.}
In \emph{International Conference on Learning Representations 2023}.
}
\seealso{
\itemize{
\item \link[mlr3misc:Dictionary]{Dictionary} of \link[mlr3:Learner]{Learners}: \link[mlr3:mlr_learners]{mlr3::mlr_learners}.
\item \code{as.data.table(mlr_learners)} for a table of available \link[mlr3:Learner]{Learners} in the running session (depending on the loaded packages).
\item Chapter in the \href{https://mlr3book.mlr-org.com/}{mlr3book}: \url{https://mlr3book.mlr-org.com/basics.html#learners}
\item \CRANpkg{mlr3learners} for a selection of recommended learners.
\item \CRANpkg{mlr3cluster} for unsupervised clustering learners.
\item \CRANpkg{mlr3pipelines} to combine learners with pre- and postprocessing steps.
\item \CRANpkg{mlr3tuning} for tuning of hyperparameters, \CRANpkg{mlr3tuningspaces} for established default tuning spaces.
}
}
\author{
b-zhou
}
\section{Super classes}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{\link[mlr3:LearnerRegr]{mlr3::LearnerRegr}} -> \code{LearnerRegrTabPFN}
}
\section{Active bindings}{
\if{html}{\out{<div class="r6-active-bindings">}}
\describe{
\item{\code{marshaled}}{(\code{logical(1)})\cr
Whether the learner has been marshaled.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-LearnerRegrTabPFN-new}{\code{LearnerRegrTabPFN$new()}}
\item \href{#method-LearnerRegrTabPFN-marshal}{\code{LearnerRegrTabPFN$marshal()}}
\item \href{#method-LearnerRegrTabPFN-unmarshal}{\code{LearnerRegrTabPFN$unmarshal()}}
\item \href{#method-LearnerRegrTabPFN-clone}{\code{LearnerRegrTabPFN$clone()}}
}
}
\if{html}{\out{
<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="configure"><a href='../../mlr3/html/Learner.html#method-Learner-configure'><code>mlr3::Learner$configure()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="encapsulate"><a href='../../mlr3/html/Learner.html#method-Learner-encapsulate'><code>mlr3::Learner$encapsulate()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="selected_features"><a href='../../mlr3/html/Learner.html#method-Learner-selected_features'><code>mlr3::Learner$selected_features()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="LearnerRegr" data-id="predict_newdata_fast"><a href='../../mlr3/html/LearnerRegr.html#method-LearnerRegr-predict_newdata_fast'><code>mlr3::LearnerRegr$predict_newdata_fast()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrTabPFN-new"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrTabPFN-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrTabPFN$new()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrTabPFN-marshal"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrTabPFN-marshal}{}}}
\subsection{Method \code{marshal()}}{
Marshal the learner's model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrTabPFN$marshal(...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{...}}{(any)\cr
Additional arguments passed to \code{\link[mlr3:marshaling]{mlr3::marshal_model()}}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrTabPFN-unmarshal"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrTabPFN-unmarshal}{}}}
\subsection{Method \code{unmarshal()}}{
Unmarshal the learner's model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrTabPFN$unmarshal(...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{...}}{(any)\cr
Additional arguments passed to \code{\link[mlr3:marshaling]{mlr3::unmarshal_model()}}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrTabPFN-clone"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrTabPFN-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrTabPFN$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
