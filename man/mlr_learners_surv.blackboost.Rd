% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learner_mboost_surv_blackboost.R
\name{mlr_learners_surv.blackboost}
\alias{mlr_learners_surv.blackboost}
\alias{LearnerSurvBlackBoost}
\title{Gradient Boosting with Regression Trees Survival Learner}
\description{
Gradient boosting with regression trees for survival analysis.
Calls \code{\link[mboost:blackboost]{mboost::blackboost()}} from \CRANpkg{mboost}.
}
\details{
\code{distr} prediction made by \code{\link[mboost:survFit]{mboost::survFit()}}.
}
\section{Prediction types}{

This learner returns two to three prediction types:
\enumerate{
\item \code{lp}: a vector containing the linear predictors (relative risk scores),
where each score corresponds to a specific test observation.
Calculated using \code{\link[mboost:methods]{mboost::predict.blackboost()}}.
If the \code{family} parameter is not \code{"coxph"}, \code{-lp} is returned, since non-coxph
families represent AFT-style distributions where lower \code{lp} values indicate higher risk.
\item \code{crank}: same as \code{lp}.
\item \code{distr}: a survival matrix in two dimensions, where observations are
represented in rows and time points in columns.
Calculated using \code{\link[mboost:survFit]{mboost::survFit()}}.
This prediction type is present only when the \code{family} distribution parameter
is equal to \code{"coxph"} (default).
By default the Breslow estimator is used for computing the baseline hazard.
}
}

\section{Dictionary}{

This \link[mlr3:Learner]{Learner} can be instantiated via \link[mlr3:mlr_sugar]{lrn()}:

\if{html}{\out{<div class="sourceCode">}}\preformatted{lrn("surv.blackboost")
}\if{html}{\out{</div>}}
}

\section{Meta Information}{

\itemize{
\item Task type: \dQuote{surv}
\item Predict Types: \dQuote{crank}, \dQuote{distr}, \dQuote{lp}
\item Feature Types: \dQuote{integer}, \dQuote{numeric}, \dQuote{factor}
\item Required Packages: \CRANpkg{mlr3}, \CRANpkg{mlr3proba}, \CRANpkg{mlr3extralearners}, \CRANpkg{mboost}
}
}

\section{Parameters}{
\tabular{lllll}{
   Id \tab Type \tab Default \tab Levels \tab Range \cr
   family \tab character \tab coxph \tab coxph, weibull, loglog, lognormal, gehan, cindex, custom \tab - \cr
   custom.family \tab untyped \tab - \tab  \tab - \cr
   nuirange \tab untyped \tab c(0, 100) \tab  \tab - \cr
   center \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   mstop \tab integer \tab 100 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   nu \tab numeric \tab 0.1 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   risk \tab character \tab - \tab inbag, oobag, none \tab - \cr
   stopintern \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   trace \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   oobweights \tab untyped \tab - \tab  \tab - \cr
   teststat \tab character \tab quadratic \tab quadratic, maximum \tab - \cr
   splitstat \tab character \tab quadratic \tab quadratic, maximum \tab - \cr
   splittest \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   testtype \tab character \tab Bonferroni \tab Bonferroni, MonteCarlo, Univariate, Teststatistic \tab - \cr
   maxpts \tab integer \tab 25000 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   abseps \tab numeric \tab 0.001 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   releps \tab numeric \tab 0 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   nmax \tab untyped \tab - \tab  \tab - \cr
   alpha \tab numeric \tab 0.05 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   mincriterion \tab numeric \tab 0.95 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   logmincriterion \tab numeric \tab -0.05129329 \tab  \tab \eqn{(-\infty, 0]}{(-Inf, 0]} \cr
   minsplit \tab integer \tab 20 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   minbucket \tab integer \tab 7 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   minprob \tab numeric \tab 0.01 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   stump \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   lookahead \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   MIA \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   nresample \tab integer \tab 9999 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   tol \tab numeric \tab 1.490116e-08 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   maxsurrogate \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   mtry \tab integer \tab - \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   maxdepth \tab integer \tab - \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   multiway \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   splittry \tab integer \tab 2 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   intersplit \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   majority \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   caseweights \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   sigma \tab numeric \tab 0.1 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   ipcw \tab untyped \tab 1 \tab  \tab - \cr
   na.action \tab untyped \tab stats::na.omit \tab  \tab - \cr
}
}

\section{Offset}{

If a \code{Task} contains a column with the \code{offset} role, it is automatically
incorporated via the \code{offset} argument in \code{mboost}'s training function.
No offset is applied during prediction for this learner.
}

\examples{
\dontshow{if (learner_is_runnable("surv.blackboost")) withAutoprint(\{ # examplesIf}
# Define the Learner
learner = lrn("surv.blackboost")
print(learner)

# Define a Task
task = tsk("grace")

# Create train and test set
ids = partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)

print(learner$model)


# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()
\dontshow{\}) # examplesIf}
}
\references{
BÃ¼hlmann, Peter, Yu, Bin (2003).
\dQuote{Boosting with the L 2 loss: regression and classification.}
\emph{Journal of the American Statistical Association}, \bold{98}(462), 324--339.
}
\seealso{
\itemize{
\item \link[mlr3misc:Dictionary]{Dictionary} of \link[mlr3:Learner]{Learners}: \link[mlr3:mlr_learners]{mlr3::mlr_learners}.
\item \code{as.data.table(mlr_learners)} for a table of available \link[mlr3:Learner]{Learners} in the running session (depending on the loaded packages).
\item Chapter in the \href{https://mlr3book.mlr-org.com/}{mlr3book}: \url{https://mlr3book.mlr-org.com/basics.html#learners}
\item \CRANpkg{mlr3learners} for a selection of recommended learners.
\item \CRANpkg{mlr3cluster} for unsupervised clustering learners.
\item \CRANpkg{mlr3pipelines} to combine learners with pre- and postprocessing steps.
\item \CRANpkg{mlr3tuning} for tuning of hyperparameters, \CRANpkg{mlr3tuningspaces} for established default tuning spaces.
}
}
\author{
RaphaelS1
}
\section{Super classes}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{\link[mlr3proba:LearnerSurv]{mlr3proba::LearnerSurv}} -> \code{LearnerSurvBlackBoost}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-LearnerSurvBlackBoost-new}{\code{LearnerSurvBlackBoost$new()}}
\item \href{#method-LearnerSurvBlackBoost-clone}{\code{LearnerSurvBlackBoost$clone()}}
}
}
\if{html}{\out{
<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="configure"><a href='../../mlr3/html/Learner.html#method-Learner-configure'><code>mlr3::Learner$configure()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="encapsulate"><a href='../../mlr3/html/Learner.html#method-Learner-encapsulate'><code>mlr3::Learner$encapsulate()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="selected_features"><a href='../../mlr3/html/Learner.html#method-Learner-selected_features'><code>mlr3::Learner$selected_features()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerSurvBlackBoost-new"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerSurvBlackBoost-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerSurvBlackBoost$new()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerSurvBlackBoost-clone"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerSurvBlackBoost-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerSurvBlackBoost$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
