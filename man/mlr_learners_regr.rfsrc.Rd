% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learner_randomForestSRC_regr_rfsrc.R
\name{mlr_learners_regr.rfsrc}
\alias{mlr_learners_regr.rfsrc}
\alias{LearnerRegrRandomForestSRC}
\title{Regression Random Forest SRC Learner}
\description{
Random forest for regression.
Calls \code{\link[randomForestSRC:rfsrc]{randomForestSRC::rfsrc()}} from \CRANpkg{randomForestSRC}.
}
\section{Dictionary}{

This \link{Learner} can be instantiated via the \link[mlr3misc:Dictionary]{dictionary} \link{mlr_learners} or with the associated sugar function \code{\link[=lrn]{lrn()}}:

\if{html}{\out{<div class="sourceCode">}}\preformatted{mlr_learners$get("regr.rfsrc")
lrn("regr.rfsrc")
}\if{html}{\out{</div>}}
}

\section{Meta Information}{

\itemize{
\item Task type: \dQuote{regr}
\item Predict Types: \dQuote{response}
\item Feature Types: \dQuote{logical}, \dQuote{integer}, \dQuote{numeric}, \dQuote{factor}
\item Required Packages: \CRANpkg{mlr3}, \CRANpkg{mlr3extralearners}, \CRANpkg{randomForestSRC}
}
}

\section{Parameters}{
\tabular{lllll}{
   Id \tab Type \tab Default \tab Levels \tab Range \cr
   ntree \tab integer \tab 1000 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   mtry \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   mtry.ratio \tab numeric \tab - \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   nodesize \tab integer \tab 15 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   nodedepth \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   splitrule \tab character \tab mse \tab mse, quantile.regr, la.quantile.regr \tab - \cr
   nsplit \tab integer \tab 10 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   importance \tab character \tab FALSE \tab FALSE, TRUE, none, permute, random, anti \tab - \cr
   block.size \tab integer \tab 10 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   bootstrap \tab character \tab by.root \tab by.root, by.node, none, by.user \tab - \cr
   samptype \tab character \tab swor \tab swor, swr \tab - \cr
   samp \tab untyped \tab - \tab  \tab - \cr
   membership \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   sampsize \tab untyped \tab - \tab  \tab - \cr
   sampsize.ratio \tab numeric \tab - \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   na.action \tab character \tab na.omit \tab na.omit, na.impute \tab - \cr
   nimpute \tab integer \tab 1 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   ntime \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   cause \tab integer \tab - \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   proximity \tab character \tab FALSE \tab FALSE, TRUE, inbag, oob, all \tab - \cr
   distance \tab character \tab FALSE \tab FALSE, TRUE, inbag, oob, all \tab - \cr
   forest.wt \tab character \tab FALSE \tab FALSE, TRUE, inbag, oob, all \tab - \cr
   xvar.wt \tab untyped \tab - \tab  \tab - \cr
   split.wt \tab untyped \tab - \tab  \tab - \cr
   forest \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   var.used \tab character \tab FALSE \tab FALSE, all.trees, by.tree \tab - \cr
   split.depth \tab character \tab FALSE \tab FALSE, all.trees, by.tree \tab - \cr
   seed \tab integer \tab - \tab  \tab \eqn{(-\infty, -1]}{(-Inf, -1]} \cr
   do.trace \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   statistics \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   get.tree \tab untyped \tab - \tab  \tab - \cr
   outcome \tab character \tab train \tab train, test \tab - \cr
   ptn.count \tab integer \tab 0 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   cores \tab integer \tab 1 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   save.memory \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
}
}

\section{Initial parameter values}{

\itemize{
\item \code{mtry}:
\itemize{
\item This hyperparameter can alternatively be set via the added hyperparameter \code{mtry.ratio}
as \code{mtry = max(ceiling(mtry.ratio * n_features), 1)}.
Note that \code{mtry} and \code{mtry.ratio} are mutually exclusive.
}
\item \code{sampsize}:
\itemize{
\item This hyperparameter can alternatively be set via the added hyperparameter \code{sampsize.ratio}
as \code{sampsize = max(ceiling(sampsize.ratio * n_obs), 1)}.
Note that \code{sampsize} and \code{sampsize.ratio} are mutually exclusive.
}
}
}

\examples{
learner = mlr3::lrn("regr.rfsrc")
print(learner)

# available parameters:
learner$param_set$ids()
}
\references{
Breiman, Leo (2001).
\dQuote{Random Forests.}
\emph{Machine Learning}, \bold{45}(1), 5--32.
ISSN 1573-0565, \doi{10.1023/A:1010933404324}.
}
\seealso{
\itemize{
\item \link[mlr3misc:Dictionary]{Dictionary} of \link[mlr3:Learner]{Learners}: \link[mlr3:mlr_learners]{mlr3::mlr_learners}.
\item \code{as.data.table(mlr_learners)} for a table of available \link[=Learner]{Learners} in the running session (depending on the loaded packages).
\item Chapter in the \href{https://mlr3book.mlr-org.com/}{mlr3book}: \url{https://mlr3book.mlr-org.com/basics.html#learners}
\item \CRANpkg{mlr3learners} for a selection of recommended learners.
\item \CRANpkg{mlr3cluster} for unsupervised clustering learners.
\item \CRANpkg{mlr3pipelines} to combine learners with pre- and postprocessing steps.
\item \CRANpkg{mlr3tuning} for tuning of hyperparameters, \CRANpkg{mlr3tuningspaces} for established default tuning spaces.
}
}
\author{
RaphaelS1
}
\section{Super classes}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{\link[mlr3:LearnerRegr]{mlr3::LearnerRegr}} -> \code{LearnerRegrRandomForestSRC}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-LearnerRegrRandomForestSRC-new}{\code{LearnerRegrRandomForestSRC$new()}}
\item \href{#method-LearnerRegrRandomForestSRC-importance}{\code{LearnerRegrRandomForestSRC$importance()}}
\item \href{#method-LearnerRegrRandomForestSRC-selected_features}{\code{LearnerRegrRandomForestSRC$selected_features()}}
\item \href{#method-LearnerRegrRandomForestSRC-oob_error}{\code{LearnerRegrRandomForestSRC$oob_error()}}
\item \href{#method-LearnerRegrRandomForestSRC-clone}{\code{LearnerRegrRandomForestSRC$clone()}}
}
}
\if{html}{\out{
<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrRandomForestSRC-new"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrRandomForestSRC-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrRandomForestSRC$new()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrRandomForestSRC-importance"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrRandomForestSRC-importance}{}}}
\subsection{Method \code{importance()}}{
The importance scores are extracted from the model slot \code{importance}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrRandomForestSRC$importance()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
Named \code{numeric()}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrRandomForestSRC-selected_features"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrRandomForestSRC-selected_features}{}}}
\subsection{Method \code{selected_features()}}{
Selected features are extracted from the model slot \code{var.used}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrRandomForestSRC$selected_features()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{character()}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrRandomForestSRC-oob_error"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrRandomForestSRC-oob_error}{}}}
\subsection{Method \code{oob_error()}}{
OOB error extracted from the model slot \code{err.rate}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrRandomForestSRC$oob_error()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{numeric()}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerRegrRandomForestSRC-clone"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerRegrRandomForestSRC-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerRegrRandomForestSRC$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
