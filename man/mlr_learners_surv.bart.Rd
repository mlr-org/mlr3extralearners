% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learner_BART_surv_bart.R
\name{mlr_learners_surv.bart}
\alias{mlr_learners_surv.bart}
\alias{LearnerSurvLearnerSurvBART}
\title{Survival Bayesian Additive Regression Trees Learner}
\description{
Fits a Bayesian Additive Regression Trees (BART) learner to right-censored
survival data.
For prediction, we return the mean posterior estimates of the survival
function and the corresponding \code{crank} (expected mortality) using
\link[mlr3proba:dot-surv_return]{mlr3proba::.surv_return}.
The full posterior estimates are currently stored in the
\code{learner$state$surv_test} slot, along with the number of test observations
\code{N}, number of unique times in the train set \code{K} and number of posterior
draws \code{M}.
See example for more details.

Calls \code{\link[BART:surv.bart]{BART::mc.surv.bart()}} from \CRANpkg{BART}.
Based on BART version 2.9.4 (2023-03-25).
}
\section{Custom mlr3 defaults}{

\itemize{
\item \code{mc.cores} (in general use as many as possible if no issues arise):
\itemize{
\item Actual default: 2
\item Adjusted value: 1
\item Reason for change: May conflict with parallelization via \CRANpkg{future}.
}
}
}

\section{Initial parameter values}{

\itemize{
\item \code{quiet}
\itemize{
\item Default is \code{TRUE}, to suppress messages generated by the wrapped C++ code
during prediction.
}
}
}

\section{Dictionary}{

This \link{Learner} can be instantiated via the \link[mlr3misc:Dictionary]{dictionary} \link{mlr_learners} or with the associated sugar function \code{\link[=lrn]{lrn()}}:

\if{html}{\out{<div class="sourceCode">}}\preformatted{mlr_learners$get("surv.bart")
lrn("surv.bart")
}\if{html}{\out{</div>}}
}

\section{Meta Information}{

\itemize{
\item Task type: \dQuote{surv}
\item Predict Types: \dQuote{crank}, \dQuote{distr}
\item Feature Types: \dQuote{logical}, \dQuote{integer}, \dQuote{numeric}, \dQuote{factor}
\item Required Packages: \CRANpkg{mlr3}, \CRANpkg{mlr3proba}, \CRANpkg{BART}
}
}

\section{Parameters}{
\tabular{lllll}{
   Id \tab Type \tab Default \tab Levels \tab Range \cr
   K \tab untyped \tab  \tab  \tab - \cr
   events \tab untyped \tab  \tab  \tab - \cr
   ztimes \tab untyped \tab  \tab  \tab - \cr
   zdelta \tab untyped \tab  \tab  \tab - \cr
   sparse \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   theta \tab numeric \tab 0 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   omega \tab numeric \tab 1 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   a \tab numeric \tab 0.5 \tab  \tab \eqn{[0.5, 1]}{[0.5, 1]} \cr
   b \tab numeric \tab 1 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   augment \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   rho \tab numeric \tab NULL \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   usequants \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   rm.const \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   type \tab character \tab pbart \tab pbart, lbart \tab - \cr
   ntype \tab integer \tab - \tab  \tab \eqn{[1, 3]}{[1, 3]} \cr
   k \tab numeric \tab 2 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   power \tab numeric \tab 2 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   base \tab numeric \tab 0.95 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   offset \tab numeric \tab NULL \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   ntree \tab integer \tab 50 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   numcut \tab integer \tab 100 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   ndpost \tab integer \tab 1000 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   nskip \tab integer \tab 250 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   keepevery \tab integer \tab 10 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   printevery \tab integer \tab 100 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   seed \tab integer \tab 99 \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   mc.cores \tab integer \tab 2 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   nice \tab integer \tab 19 \tab  \tab \eqn{[0, 19]}{[0, 19]} \cr
   openmp \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   quiet \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
}
}

\examples{
library(mlr3proba)
library(dplyr)
library(ggplot2)

learner = lrn("surv.bart", nskip = 10, ndpost = 20, keepevery = 2)
task = tsk("lung")
task$missings() # has missing values

# split to train and test sets
set.seed(42)
part = partition(task)

# Train
learner$train(task, row_ids = part$train)

# Importance: average number of times a feature has been used in the trees
learner$importance()

# Test
p = learner$predict(task, row_ids = part$test)
p$score() # C-index

# Mean survival probabilities for the first 3 patients at given time points
p$distr$survival(times = c(1,50,150))[,1:3]

# number of posterior draws
M = learner$state$M
stopifnot(M == 20)
# number of test observations
N = learner$state$N
stopifnot(N == length(part$test))
# number of unique time points in the train set
K = learner$state$K
stopifnot(K == length(task$unique_times(rows = part$train)))
# the actual times are also available in the `$model` slot:
head(learner$model$times)

# Full posterior prediction matrix
surv_test = learner$state$surv_test
stopifnot(all(dim(surv_test) == c(M, K * N)))

# Posterior survival function estimates for the 1st test patient for all
# time points (from the train set) - see Sparapani (2021), pages 34-35
post_surv = surv_test[, 1:K]

# For every time point, get the median survival estimate as well as
# the lower and upper bounds of the 95\% quantile credible interval
surv_data = post_surv \%>\%
  as.data.frame() \%>\%
  `colnames<-` (learner$model$times) \%>\%
  summarise(across(everything(), list(
    median   = ~ median(.),
    low_qi   = ~ quantile(., 0.025),
    high_qi  = ~ quantile(., 0.975)
  ))) \%>\%
  tidyr::pivot_longer(
    cols = everything(),
    names_to = c("times", ".value"),
    names_pattern = "(^[^_]+)_(.*)" # everything until the first underscore
  ) \%>\%
  mutate(times = as.numeric(times))
surv_data

# Draw a survival curve for the first patient in the test set with
# uncertainty quantified
surv_data \%>\%
  ggplot2::ggplot(aes(x = times, y = median)) +
  geom_step(col = 'black') +
  xlab('Time (Days)') +
  ylab('Survival Probability') +
  geom_ribbon(aes(ymin = low_qi, ymax = high_qi), alpha = 0.3) +
  theme_bw()
}
\references{
Sparapani, Rodney, Spanbauer, Charles, McCulloch, Robert (2021).
\dQuote{Nonparametric machine learning and efficient computation with bayesian additive regression trees: the BART R package.}
\emph{Journal of Statistical Software}, \bold{97}, 1--66.

Chipman, A H, George, I E, McCulloch, E R (2010).
\dQuote{BART: Bayesian additive regression trees.}
\emph{The Annals of Applied Statistics}, \bold{4}(1), 266--298.
}
\seealso{
\itemize{
\item \link[mlr3misc:Dictionary]{Dictionary} of \link[mlr3:Learner]{Learners}: \link[mlr3:mlr_learners]{mlr3::mlr_learners}.
\item \code{as.data.table(mlr_learners)} for a table of available \link[=Learner]{Learners} in the running session (depending on the loaded packages).
\item Chapter in the \href{https://mlr3book.mlr-org.com/}{mlr3book}: \url{https://mlr3book.mlr-org.com/basics.html#learners}
\item \CRANpkg{mlr3learners} for a selection of recommended learners.
\item \CRANpkg{mlr3cluster} for unsupervised clustering learners.
\item \CRANpkg{mlr3pipelines} to combine learners with pre- and postprocessing steps.
\item \CRANpkg{mlr3tuning} for tuning of hyperparameters, \CRANpkg{mlr3tuningspaces} for established default tuning spaces.
}
}
\author{
bblodfon
}
\section{Super classes}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{\link[mlr3proba:LearnerSurv]{mlr3proba::LearnerSurv}} -> \code{LearnerSurvLearnerSurvBART}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-LearnerSurvLearnerSurvBART-new}{\code{LearnerSurvLearnerSurvBART$new()}}
\item \href{#method-LearnerSurvLearnerSurvBART-importance}{\code{LearnerSurvLearnerSurvBART$importance()}}
\item \href{#method-LearnerSurvLearnerSurvBART-clone}{\code{LearnerSurvLearnerSurvBART$clone()}}
}
}
\if{html}{\out{
<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerSurvLearnerSurvBART-new"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerSurvLearnerSurvBART-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerSurvLearnerSurvBART$new()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerSurvLearnerSurvBART-importance"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerSurvLearnerSurvBART-importance}{}}}
\subsection{Method \code{importance()}}{
Two types of importance scores are supported:
\enumerate{
\item The mean selection probability of each feature in the trees,
extracted from the slot \code{varprob.mean}.
If \code{sparse = FALSE} (default), this is a fixed constant.
Recommended to use this option when \code{sparse = TRUE}.
\item The observed count of each feature in the trees, extracted from the
slot \code{varcount.mean}.
This is the default importance scores.
}

In both cases, higher values signify more important variables.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerSurvLearnerSurvBART$importance(type = "count")}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{type}}{Can be either \code{count} or \code{prob}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Named \code{numeric()}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerSurvLearnerSurvBART-clone"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerSurvLearnerSurvBART-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerSurvLearnerSurvBART$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
