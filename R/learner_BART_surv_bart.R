#' @title Survival Bayesian Additive Regression Trees Learner
#' @author bblodfon
#' @name mlr_learners_surv.bart
#'
#' @description
#' Fits a Bayesian Additive Regression Trees (BART) learner to right-censored
#' survival data.
#' For prediction, we return the mean posterior estimates of the survival
#' function and the corresponding `crank` (expected mortality) using
#' [mlr3proba::.surv_return].
#' The full posterior estimates are currently stored in the
#' `learner$state$surv_test` slot, along with the number of test observations
#' `N`, number of unique times in the train set `K` and number of posterior
#' draws `M`.
#' See example for more details.
#'
#' Calls [BART::mc.surv.bart()] from \CRANpkg{BART}.
#'
#' @section Custom mlr3 defaults:
#' - `mc.cores` is initialized to 1 to avoid threading conflicts with \CRANpkg{future}.
#'
#' @section Initial parameter values:
#' - `quiet` allows to suppress messages generated by the wrapped C++ code. Is `TRUE` by default.
#'
#' @templateVar id surv.bart
#' @template learner
#'
#' @references
#' `r format_bib("sparapani2021nonparametric", "chipman2010bart")`
#'
#' @template seealso_learner
#' @examples
#' library(mlr3proba)
#' library(dplyr)
#' library(tidyr)
#' library(ggplot2)
#'
#' learner = lrn("surv.bart", nskip = 10, ndpost = 20, keepevery = 2)
#' task = tsk("lung")
#' task$missings() # has missing values
#'
#' # split to train and test sets
#' set.seed(42)
#' part = partition(task)
#'
#' # Train
#' learner$train(task, row_ids = part$train)
#'
#' # Importance: average number of times a feature has been used in the trees
#' learner$importance()
#'
#' # Test
#' p = learner$predict(task, row_ids = part$test)
#' p$score() # C-index
#'
#' # Mean survival probabilities for the first 3 patients at given time points
#' p$distr$survival(times = c(1,50,150))[,1:3]
#'
#' # number of posterior draws
#' M = learner$state$M
#' stopifnot(M == 20)
#' # number of test observations
#' N = learner$state$N
#' stopifnot(N == length(part$test))
#' # number of unique time points in the train set
#' K = learner$state$K
#' stopifnot(K == length(task$unique_times(rows = part$train)))
#' # the actual times are also available in the `$model` slot:
#' head(learner$model$times)
#'
#' # Full posterior prediction matrix
#' surv_test = learner$state$surv_test
#' stopifnot(all(dim(surv_test) == c(M, K * N)))
#'
#' # Posterior survival function estimates for the 1st test patient for all
#' # time points (from the train set) - see Sparapani (2021), pages 34-35
#' post_surv = surv_test[, 1:K]
#'
#' # For every time point, get the median survival estimate as well as
#' # the lower and upper bounds of the 95% quantile credible interval
#' surv_data = post_surv %>%
#'   as.data.frame() %>%
#'   `colnames<-` (learner$model$times) %>%
#'   summarise(across(everything(), list(
#'     median   = ~ median(.),
#'     low_qi   = ~ quantile(., 0.025),
#'     high_qi  = ~ quantile(., 0.975)
#'   ))) %>%
#'   pivot_longer(
#'     cols = everything(),
#'     names_to = c("times", ".value"),
#'     names_pattern = "(^[^_]+)_(.*)" # everything until the first underscore
#'   ) %>%
#'   mutate(times = as.numeric(times))
#' surv_data
#'
#' # Draw a survival curve for the first patient in the test set with
#' # uncertainty quantified
#' surv_data %>%
#'   ggplot(aes(x = times, y = median)) +
#'   geom_step(col = 'black') +
#'   xlab('Time (Days)') +
#'   ylab('Survival Probability') +
#'   geom_ribbon(aes(ymin = low_qi, ymax = high_qi), alpha = 0.3) +
#'   theme_bw()
#' @export
delayedAssign(
  "LearnerSurvLearnerSurvBART", R6Class("LearnerSurvLearnerSurvBART",
    inherit = mlr3proba::LearnerSurv,
    public = list(
      #' @description
      #' Creates a new instance of this [R6][R6::R6Class] class.
      initialize = function() {
        param_set = ps(
          K          = p_dbl(default = NULL, special_vals = list(NULL), lower = 1, tags = c("train", "predict")),
          events     = p_uty(default = NULL, tags = c("train", "predict")),
          ztimes     = p_uty(default = NULL, tags = c("train", "predict")),
          zdelta     = p_uty(default = NULL, tags = c("train", "predict")),
          sparse     = p_lgl(default = FALSE, tags = "train"),
          theta      = p_dbl(default = 0, tags = "train"),
          omega      = p_dbl(default = 1, tags = "train"),
          a          = p_dbl(default = 0.5, lower = 0.5, upper = 1, tags = "train"),
          b          = p_dbl(default = 1L, tags = "train"),
          augment    = p_lgl(default = FALSE, tags = "train"),
          rho        = p_dbl(default = NULL, special_vals = list(NULL), tags = "train"),
          usequants  = p_lgl(default = FALSE, tags = "train"),
          rm.const   = p_lgl(default = TRUE, tags = "train"),
          type       = p_fct(levels = c("pbart", "lbart"), default = "pbart", tags = "train"),
          ntype      = p_int(lower = 1, upper = 3, tags = "train"),
          k          = p_dbl(default = 2.0, lower = 0, tags = "train"),
          power      = p_dbl(default = 2.0, lower = 0, tags = "train"),
          base       = p_dbl(default = 0.95, lower = 0, upper = 1, tags = "train"),
          offset     = p_dbl(default = NULL, special_vals = list(NULL), tags = "train"),
          ntree      = p_int(default = 50L, lower = 1L, tags = "train"),
          numcut     = p_int(default = 100L, lower = 1L, tags = "train"),
          ndpost     = p_int(default = 1000L, lower = 1L, tags = "train"),
          nskip      = p_int(default = 250L, lower = 0L, tags = "train"),
          keepevery  = p_int(default = 10L, lower = 1L, tags = "train"),
          printevery = p_int(default = 100L, lower = 1L, tags = "train"),
          seed       = p_int(default = 99L, tags = "train"),
          mc.cores   = p_int(default = 2L, lower = 1L, tags = c("train", "predict")),
          nice       = p_int(default = 19L, lower = 0L, upper = 19L, tags = c("train", "predict")),
          openmp     = p_lgl(default = TRUE, tags = "predict"),
          quiet      = p_lgl(default = TRUE, tags = "predict")
        )

        # custom defaults
        param_set$values = list(mc.cores = 1, quiet = TRUE)

        super$initialize(
          id = "surv.bart",
          packages = "BART",
          feature_types = c("logical", "integer", "numeric", "factor"),
          predict_types = c("crank", "distr"),
          param_set = param_set,
          properties = c("importance", "missings"),
          man = "mlr3extralearners::mlr_learners_surv.bart",
          label = "Bayesian Additive Regression Trees"
        )
      },

      #' @description
      #' Two types of importance scores are supported:
      #' 1. The mean selection probability of each feature in the trees,
      #' extracted from the slot `varprob.mean`.
      #' If `sparse = FALSE` (default), this is a fixed constant.
      #' Recommended to use this option when `sparse = TRUE`.
      #' 2. The observed count of each feature in the trees, extracted from the
      #' slot `varcount.mean`.
      #' This is the default importance scores.
      #'
      #' In both cases, higher values signify more important variables.
      #'
      #' @param type Can be either `count` or `prob`.
      #' @return Named `numeric()`.
      importance = function(type = "count") {
assert_choice(type, c("prob", "count"))

        if (is.null(self$model)) {
          stopf("No model stored")
        }

        if (type == 'prob') {
          sort(self$model$varprob.mean[-1], decreasing = T)
        } else {
          sort(self$model$varcount.mean[-1], decreasing = T)
        }
      }
    ),

    private = list(
      .train = function(task) {
        pars = self$param_set$get_values(tags = "train")

        x_train = as.data.frame(task$data(cols = task$feature_names))
        times   = task$truth()[,1]
        delta   = task$truth()[,2] # delta => status

        # need these for predict
        self$state$train_data = list(x_train = x_train, times = times, delta = delta)

        invoke(
          BART::mc.surv.bart,
          x.train = x_train,
          times = times,
          delta = delta,
          .args = pars
        )
      },

      .predict = function(task) {
        # get parameters with tag "predict"
        pars = self$param_set$get_values(tags = "predict")

        # get newdata and ensure same ordering in train and predict
        x_test = as.data.frame(ordered_features(task, self))

        # transform data to be suitable for BART survival analysis (needs train data)
        train_data = self$state$train_data

        # subset parameters to use in `surv.pre.bart`
        pars_pre = pars[names(pars) %in% c('K', 'events', 'ztimes', 'zdelta')]

        trans_data = invoke(
          BART::surv.pre.bart,
          times   = train_data$times,
          delta   = train_data$delta,
          x.train = train_data$x_train,
          x.test  = x_test,
          .args   = pars_pre
        )

        # subset parameters to use in `predict`
        pars_pred = pars[names(pars) %in% c('mc.cores', 'nice')]

        pred_fun = function() {
          invoke(
            predict,
            self$model,
            newdata = trans_data$tx.test,
            .args = pars_pred
          )
        }

        # don't print C++ generated info during prediction
        if (pars$quiet) {
          utils::capture.output({
            pred = pred_fun()
          })
        } else {
          pred = pred_fun()
        }

        # Build survival matrix using the mean posterior estimates of the survival
        # function, see page 34-35 in Sparapani (2021) for more details

        # Number of test observations
        N = task$nrow
        self$state$N = N
        # Number of unique times
        K = pred$K
        self$state$K = K
        # Number of posterior draws
        self$state$M = nrow(pred$surv.test)

        # save the full posterior survival matrix
        self$state$surv_test = pred$surv.test

        # create mean posterior survival matrix (N obs x K times)
        surv = matrix(bart_p2$surv.test.mean, nrow = N, ncol = K, byrow = TRUE)

        mlr3proba::.surv_return(times = pred$times, surv = surv)
      }
    )
  )
)

.extralrns_dict$add("surv.bart", LearnerSurvLearnerSurvBART)
