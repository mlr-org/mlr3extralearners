# Classification Stacked Autoencoder Deep Neural Network Learner

Calls
[`deepnet::sae.dnn.train()`](https://rdrr.io/pkg/deepnet/man/sae.dnn.train.html)
from [deepnet](https://CRAN.R-project.org/package=deepnet).

## Initial parameter values

- `output` is set to `"softmax"` for probabilistic classification.

## Dictionary

This [Learner](https://mlr3.mlr-org.com/reference/Learner.html) can be
instantiated via
[lrn()](https://mlr3.mlr-org.com/reference/mlr_sugar.html):

    lrn("classif.saeDNN")

## Meta Information

- Task type: “classif”

- Predict Types: “response”, “prob”

- Feature Types: “integer”, “numeric”

- Required Packages: [mlr3](https://CRAN.R-project.org/package=mlr3),
  [deepnet](https://CRAN.R-project.org/package=deepnet)

## Parameters

|                    |           |         |                       |                  |
|--------------------|-----------|---------|-----------------------|------------------|
| Id                 | Type      | Default | Levels                | Range            |
| hidden             | untyped   | 10L     |                       | \-               |
| activationfun      | character | sigm    | sigm, linear, tanh    | \-               |
| learningrate       | numeric   | 0.8     |                       | \\\[0, \infty)\\ |
| momentum           | numeric   | 0.5     |                       | \\\[0, \infty)\\ |
| learningrate_scale | numeric   | 1       |                       | \\\[0, \infty)\\ |
| numepochs          | integer   | 3       |                       | \\\[1, \infty)\\ |
| batchsize          | integer   | 100     |                       | \\\[1, \infty)\\ |
| output             | character | \-      | sigm, linear, softmax | \-               |
| sae_output         | character | linear  | sigm, linear, softmax | \-               |
| hidden_dropout     | numeric   | 0       |                       | \\\[0, 1\]\\     |
| visible_dropout    | numeric   | 0       |                       | \\\[0, 1\]\\     |

## References

Rong, Xiao (2022). “deepnet: Deep Learning Toolkit in R.” *R package
version 0.2.1*.
[doi:10.32614/CRAN.package.deepnet](https://doi.org/10.32614/CRAN.package.deepnet)
, <https://CRAN.R-project.org/package=deepnet>.

## See also

- [Dictionary](https://mlr3misc.mlr-org.com/reference/Dictionary.html)
  of [Learners](https://mlr3.mlr-org.com/reference/Learner.html):
  [mlr3::mlr_learners](https://mlr3.mlr-org.com/reference/mlr_learners.html).

- `as.data.table(mlr_learners)` for a table of available
  [Learners](https://mlr3.mlr-org.com/reference/Learner.html) in the
  running session (depending on the loaded packages).

- Chapter in the [mlr3book](https://mlr3book.mlr-org.com/):
  <https://mlr3book.mlr-org.com/basics.html#learners>

- [mlr3learners](https://CRAN.R-project.org/package=mlr3learners) for a
  selection of recommended learners.

- [mlr3cluster](https://CRAN.R-project.org/package=mlr3cluster) for
  unsupervised clustering learners.

- [mlr3pipelines](https://CRAN.R-project.org/package=mlr3pipelines) to
  combine learners with pre- and postprocessing steps.

- [mlr3tuning](https://CRAN.R-project.org/package=mlr3tuning) for tuning
  of hyperparameters,
  [mlr3tuningspaces](https://CRAN.R-project.org/package=mlr3tuningspaces)
  for established default tuning spaces.

## Author

awinterstetter

## Super classes

[`mlr3::Learner`](https://mlr3.mlr-org.com/reference/Learner.html) -\>
[`mlr3::LearnerClassif`](https://mlr3.mlr-org.com/reference/LearnerClassif.html)
-\> `LearnerClassifSaeDNN`

## Methods

### Public methods

- [`LearnerClassifSaeDNN$new()`](#method-LearnerClassifSaeDNN-new)

- [`LearnerClassifSaeDNN$clone()`](#method-LearnerClassifSaeDNN-clone)

Inherited methods

- [`mlr3::Learner$base_learner()`](https://mlr3.mlr-org.com/reference/Learner.html#method-base_learner)
- [`mlr3::Learner$configure()`](https://mlr3.mlr-org.com/reference/Learner.html#method-configure)
- [`mlr3::Learner$encapsulate()`](https://mlr3.mlr-org.com/reference/Learner.html#method-encapsulate)
- [`mlr3::Learner$format()`](https://mlr3.mlr-org.com/reference/Learner.html#method-format)
- [`mlr3::Learner$help()`](https://mlr3.mlr-org.com/reference/Learner.html#method-help)
- [`mlr3::Learner$predict()`](https://mlr3.mlr-org.com/reference/Learner.html#method-predict)
- [`mlr3::Learner$predict_newdata()`](https://mlr3.mlr-org.com/reference/Learner.html#method-predict_newdata)
- [`mlr3::Learner$print()`](https://mlr3.mlr-org.com/reference/Learner.html#method-print)
- [`mlr3::Learner$reset()`](https://mlr3.mlr-org.com/reference/Learner.html#method-reset)
- [`mlr3::Learner$selected_features()`](https://mlr3.mlr-org.com/reference/Learner.html#method-selected_features)
- [`mlr3::Learner$train()`](https://mlr3.mlr-org.com/reference/Learner.html#method-train)
- [`mlr3::LearnerClassif$predict_newdata_fast()`](https://mlr3.mlr-org.com/reference/LearnerClassif.html#method-predict_newdata_fast)

------------------------------------------------------------------------

### Method `new()`

Creates a new instance of this
[R6](https://r6.r-lib.org/reference/R6Class.html) class.

#### Usage

    LearnerClassifSaeDNN$new()

------------------------------------------------------------------------

### Method `clone()`

The objects of this class are cloneable with this method.

#### Usage

    LearnerClassifSaeDNN$clone(deep = FALSE)

#### Arguments

- `deep`:

  Whether to make a deep clone.

## Examples

``` r
# Define the Learner
learner = lrn("classif.saeDNN")
print(learner)
#> 
#> ── <LearnerClassifSaeDNN> (classif.saeDNN): Deep neural network with weights ini
#> • Model: -
#> • Parameters: output=softmax
#> • Packages: mlr3 and deepnet
#> • Predict Types: [response] and prob
#> • Feature Types: integer and numeric
#> • Encapsulation: none (fallback: -)
#> • Properties: multiclass and twoclass
#> • Other settings: use_weights = 'error'

# Define a Task
task = tsk("sonar")

# Create train and test set
ids = partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)
#> begin to train sae ......
#> training layer 1 autoencoder ...
#> sae has been trained.
#> begin to train deep nn ......
#> deep nn has been trained.

print(learner$model)
#> $input_dim
#> [1] 60
#> 
#> $output_dim
#> [1] 2
#> 
#> $hidden
#> [1] 1
#> 
#> $size
#> [1] 60  1  2
#> 
#> $activationfun
#> [1] "sigm"
#> 
#> $learningrate
#> [1] 0.8
#> 
#> $momentum
#> [1] 0.5
#> 
#> $learningrate_scale
#> [1] 1
#> 
#> $hidden_dropout
#> [1] 0
#> 
#> $visible_dropout
#> [1] 0
#> 
#> $output
#> [1] "softmax"
#> 
#> $W
#> $W[[1]]
#>             V1         V10        V11        V12        V13        V14
#> [1,] 0.0342012 -0.06231865 -0.1302962 -0.2359656 -0.2372771 -0.1537936
#>             V15        V16        V17        V18        V19          V2
#> [1,] -0.1302679 -0.2097418 -0.1985358 -0.2439957 -0.3506563 -0.05315763
#>             V20        V21        V22        V23        V24        V25
#> [1,] -0.4020595 -0.3683294 -0.3205393 -0.3432467 -0.4062527 -0.4025905
#>             V26        V27        V28        V29         V3        V30
#> [1,] -0.4198617 -0.4565856 -0.4764152 -0.3724288 0.02584356 -0.4490515
#>             V31        V32        V33       V34        V35        V36
#> [1,] -0.3904161 -0.3375418 -0.3916032 -0.198543 -0.3335986 -0.2335295
#>             V37        V38        V39         V4        V40        V41
#> [1,] -0.1765125 -0.2750749 -0.2606311 0.05618745 -0.1989678 -0.1218022
#>             V42        V43        V44         V45         V46         V47
#> [1,] -0.1083505 -0.2572426 -0.1260236 -0.04119153 -0.08758329 -0.04999384
#>              V48        V49         V5         V50        V51        V52
#> [1,] -0.03736928 0.02613667 -0.1072483 0.007836214 0.08868072 0.03994709
#>              V53        V54         V55        V56        V57         V58
#> [1,] -0.03697102 0.08430604 0.009665929 0.02626598 0.07896297 -0.04554727
#>               V59         V6        V60         V7          V8         V9
#> [1,] 0.0007947722 0.03092634 0.09299218 0.01739761 -0.05859652 -0.1006682
#> 
#> $W[[2]]
#>             [,1]
#> [1,] -0.05638118
#> [2,] -0.02654168
#> 
#> 
#> $vW
#> $vW[[1]]
#>                V1          V10         V11           V12           V13
#> [1,] 1.758783e-07 7.574087e-08 6.49773e-07 -1.566574e-06 -3.061768e-06
#>                V14          V15           V16           V17           V18
#> [1,] -2.665786e-06 -2.55327e-06 -3.495922e-06 -5.799025e-06 -6.090799e-06
#>                V19           V2           V20          V21           V22
#> [1,] -3.432882e-06 1.411549e-07 -4.816997e-07 -9.25639e-07 -3.298244e-06
#>                V23           V24           V25           V26          V27
#> [1,] -7.552894e-06 -1.223238e-05 -1.611131e-05 -1.677139e-05 -1.67885e-05
#>                V28           V29            V3           V30           V31
#> [1,] -1.884266e-05 -1.894179e-05 -6.229571e-08 -1.387492e-05 -1.403658e-05
#>                V32           V33           V34           V35          V36
#> [1,] -8.792699e-06 -9.088903e-06 -1.103125e-05 -1.214231e-05 -1.28591e-05
#>                V37           V38           V39          V4           V40
#> [1,] -1.019376e-05 -5.920642e-06 -4.677508e-06 9.50223e-08 -6.287418e-06
#>                V41           V42           V43           V44          V45
#> [1,] -7.493662e-06 -6.638778e-06 -3.117702e-06 -1.388238e-06 1.816336e-06
#>               V46          V47          V48          V49            V5
#> [1,] 1.473926e-06 5.991391e-07 4.528278e-07 3.670071e-07 -2.463877e-07
#>               V50           V51           V52           V53           V54
#> [1,] 1.593389e-07 -1.107959e-07 -5.639626e-08 -2.450203e-07 -9.521436e-08
#>                V55           V56           V57           V58           V59
#> [1,] -1.877412e-07 -5.636146e-08 -1.385783e-07 -9.254097e-09 -9.656075e-08
#>                V6          V60            V7            V8           V9
#> [1,] -1.29601e-06 -1.19271e-07 -1.627068e-06 -1.701274e-07 7.919442e-07
#> 
#> $vW[[2]]
#>               [,1]
#> [1,]  0.0009452459
#> [2,] -0.0009452459
#> 
#> 
#> $B
#> $B[[1]]
#> [1] -0.5832822
#> 
#> $B[[2]]
#> [1]  0.02291893 -0.06021544
#> 
#> 
#> $vB
#> $vB[[1]]
#> [1] -2.469606e-05
#> 
#> $vB[[2]]
#> [1]  0.02552323 -0.02552323
#> 
#> 
#> $post
#> $post[[1]]
#>           V1    V10    V11    V12    V13    V14    V15    V16    V17    V18
#>  [1,] 0.0123 0.0835 0.0548 0.0847 0.2026 0.2557 0.1870 0.2032 0.1463 0.2849
#>  [2,] 0.1371 0.2067 0.4257 0.5484 0.7131 0.7003 0.6777 0.7939 0.9382 0.8925
#>  [3,] 0.0131 0.2079 0.2295 0.1990 0.1184 0.1891 0.2949 0.5343 0.6850 0.7923
#>  [4,] 0.0188 0.1806 0.2139 0.1523 0.1975 0.4844 0.7298 0.7807 0.7906 0.6122
#>  [5,] 0.0208 0.1093 0.1063 0.1179 0.1291 0.1591 0.1680 0.1918 0.1615 0.1647
#>  [6,] 0.0352 0.2912 0.2328 0.2237 0.2470 0.1560 0.3491 0.3308 0.2299 0.2203
#>  [7,] 0.0238 0.2048 0.2652 0.3100 0.2381 0.1918 0.1430 0.1735 0.1781 0.2852
#>  [8,] 0.0047 0.3469 0.3265 0.3263 0.2301 0.1253 0.2102 0.2401 0.1928 0.1673
#>  [9,] 0.0261 0.2013 0.2890 0.3650 0.3510 0.3495 0.4325 0.5398 0.6237 0.6876
#> [10,] 0.0090 0.1895 0.1896 0.2547 0.4073 0.2988 0.2901 0.5326 0.4022 0.1571
#> [11,] 0.0790 0.6609 0.5002 0.2583 0.1650 0.4347 0.4515 0.4579 0.3366 0.4000
#> [12,] 0.0530 0.0740 0.1610 0.2226 0.2703 0.3365 0.4266 0.4144 0.5655 0.6921
#> [13,] 0.0207 0.1234 0.1796 0.1787 0.1247 0.2577 0.3370 0.3990 0.1647 0.2266
#> [14,] 0.0209 0.3914 0.3504 0.3669 0.3943 0.3311 0.3331 0.3002 0.2324 0.1381
#> [15,] 0.0762 0.4459 0.4152 0.3952 0.4256 0.4135 0.4528 0.5326 0.7306 0.6193
#> [16,] 0.0228 0.2227 0.2621 0.3109 0.2859 0.3316 0.3755 0.4499 0.4765 0.6254
#> [17,] 0.0331 0.0193 0.0897 0.1734 0.1936 0.2803 0.3313 0.5020 0.6360 0.7096
#> [18,] 0.0968 0.5025 0.3488 0.1700 0.2076 0.3087 0.4224 0.5312 0.2436 0.1884
#> [19,] 0.0293 0.0751 0.0528 0.1209 0.1763 0.2039 0.2727 0.2321 0.2676 0.2934
#> [20,] 0.0025 0.1430 0.0994 0.2250 0.2444 0.3239 0.3039 0.2410 0.0367 0.1672
#> [21,] 0.0123 0.0475 0.1152 0.0520 0.1192 0.1943 0.1840 0.2077 0.1956 0.1630
#> [22,] 0.0257 0.0561 0.0891 0.0861 0.1531 0.1524 0.1849 0.2871 0.2009 0.2748
#> [23,] 0.0137 0.0874 0.1100 0.1084 0.1094 0.1023 0.0601 0.0906 0.1313 0.2758
#> [24,] 0.0428 0.0113 0.1255 0.2473 0.3011 0.3747 0.4520 0.5392 0.6588 0.7113
#> [25,] 0.0086 0.1185 0.0775 0.1101 0.1042 0.0853 0.0456 0.1304 0.2690 0.2947
#> [26,] 0.0130 0.1375 0.2026 0.2389 0.2112 0.1444 0.0742 0.1533 0.3052 0.4116
#> [27,] 0.1150 0.5378 0.3816 0.0991 0.0616 0.1795 0.3907 0.3602 0.3041 0.2428
#> [28,] 0.0388 0.2718 0.3645 0.3934 0.3843 0.4677 0.5364 0.4823 0.4835 0.5862
#> [29,] 0.0368 0.0506 0.0906 0.2545 0.1464 0.1272 0.1223 0.1669 0.1424 0.1285
#> [30,] 0.0201 0.1097 0.0841 0.0942 0.1204 0.0420 0.0031 0.0162 0.0624 0.2127
#> [31,] 0.0231 0.2461 0.2245 0.1520 0.1732 0.3099 0.4380 0.5595 0.6820 0.6164
#> [32,] 0.0201 0.1199 0.1742 0.1387 0.2042 0.2580 0.2616 0.2097 0.2532 0.3213
#> [33,] 0.0305 0.3127 0.2192 0.2621 0.2419 0.2179 0.1159 0.1237 0.0886 0.1755
#> [34,] 0.0298 0.0852 0.2476 0.3645 0.2777 0.2826 0.3237 0.4335 0.5638 0.4555
#> [35,] 0.0151 0.1205 0.0847 0.1518 0.2305 0.2793 0.3404 0.4527 0.6950 0.8807
#> [36,] 0.0139 0.1015 0.1261 0.0828 0.0493 0.0848 0.1514 0.1396 0.1066 0.1923
#> [37,] 0.0095 0.3745 0.4229 0.4499 0.5404 0.4303 0.3333 0.3496 0.3426 0.2851
#> [38,] 0.0721 0.0795 0.2534 0.3920 0.3375 0.1610 0.1889 0.3308 0.2282 0.2177
#> [39,] 0.0189 0.2522 0.2607 0.3710 0.3906 0.2672 0.2716 0.4183 0.6988 0.5733
#> [40,] 0.0100 0.2668 0.3376 0.3282 0.2432 0.1268 0.1278 0.4441 0.6795 0.7051
#>          V19     V2    V20    V21    V22    V23    V24    V25    V26    V27
#>  [1,] 0.5824 0.0309 0.7728 0.7852 0.8515 0.5312 0.3653 0.5973 0.8275 1.0000
#>  [2,] 0.9146 0.1226 0.7832 0.7960 0.7983 0.7716 0.6615 0.4860 0.5572 0.4697
#>  [3,] 0.8220 0.0201 0.7290 0.7352 0.7918 0.8057 0.4898 0.1934 0.2924 0.6255
#>  [4,] 0.4200 0.0370 0.2807 0.5148 0.7569 0.8596 1.0000 0.8457 0.6797 0.6971
#>  [5,] 0.1397 0.0186 0.1426 0.2429 0.2816 0.4290 0.6443 0.9061 1.0000 0.8087
#>  [6,] 0.2493 0.0116 0.4128 0.3158 0.6191 0.5854 0.3395 0.2561 0.5599 0.8145
#>  [7,] 0.5036 0.0318 0.6166 0.7616 0.8125 0.7793 0.8788 0.8813 0.9470 1.0000
#>  [8,] 0.1228 0.0059 0.0902 0.1557 0.3291 0.5268 0.6740 0.7906 0.8938 0.9395
#>  [9,] 0.7329 0.0266 0.8107 0.8396 0.8632 0.8747 0.9607 0.9716 0.9121 0.8576
#> [10,] 0.3024 0.0062 0.3907 0.3542 0.4438 0.6414 0.4601 0.6009 0.8690 0.8345
#> [11,] 0.5325 0.0707 0.9010 0.9939 0.3689 0.1012 0.0248 0.2318 0.3981 0.2259
#> [12,] 0.8547 0.0885 0.9234 0.9171 1.0000 0.9532 0.9101 0.8337 0.7053 0.6534
#> [13,] 0.3219 0.0535 0.5356 0.8159 1.0000 0.8701 0.6889 0.6299 0.5738 0.5707
#> [14,] 0.3450 0.0191 0.4428 0.4890 0.3677 0.4379 0.4864 0.6207 0.7256 0.6624
#> [15,] 0.2032 0.0666 0.4636 0.4148 0.4292 0.5730 0.5399 0.3161 0.2285 0.6995
#> [16,] 0.7304 0.0106 0.8702 0.9349 0.9614 0.9126 0.9443 1.0000 0.9455 0.8815
#> [17,] 0.8333 0.0423 0.8730 0.8073 0.7507 0.7526 0.7298 0.6177 0.4946 0.4531
#> [18,] 0.1908 0.0821 0.8321 1.0000 0.4076 0.0960 0.1928 0.2419 0.3790 0.2893
#> [19,] 0.3295 0.0378 0.4910 0.5402 0.6257 0.6826 0.7527 0.8504 0.8938 0.9928
#> [20,] 0.3038 0.0309 0.4069 0.3613 0.1994 0.4611 0.6849 0.7272 0.7152 0.7102
#> [21,] 0.1218 0.0022 0.1017 0.1354 0.3157 0.4645 0.5906 0.6776 0.8119 0.8594
#> [22,] 0.5017 0.0447 0.2172 0.4978 0.5265 0.3647 0.5768 0.5161 0.5715 0.4006
#> [23,] 0.3660 0.0297 0.5269 0.5810 0.6181 0.5875 0.4639 0.5424 0.7367 0.9089
#> [24,] 0.7602 0.0555 0.8672 0.8416 0.7974 0.8385 0.9317 0.8555 0.6162 0.4139
#> [25,] 0.3669 0.0215 0.4948 0.6275 0.8162 0.9237 0.8710 0.8052 0.8756 1.0000
#> [26,] 0.5466 0.0120 0.5933 0.6663 0.7333 0.7136 0.7014 0.7758 0.9137 0.9964
#> [27,] 0.4060 0.1163 0.8395 0.9777 0.4680 0.0610 0.2143 0.1348 0.2854 0.1617
#> [28,] 0.7579 0.0324 0.6997 0.6918 0.8633 0.9107 0.9346 0.7884 0.8585 0.9261
#> [29,] 0.1857 0.0403 0.1136 0.2069 0.0219 0.2400 0.2547 0.0240 0.1923 0.4753
#> [30,] 0.3436 0.0026 0.3813 0.3825 0.4764 0.6313 0.7523 0.8675 0.8788 0.7901
#> [31,] 0.6803 0.0315 0.8435 0.9921 1.0000 0.7983 0.5426 0.3952 0.5179 0.5650
#> [32,] 0.4327 0.0116 0.4760 0.5328 0.6057 0.6696 0.7476 0.8930 0.9405 1.0000
#> [33,] 0.1758 0.0363 0.1540 0.0512 0.1805 0.4039 0.5697 0.6577 0.7474 0.8543
#> [34,] 0.4348 0.0615 0.6433 0.3932 0.1989 0.3540 0.9165 0.9371 0.4620 0.2771
#> [35,] 0.9154 0.0320 0.7542 0.6736 0.7146 0.8335 0.7701 0.6993 0.6543 0.5040
#> [36,] 0.2991 0.0222 0.3247 0.3797 0.5658 0.7483 0.8757 0.9048 0.7511 0.6858
#> [37,] 0.4062 0.0308 0.6833 0.7650 0.6670 0.5703 0.5995 0.6484 0.8614 0.9819
#> [38,] 0.1853 0.1574 0.5167 0.5342 0.6298 0.8437 0.6756 0.5825 0.6141 0.8809
#> [39,] 0.2226 0.0308 0.2631 0.7473 0.7263 0.3393 0.2824 0.6053 0.5897 0.4967
#> [40,] 0.7966 0.0275 0.9401 0.9857 0.8193 0.5789 0.6394 0.7043 0.6875 0.4081
#>          V28    V29     V3    V30    V31    V32    V33    V34    V35    V36
#>  [1,] 0.8673 0.6301 0.0169 0.4591 0.3940 0.2576 0.2817 0.2641 0.2757 0.2698
#>  [2,] 0.5640 0.4517 0.1385 0.3369 0.2684 0.2339 0.3052 0.3016 0.2753 0.1041
#>  [3,] 0.8546 0.8966 0.0045 0.7821 0.5168 0.4840 0.4038 0.3411 0.2849 0.2353
#>  [4,] 0.5843 0.4772 0.0953 0.5201 0.4241 0.1592 0.1668 0.0588 0.3967 0.7147
#>  [5,] 0.6119 0.5260 0.0131 0.3677 0.2746 0.1020 0.1339 0.1582 0.1952 0.1787
#>  [6,] 0.6941 0.6985 0.0191 0.8660 0.5930 0.3664 0.6750 0.8697 0.7837 0.7552
#>  [7,] 0.9739 0.8446 0.0422 0.6151 0.4302 0.3165 0.2869 0.2017 0.1206 0.0271
#>  [8,] 0.9493 0.9040 0.0080 0.9151 0.8828 0.8086 0.7180 0.6720 0.6447 0.6879
#>  [9,] 0.8798 0.7720 0.0223 0.5711 0.4264 0.2860 0.3114 0.2066 0.1165 0.0185
#> [10,] 0.7669 0.5081 0.0253 0.4620 0.5380 0.5375 0.3844 0.3601 0.7402 0.7761
#> [11,] 0.5247 0.6898 0.0352 0.8316 0.4326 0.3741 0.5756 0.8043 0.7963 0.7174
#> [12,] 0.4483 0.2460 0.1997 0.2020 0.1446 0.0994 0.1510 0.2392 0.4434 0.5023
#> [13,] 0.5976 0.4301 0.0334 0.2058 0.1000 0.2247 0.2308 0.3977 0.3317 0.1726
#> [14,] 0.7689 0.7981 0.0411 0.8577 0.9273 0.7009 0.4851 0.3409 0.1406 0.1147
#> [15,] 1.0000 0.7262 0.0481 0.4724 0.5103 0.5459 0.2881 0.0981 0.1951 0.4181
#> [16,] 0.7520 0.7068 0.0130 0.5986 0.3857 0.2510 0.2162 0.0968 0.1323 0.1344
#> [17,] 0.4099 0.4540 0.0474 0.4124 0.3139 0.3194 0.3692 0.3776 0.4469 0.4777
#> [18,] 0.3451 0.3777 0.0629 0.5213 0.2316 0.3335 0.4781 0.6116 0.6705 0.7375
#> [19,] 0.9134 0.7080 0.0257 0.6318 0.6126 0.4638 0.2797 0.1721 0.1665 0.2561
#> [20,] 0.8516 1.0000 0.0171 0.7690 0.4841 0.3717 0.6096 0.5110 0.2586 0.0916
#> [21,] 0.9228 0.8387 0.0196 0.7238 0.6292 0.5181 0.4629 0.5255 0.5147 0.3929
#> [22,] 0.3650 0.6685 0.0388 0.8659 0.8052 0.4082 0.3379 0.5092 0.6776 0.7313
#> [23,] 1.0000 0.8247 0.0116 0.5441 0.3349 0.0877 0.1600 0.4169 0.6576 0.7390
#> [24,] 0.3269 0.3108 0.0708 0.2554 0.3367 0.4465 0.5000 0.5111 0.5194 0.4619
#> [25,] 0.9858 0.9427 0.0242 0.8114 0.6987 0.6810 0.6591 0.6954 0.7290 0.6680
#> [26,] 1.0000 0.8881 0.0436 0.6585 0.2707 0.1746 0.2709 0.4853 0.7184 0.8209
#> [27,] 0.2649 0.4565 0.0866 0.6502 0.2848 0.3296 0.5370 0.6627 0.8626 0.8547
#> [28,] 0.7080 0.5779 0.0688 0.5215 0.4505 0.3129 0.1448 0.1046 0.1820 0.1519
#> [29,] 0.7003 0.6825 0.0317 0.6443 0.7063 0.5373 0.6601 0.8708 0.9518 0.9605
#> [30,] 0.8357 0.9631 0.0138 0.9619 0.9236 0.8903 0.9708 0.9647 0.7892 0.5307
#> [31,] 0.3042 0.1881 0.0170 0.3960 0.2286 0.3544 0.4187 0.2398 0.1847 0.3760
#> [32,] 0.9785 0.8473 0.0123 0.7639 0.6701 0.4989 0.3718 0.2196 0.1416 0.2680
#> [33,] 0.9085 0.8668 0.0214 0.8892 0.9065 0.8522 0.7204 0.6200 0.6253 0.6848
#> [34,] 0.6613 0.8028 0.0650 0.4200 0.5192 0.6962 0.5792 0.8889 0.7863 0.7133
#> [35,] 0.4926 0.4992 0.0599 0.4161 0.1631 0.0404 0.0637 0.2962 0.3609 0.1866
#> [36,] 0.7043 0.5864 0.0089 0.3773 0.2206 0.2628 0.2672 0.2907 0.1982 0.2288
#> [37,] 0.9380 0.8435 0.0539 0.6074 0.5403 0.6890 0.5977 0.3244 0.0516 0.3157
#> [38,] 0.8375 0.3869 0.1112 0.5051 0.5455 0.4241 0.1534 0.4950 0.6983 0.7109
#> [39,] 0.8616 0.8339 0.0197 0.4084 0.2268 0.1745 0.0507 0.1588 0.3040 0.1369
#> [40,] 0.1811 0.2064 0.0190 0.3917 0.3791 0.2042 0.2227 0.3341 0.3984 0.5077
#>          V37    V38    V39     V4    V40    V41    V42    V43    V44    V45
#>  [1,] 0.3994 0.4576 0.3940 0.0313 0.2522 0.1782 0.1354 0.0516 0.0337 0.0894
#>  [2,] 0.1757 0.3156 0.3603 0.1484 0.2736 0.1301 0.2458 0.3404 0.1753 0.0679
#>  [3,] 0.2699 0.4442 0.4323 0.0217 0.3314 0.1195 0.1669 0.3702 0.3072 0.0945
#>  [4,] 0.7319 0.3509 0.0589 0.0824 0.2690 0.4200 0.3874 0.2440 0.2000 0.2307
#>  [5,] 0.0429 0.1096 0.1762 0.0211 0.2481 0.3150 0.2920 0.1902 0.0696 0.0758
#>  [6,] 0.5789 0.4713 0.1252 0.0469 0.6087 0.7322 0.5977 0.3431 0.1803 0.2378
#>  [7,] 0.0580 0.1262 0.1072 0.0399 0.1082 0.0360 0.1197 0.2061 0.2054 0.1878
#>  [8,] 0.6241 0.4936 0.4144 0.0554 0.4240 0.4546 0.4392 0.4323 0.4921 0.4710
#>  [9,] 0.1302 0.2480 0.1637 0.0749 0.1103 0.2144 0.2033 0.1887 0.1370 0.1376
#> [10,] 0.3858 0.0667 0.3684 0.0489 0.6114 0.3510 0.2312 0.2195 0.3051 0.1937
#> [11,] 0.7056 0.8148 0.7601 0.1660 0.6034 0.4554 0.4729 0.4478 0.3722 0.4693
#> [12,] 0.4441 0.4571 0.3927 0.2604 0.2900 0.3408 0.4990 0.3632 0.1387 0.1800
#> [13,] 0.1429 0.2168 0.1967 0.0818 0.2140 0.3674 0.2023 0.0778 0.0925 0.2388
#> [14,] 0.1433 0.1820 0.3605 0.0321 0.5529 0.5988 0.5077 0.5512 0.5027 0.7034
#> [15,] 0.4604 0.3217 0.2828 0.0394 0.2430 0.1979 0.2444 0.1847 0.0841 0.0692
#> [16,] 0.2250 0.3244 0.3939 0.0842 0.3806 0.3258 0.3654 0.2983 0.1779 0.1535
#> [17,] 0.4716 0.4664 0.3893 0.0818 0.4255 0.4064 0.3712 0.3863 0.2802 0.1283
#> [18,] 0.7356 0.7792 0.6788 0.0608 0.5259 0.2762 0.1545 0.2019 0.2231 0.4221
#> [19,] 0.2735 0.3209 0.2724 0.0062 0.1880 0.1552 0.2522 0.2121 0.1801 0.1473
#> [20,] 0.0947 0.2287 0.3480 0.0228 0.2095 0.1901 0.2941 0.2211 0.1524 0.0746
#> [21,] 0.1279 0.0411 0.0859 0.0206 0.1131 0.1306 0.1757 0.2648 0.1955 0.0656
#> [22,] 0.6062 0.7040 0.8849 0.0239 0.8979 0.7751 0.7247 0.7733 0.7762 0.6009
#> [23,] 0.7963 0.7493 0.6795 0.0082 0.4713 0.2355 0.1704 0.2728 0.4016 0.4125
#> [24,] 0.4234 0.4372 0.4277 0.0618 0.4433 0.3700 0.3324 0.2564 0.2527 0.2137
#> [25,] 0.5917 0.4899 0.3439 0.0445 0.2366 0.1716 0.1013 0.0766 0.0845 0.0260
#> [26,] 0.7536 0.6496 0.4708 0.0624 0.3482 0.3508 0.3181 0.3524 0.3659 0.2846
#> [27,] 0.7848 0.9016 0.8827 0.0358 0.6086 0.2810 0.0906 0.1177 0.2694 0.5214
#> [28,] 0.1017 0.1438 0.1986 0.0898 0.2039 0.2778 0.2879 0.1331 0.1140 0.1310
#> [29,] 0.7712 0.6772 0.6431 0.0293 0.6720 0.6035 0.5155 0.3802 0.2278 0.1522
#> [30,] 0.2718 0.1953 0.1374 0.0062 0.3105 0.3790 0.4105 0.3355 0.2998 0.2748
#> [31,] 0.4331 0.3626 0.2519 0.0226 0.1870 0.1046 0.2339 0.1991 0.1100 0.0684
#> [32,] 0.2630 0.3104 0.3392 0.0245 0.2123 0.1170 0.2655 0.2203 0.1541 0.1464
#> [33,] 0.7337 0.6281 0.5725 0.0227 0.6119 0.5597 0.4965 0.5027 0.5772 0.5907
#> [34,] 0.7615 0.4401 0.3009 0.0921 0.3163 0.2809 0.2898 0.0526 0.1867 0.1553
#> [35,] 0.0476 0.1497 0.2405 0.1050 0.1980 0.3175 0.2379 0.1716 0.1559 0.1556
#> [36,] 0.3186 0.2871 0.2921 0.0108 0.2806 0.2682 0.2112 0.1513 0.1789 0.1850
#> [37,] 0.3590 0.3881 0.5716 0.0411 0.4314 0.3051 0.4393 0.4302 0.4831 0.5084
#> [38,] 0.5647 0.4870 0.5515 0.1085 0.4433 0.5250 0.6075 0.5251 0.1359 0.4268
#> [39,] 0.1605 0.2061 0.0734 0.0622 0.0202 0.1638 0.1583 0.1830 0.1886 0.1008
#> [40,] 0.5534 0.3352 0.2723 0.0371 0.2278 0.2044 0.1986 0.0835 0.0908 0.1380
#>          V46    V47    V48    V49     V5    V50    V51    V52    V53    V54
#>  [1,] 0.0861 0.0872 0.0445 0.0134 0.0358 0.0217 0.0188 0.0133 0.0265 0.0224
#>  [2,] 0.1062 0.0643 0.0532 0.0531 0.1776 0.0272 0.0171 0.0118 0.0129 0.0344
#>  [3,] 0.1545 0.1394 0.0772 0.0615 0.0230 0.0230 0.0111 0.0168 0.0086 0.0045
#>  [4,] 0.1886 0.1960 0.1701 0.1366 0.0249 0.0398 0.0143 0.0093 0.0033 0.0113
#>  [5,] 0.0910 0.0441 0.0244 0.0265 0.0610 0.0095 0.0140 0.0074 0.0063 0.0081
#>  [6,] 0.3424 0.2303 0.0689 0.0216 0.0737 0.0469 0.0426 0.0346 0.0158 0.0154
#>  [7,] 0.2047 0.1716 0.1069 0.0477 0.0788 0.0170 0.0186 0.0096 0.0071 0.0084
#>  [8,] 0.3196 0.2241 0.1806 0.0990 0.0883 0.0251 0.0129 0.0095 0.0126 0.0069
#>  [9,] 0.0307 0.0373 0.0606 0.0399 0.1364 0.0169 0.0135 0.0222 0.0175 0.0127
#> [10,] 0.1570 0.0479 0.0538 0.0146 0.1197 0.0068 0.0187 0.0059 0.0095 0.0194
#> [11,] 0.3839 0.0768 0.1467 0.0777 0.1330 0.0469 0.0193 0.0298 0.0390 0.0294
#> [12,] 0.1299 0.0523 0.0817 0.0469 0.3225 0.0114 0.0299 0.0244 0.0199 0.0257
#> [13,] 0.3400 0.2594 0.1102 0.0911 0.0740 0.0462 0.0171 0.0033 0.0050 0.0190
#> [14,] 0.5904 0.4069 0.2761 0.1584 0.0698 0.0510 0.0054 0.0078 0.0201 0.0104
#> [15,] 0.0528 0.0357 0.0085 0.0230 0.0590 0.0046 0.0156 0.0031 0.0054 0.0105
#> [16,] 0.1199 0.0959 0.0765 0.0649 0.1117 0.0313 0.0185 0.0098 0.0178 0.0077
#> [17,] 0.1117 0.1303 0.0787 0.0436 0.0835 0.0224 0.0133 0.0078 0.0174 0.0176
#> [18,] 0.3067 0.1329 0.1349 0.1057 0.0617 0.0499 0.0206 0.0073 0.0081 0.0303
#> [19,] 0.0681 0.1091 0.0919 0.0397 0.0130 0.0093 0.0076 0.0065 0.0072 0.0108
#> [20,] 0.0606 0.0692 0.0446 0.0344 0.0434 0.0082 0.0108 0.0149 0.0077 0.0036
#> [21,] 0.0580 0.0319 0.0301 0.0272 0.0180 0.0074 0.0149 0.0125 0.0134 0.0026
#> [22,] 0.4514 0.3096 0.1859 0.0956 0.1315 0.0206 0.0206 0.0096 0.0153 0.0096
#> [23,] 0.3470 0.2739 0.1790 0.0922 0.0241 0.0276 0.0169 0.0081 0.0040 0.0025
#> [24,] 0.1789 0.1010 0.0528 0.0453 0.1215 0.0118 0.0009 0.0142 0.0179 0.0079
#> [25,] 0.0333 0.0205 0.0309 0.0101 0.0667 0.0095 0.0047 0.0072 0.0054 0.0022
#> [26,] 0.1714 0.0694 0.0303 0.0292 0.0428 0.0116 0.0024 0.0084 0.0100 0.0018
#> [27,] 0.4232 0.2340 0.1928 0.1092 0.0232 0.0507 0.0228 0.0099 0.0065 0.0085
#> [28,] 0.1433 0.0624 0.0100 0.0098 0.1267 0.0131 0.0152 0.0255 0.0071 0.0263
#> [29,] 0.0801 0.0804 0.0752 0.0566 0.0820 0.0175 0.0058 0.0091 0.0160 0.0160
#> [30,] 0.2024 0.1043 0.0453 0.0337 0.0133 0.0122 0.0072 0.0108 0.0070 0.0063
#> [31,] 0.0303 0.0674 0.0785 0.0455 0.0410 0.0246 0.0151 0.0125 0.0036 0.0123
#> [32,] 0.1044 0.1225 0.0745 0.0490 0.0547 0.0224 0.0032 0.0076 0.0045 0.0056
#> [33,] 0.4803 0.3877 0.2779 0.1427 0.0456 0.0424 0.0271 0.0200 0.0070 0.0070
#> [34,] 0.1633 0.1252 0.0748 0.0452 0.1615 0.0064 0.0154 0.0031 0.0153 0.0071
#> [35,] 0.0422 0.0493 0.0476 0.0219 0.1163 0.0059 0.0086 0.0061 0.0015 0.0084
#> [36,] 0.1717 0.0898 0.0656 0.0445 0.0215 0.0110 0.0024 0.0062 0.0072 0.0113
#> [37,] 0.1952 0.1539 0.2037 0.1054 0.0613 0.0251 0.0357 0.0181 0.0019 0.0102
#> [38,] 0.4442 0.2193 0.0900 0.1200 0.0666 0.0628 0.0234 0.0309 0.0127 0.0082
#> [39,] 0.0663 0.0183 0.0404 0.0108 0.0080 0.0143 0.0091 0.0038 0.0096 0.0142
#> [40,] 0.1948 0.1211 0.0843 0.0589 0.0416 0.0247 0.0118 0.0088 0.0104 0.0036
#>          V55    V56    V57    V58    V59     V6    V60     V7     V8     V9
#>  [1,] 0.0074 0.0118 0.0026 0.0092 0.0009 0.0102 0.0044 0.0182 0.0579 0.1122
#>  [2,] 0.0065 0.0067 0.0022 0.0079 0.0146 0.1428 0.0051 0.1773 0.2161 0.1630
#>  [3,] 0.0062 0.0065 0.0030 0.0066 0.0029 0.0481 0.0053 0.0742 0.0333 0.1369
#>  [4,] 0.0030 0.0057 0.0090 0.0057 0.0068 0.0488 0.0024 0.1424 0.1972 0.1873
#>  [5,] 0.0087 0.0044 0.0028 0.0019 0.0049 0.0613 0.0023 0.0612 0.0506 0.0989
#>  [6,] 0.0109 0.0048 0.0095 0.0015 0.0073 0.1185 0.0067 0.1683 0.1541 0.1466
#>  [7,] 0.0038 0.0026 0.0028 0.0013 0.0035 0.0766 0.0060 0.0881 0.1143 0.1594
#>  [8,] 0.0039 0.0068 0.0060 0.0045 0.0002 0.1278 0.0029 0.1674 0.1373 0.2922
#>  [9,] 0.0022 0.0124 0.0054 0.0021 0.0028 0.1513 0.0023 0.1316 0.1654 0.1864
#> [10,] 0.0080 0.0152 0.0158 0.0053 0.0189 0.1589 0.0102 0.1392 0.0987 0.0955
#> [11,] 0.0175 0.0249 0.0141 0.0073 0.0025 0.0226 0.0101 0.0771 0.2678 0.5664
#> [12,] 0.0082 0.0151 0.0171 0.0146 0.0134 0.2247 0.0056 0.0617 0.2287 0.0950
#> [13,] 0.0103 0.0121 0.0042 0.0090 0.0070 0.0324 0.0099 0.0918 0.1070 0.1553
#> [14,] 0.0039 0.0031 0.0062 0.0087 0.0070 0.1579 0.0042 0.1438 0.1402 0.3048
#> [15,] 0.0110 0.0015 0.0072 0.0048 0.0107 0.0649 0.0094 0.1209 0.2467 0.3564
#> [16,] 0.0074 0.0095 0.0055 0.0045 0.0063 0.1506 0.0039 0.1776 0.0997 0.1428
#> [17,] 0.0038 0.0129 0.0066 0.0044 0.0134 0.0756 0.0092 0.0374 0.0961 0.0548
#> [18,] 0.0190 0.0212 0.0126 0.0201 0.0210 0.1207 0.0041 0.0944 0.4223 0.5744
#> [19,] 0.0051 0.0102 0.0041 0.0055 0.0050 0.0612 0.0087 0.0895 0.1107 0.0973
#> [20,] 0.0114 0.0085 0.0101 0.0016 0.0028 0.1224 0.0014 0.1947 0.1661 0.1368
#> [21,] 0.0038 0.0018 0.0113 0.0058 0.0047 0.0492 0.0071 0.0033 0.0398 0.0791
#> [22,] 0.0131 0.0198 0.0025 0.0199 0.0255 0.1323 0.0180 0.1608 0.2145 0.0847
#> [23,] 0.0036 0.0058 0.0067 0.0035 0.0043 0.0253 0.0033 0.0279 0.0130 0.0489
#> [24,] 0.0060 0.0131 0.0089 0.0084 0.0113 0.1524 0.0049 0.1543 0.0391 0.0610
#> [25,] 0.0016 0.0029 0.0058 0.0050 0.0024 0.0771 0.0030 0.0499 0.0906 0.1229
#> [26,] 0.0035 0.0058 0.0011 0.0009 0.0033 0.0349 0.0026 0.0384 0.0446 0.1318
#> [27,] 0.0166 0.0110 0.0190 0.0141 0.0068 0.1267 0.0086 0.2417 0.2661 0.4346
#> [28,] 0.0079 0.0111 0.0107 0.0068 0.0097 0.1515 0.0067 0.2134 0.2613 0.2832
#> [29,] 0.0081 0.0070 0.0135 0.0067 0.0078 0.1342 0.0068 0.1161 0.0663 0.0155
#> [30,] 0.0030 0.0011 0.0007 0.0024 0.0057 0.0151 0.0044 0.0541 0.0210 0.0505
#> [31,] 0.0043 0.0114 0.0052 0.0091 0.0008 0.0116 0.0092 0.0223 0.0805 0.2365
#> [32,] 0.0075 0.0037 0.0045 0.0029 0.0008 0.0208 0.0018 0.0891 0.0836 0.1335
#> [33,] 0.0086 0.0089 0.0074 0.0042 0.0055 0.0665 0.0021 0.0939 0.0972 0.2535
#> [34,] 0.0212 0.0076 0.0152 0.0049 0.0200 0.2294 0.0073 0.2176 0.2033 0.1459
#> [35,] 0.0128 0.0054 0.0011 0.0019 0.0023 0.1734 0.0062 0.1679 0.1119 0.0889
#> [36,] 0.0012 0.0022 0.0025 0.0059 0.0039 0.0136 0.0048 0.0659 0.0954 0.0786
#> [37,] 0.0133 0.0040 0.0042 0.0030 0.0031 0.1039 0.0033 0.1016 0.1394 0.2592
#> [38,] 0.0281 0.0117 0.0092 0.0147 0.0157 0.1800 0.0129 0.1108 0.2794 0.1408
#> [39,] 0.0190 0.0140 0.0099 0.0092 0.0052 0.0789 0.0075 0.1440 0.1451 0.1789
#> [40,] 0.0088 0.0047 0.0117 0.0020 0.0091 0.0201 0.0058 0.0314 0.0651 0.1896
#> 
#> $post[[2]]
#>              [,1]
#>  [1,] 0.005671365
#>  [2,] 0.003661113
#>  [3,] 0.003456577
#>  [4,] 0.004062007
#>  [5,] 0.019039035
#>  [6,] 0.003967013
#>  [7,] 0.003964549
#>  [8,] 0.002037493
#>  [9,] 0.002271900
#> [10,] 0.004824519
#> [11,] 0.003414471
#> [12,] 0.003558603
#> [13,] 0.010483277
#> [14,] 0.003664495
#> [15,] 0.006759459
#> [16,] 0.002023043
#> [17,] 0.004122126
#> [18,] 0.008260151
#> [19,] 0.004650302
#> [20,] 0.006794332
#> [21,] 0.008778167
#> [22,] 0.003482454
#> [23,] 0.004249785
#> [24,] 0.003133572
#> [25,] 0.001645411
#> [26,] 0.002016556
#> [27,] 0.007167676
#> [28,] 0.003177062
#> [29,] 0.008842013
#> [30,] 0.002115417
#> [31,] 0.006772155
#> [32,] 0.003348025
#> [33,] 0.002444709
#> [34,] 0.003650443
#> [35,] 0.007024202
#> [36,] 0.010616264
#> [37,] 0.001933993
#> [38,] 0.003467037
#> [39,] 0.012394102
#> [40,] 0.005976267
#> 
#> $post[[3]]
#>            [,1]      [,2]
#>  [1,] 0.5334555 0.4665445
#>  [2,] 0.5334695 0.4665305
#>  [3,] 0.5334709 0.4665291
#>  [4,] 0.5334667 0.4665333
#>  [5,] 0.5333625 0.4666375
#>  [6,] 0.5334674 0.4665326
#>  [7,] 0.5334674 0.4665326
#>  [8,] 0.5334808 0.4665192
#>  [9,] 0.5334792 0.4665208
#> [10,] 0.5334614 0.4665386
#> [11,] 0.5334712 0.4665288
#> [12,] 0.5334702 0.4665298
#> [13,] 0.5334220 0.4665780
#> [14,] 0.5334695 0.4665305
#> [15,] 0.5334479 0.4665521
#> [16,] 0.5334809 0.4665191
#> [17,] 0.5334663 0.4665337
#> [18,] 0.5334375 0.4665625
#> [19,] 0.5334626 0.4665374
#> [20,] 0.5334477 0.4665523
#> [21,] 0.5334339 0.4665661
#> [22,] 0.5334707 0.4665293
#> [23,] 0.5334654 0.4665346
#> [24,] 0.5334732 0.4665268
#> [25,] 0.5334835 0.4665165
#> [26,] 0.5334809 0.4665191
#> [27,] 0.5334451 0.4665549
#> [28,] 0.5334729 0.4665271
#> [29,] 0.5334335 0.4665665
#> [30,] 0.5334803 0.4665197
#> [31,] 0.5334479 0.4665521
#> [32,] 0.5334717 0.4665283
#> [33,] 0.5334780 0.4665220
#> [34,] 0.5334696 0.4665304
#> [35,] 0.5334461 0.4665539
#> [36,] 0.5334211 0.4665789
#> [37,] 0.5334815 0.4665185
#> [38,] 0.5334709 0.4665291
#> [39,] 0.5334088 0.4665912
#> [40,] 0.5334534 0.4665466
#> 
#> 
#> $pre
#> $pre[[1]]
#> NULL
#> 
#> $pre[[2]]
#>            [,1]
#>  [1,] -5.166638
#>  [2,] -5.606320
#>  [3,] -5.664014
#>  [4,] -5.502008
#>  [5,] -3.942041
#>  [6,] -5.525767
#>  [7,] -5.526391
#>  [8,] -6.193995
#>  [9,] -6.084864
#> [10,] -5.329208
#> [11,] -5.676312
#> [12,] -5.634822
#> [13,] -4.547435
#> [14,] -5.605394
#> [15,] -4.990030
#> [16,] -6.201127
#> [17,] -5.487255
#> [18,] -4.788018
#> [19,] -5.366162
#> [20,] -4.984849
#> [21,] -4.726671
#> [22,] -5.656530
#> [23,] -5.456628
#> [24,] -5.762443
#> [25,] -6.408118
#> [26,] -6.204346
#> [27,] -4.930980
#> [28,] -5.748616
#> [29,] -4.719359
#> [30,] -6.156386
#> [31,] -4.988141
#> [32,] -5.696031
#> [33,] -6.011381
#> [34,] -5.609250
#> [35,] -4.951345
#> [36,] -4.534695
#> [37,] -6.246233
#> [38,] -5.660982
#> [39,] -4.378063
#> [40,] -5.113965
#> 
#> $pre[[3]]
#>             [,1]        [,2]
#>  [1,] 0.04812776 -0.08589455
#>  [2,] 0.04823920 -0.08583930
#>  [3,] 0.04825054 -0.08583368
#>  [4,] 0.04821698 -0.08585032
#>  [5,] 0.04738671 -0.08626199
#>  [6,] 0.04822224 -0.08584771
#>  [7,] 0.04822238 -0.08584764
#>  [8,] 0.04832921 -0.08579467
#>  [9,] 0.04831621 -0.08580111
#> [10,] 0.04817471 -0.08587128
#> [11,] 0.04825288 -0.08583252
#> [12,] 0.04824489 -0.08583648
#> [13,] 0.04786101 -0.08602682
#> [14,] 0.04823902 -0.08583939
#> [15,] 0.04806744 -0.08592446
#> [16,] 0.04833001 -0.08579427
#> [17,] 0.04821365 -0.08585197
#> [18,] 0.04798425 -0.08596571
#> [19,] 0.04818437 -0.08586649
#> [20,] 0.04806551 -0.08592542
#> [21,] 0.04795553 -0.08597995
#> [22,] 0.04824911 -0.08583439
#> [23,] 0.04820657 -0.08585548
#> [24,] 0.04826845 -0.08582480
#> [25,] 0.04835094 -0.08578389
#> [26,] 0.04833037 -0.08579409
#> [27,] 0.04804481 -0.08593568
#> [28,] 0.04826604 -0.08582599
#> [29,] 0.04795199 -0.08598171
#> [30,] 0.04832489 -0.08579681
#> [31,] 0.04806674 -0.08592481
#> [32,] 0.04825656 -0.08583069
#> [33,] 0.04830664 -0.08580586
#> [34,] 0.04823979 -0.08583901
#> [35,] 0.04805277 -0.08593174
#> [36,] 0.04785364 -0.08603047
#> [37,] 0.04833495 -0.08579183
#> [38,] 0.04824996 -0.08583396
#> [39,] 0.04775508 -0.08607934
#> [40,] 0.04811086 -0.08590293
#> 
#> 
#> $e
#>             [,1]       [,2]
#>  [1,] -0.5334555  0.5334555
#>  [2,]  0.4665305 -0.4665305
#>  [3,]  0.4665291 -0.4665291
#>  [4,] -0.5334667  0.5334667
#>  [5,] -0.5333625  0.5333625
#>  [6,] -0.5334674  0.5334674
#>  [7,]  0.4665326 -0.4665326
#>  [8,]  0.4665192 -0.4665192
#>  [9,]  0.4665208 -0.4665208
#> [10,] -0.5334614  0.5334614
#> [11,]  0.4665288 -0.4665288
#> [12,]  0.4665298 -0.4665298
#> [13,]  0.4665780 -0.4665780
#> [14,]  0.4665305 -0.4665305
#> [15,] -0.5334479  0.5334479
#> [16,]  0.4665191 -0.4665191
#> [17,]  0.4665337 -0.4665337
#> [18,]  0.4665625 -0.4665625
#> [19,] -0.5334626  0.5334626
#> [20,] -0.5334477  0.5334477
#> [21,] -0.5334339  0.5334339
#> [22,] -0.5334707  0.5334707
#> [23,]  0.4665346 -0.4665346
#> [24,]  0.4665268 -0.4665268
#> [25,] -0.5334835  0.5334835
#> [26,]  0.4665191 -0.4665191
#> [27,]  0.4665549 -0.4665549
#> [28,]  0.4665271 -0.4665271
#> [29,] -0.5334335  0.5334335
#> [30,] -0.5334803  0.5334803
#> [31,]  0.4665521 -0.4665521
#> [32,] -0.5334717  0.5334717
#> [33,]  0.4665220 -0.4665220
#> [34,] -0.5334696  0.5334696
#> [35,] -0.5334461  0.5334461
#> [36,] -0.5334211  0.5334211
#> [37,]  0.4665185 -0.4665185
#> [38,]  0.4665291 -0.4665291
#> [39,] -0.5334088  0.5334088
#> [40,] -0.5334534  0.5334534
#> 
#> $L
#> [1] 0.6913352 0.6801830 0.6778890 0.7307237 0.6860465 0.6920232
#> 


# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()
#> classif.ce 
#>  0.5072464 
```
