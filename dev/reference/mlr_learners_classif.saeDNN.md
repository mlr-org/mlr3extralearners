# Classification Stacked Autoencoder Deep Neural Network Learner

Calls
[`deepnet::sae.dnn.train()`](https://rdrr.io/pkg/deepnet/man/sae.dnn.train.html)
from [deepnet](https://CRAN.R-project.org/package=deepnet).

## Initial parameter values

- `output` is set to `"softmax"` for probabilistic classification.

## Dictionary

This [Learner](https://mlr3.mlr-org.com/reference/Learner.html) can be
instantiated via
[lrn()](https://mlr3.mlr-org.com/reference/mlr_sugar.html):

    lrn("classif.saeDNN")

## Meta Information

- Task type: “classif”

- Predict Types: “response”, “prob”

- Feature Types: “integer”, “numeric”

- Required Packages: [mlr3](https://CRAN.R-project.org/package=mlr3),
  [deepnet](https://CRAN.R-project.org/package=deepnet)

## Parameters

|                    |           |         |                       |                  |
|--------------------|-----------|---------|-----------------------|------------------|
| Id                 | Type      | Default | Levels                | Range            |
| hidden             | untyped   | 10L     |                       | \-               |
| activationfun      | character | sigm    | sigm, linear, tanh    | \-               |
| learningrate       | numeric   | 0.8     |                       | \\\[0, \infty)\\ |
| momentum           | numeric   | 0.5     |                       | \\\[0, \infty)\\ |
| learningrate_scale | numeric   | 1       |                       | \\\[0, \infty)\\ |
| numepochs          | integer   | 3       |                       | \\\[1, \infty)\\ |
| batchsize          | integer   | 100     |                       | \\\[1, \infty)\\ |
| output             | character | \-      | sigm, linear, softmax | \-               |
| sae_output         | character | linear  | sigm, linear, softmax | \-               |
| hidden_dropout     | numeric   | 0       |                       | \\\[0, 1\]\\     |
| visible_dropout    | numeric   | 0       |                       | \\\[0, 1\]\\     |

## References

Rong, Xiao (2022). “deepnet: Deep Learning Toolkit in R.” *R package
version 0.2.1*.
[doi:10.32614/CRAN.package.deepnet](https://doi.org/10.32614/CRAN.package.deepnet)
, <https://CRAN.R-project.org/package=deepnet>.

## See also

- [Dictionary](https://mlr3misc.mlr-org.com/reference/Dictionary.html)
  of [Learners](https://mlr3.mlr-org.com/reference/Learner.html):
  [mlr3::mlr_learners](https://mlr3.mlr-org.com/reference/mlr_learners.html).

- `as.data.table(mlr_learners)` for a table of available
  [Learners](https://mlr3.mlr-org.com/reference/Learner.html) in the
  running session (depending on the loaded packages).

- Chapter in the [mlr3book](https://mlr3book.mlr-org.com/):
  <https://mlr3book.mlr-org.com/basics.html#learners>

- [mlr3learners](https://CRAN.R-project.org/package=mlr3learners) for a
  selection of recommended learners.

- [mlr3cluster](https://CRAN.R-project.org/package=mlr3cluster) for
  unsupervised clustering learners.

- [mlr3pipelines](https://CRAN.R-project.org/package=mlr3pipelines) to
  combine learners with pre- and postprocessing steps.

- [mlr3tuning](https://CRAN.R-project.org/package=mlr3tuning) for tuning
  of hyperparameters,
  [mlr3tuningspaces](https://CRAN.R-project.org/package=mlr3tuningspaces)
  for established default tuning spaces.

## Author

awinterstetter

## Super classes

[`mlr3::Learner`](https://mlr3.mlr-org.com/reference/Learner.html) -\>
[`mlr3::LearnerClassif`](https://mlr3.mlr-org.com/reference/LearnerClassif.html)
-\> `LearnerClassifSaeDNN`

## Methods

### Public methods

- [`LearnerClassifSaeDNN$new()`](#method-LearnerClassifSaeDNN-new)

- [`LearnerClassifSaeDNN$clone()`](#method-LearnerClassifSaeDNN-clone)

Inherited methods

- [`mlr3::Learner$base_learner()`](https://mlr3.mlr-org.com/reference/Learner.html#method-base_learner)
- [`mlr3::Learner$configure()`](https://mlr3.mlr-org.com/reference/Learner.html#method-configure)
- [`mlr3::Learner$encapsulate()`](https://mlr3.mlr-org.com/reference/Learner.html#method-encapsulate)
- [`mlr3::Learner$format()`](https://mlr3.mlr-org.com/reference/Learner.html#method-format)
- [`mlr3::Learner$help()`](https://mlr3.mlr-org.com/reference/Learner.html#method-help)
- [`mlr3::Learner$predict()`](https://mlr3.mlr-org.com/reference/Learner.html#method-predict)
- [`mlr3::Learner$predict_newdata()`](https://mlr3.mlr-org.com/reference/Learner.html#method-predict_newdata)
- [`mlr3::Learner$print()`](https://mlr3.mlr-org.com/reference/Learner.html#method-print)
- [`mlr3::Learner$reset()`](https://mlr3.mlr-org.com/reference/Learner.html#method-reset)
- [`mlr3::Learner$selected_features()`](https://mlr3.mlr-org.com/reference/Learner.html#method-selected_features)
- [`mlr3::Learner$train()`](https://mlr3.mlr-org.com/reference/Learner.html#method-train)
- [`mlr3::LearnerClassif$predict_newdata_fast()`](https://mlr3.mlr-org.com/reference/LearnerClassif.html#method-predict_newdata_fast)

------------------------------------------------------------------------

### Method `new()`

Creates a new instance of this
[R6](https://r6.r-lib.org/reference/R6Class.html) class.

#### Usage

    LearnerClassifSaeDNN$new()

------------------------------------------------------------------------

### Method `clone()`

The objects of this class are cloneable with this method.

#### Usage

    LearnerClassifSaeDNN$clone(deep = FALSE)

#### Arguments

- `deep`:

  Whether to make a deep clone.

## Examples

``` r
# Define the Learner
learner = lrn("classif.saeDNN")
print(learner)
#> 
#> ── <LearnerClassifSaeDNN> (classif.saeDNN): Deep neural network with weights ini
#> • Model: -
#> • Parameters: output=softmax
#> • Packages: mlr3 and deepnet
#> • Predict Types: [response] and prob
#> • Feature Types: integer and numeric
#> • Encapsulation: none (fallback: -)
#> • Properties: multiclass and twoclass
#> • Other settings: use_weights = 'error'

# Define a Task
task = tsk("sonar")

# Create train and test set
ids = partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)
#> begin to train sae ......
#> training layer 1 autoencoder ...
#> sae has been trained.
#> begin to train deep nn ......
#> deep nn has been trained.

print(learner$model)
#> $input_dim
#> [1] 60
#> 
#> $output_dim
#> [1] 2
#> 
#> $hidden
#> [1] 1
#> 
#> $size
#> [1] 60  1  2
#> 
#> $activationfun
#> [1] "sigm"
#> 
#> $learningrate
#> [1] 0.8
#> 
#> $momentum
#> [1] 0.5
#> 
#> $learningrate_scale
#> [1] 1
#> 
#> $hidden_dropout
#> [1] 0
#> 
#> $visible_dropout
#> [1] 0
#> 
#> $output
#> [1] "softmax"
#> 
#> $W
#> $W[[1]]
#>               V1       V10       V11      V12        V13        V14        V15
#> [1,] -0.06295424 -0.166683 -0.195614 -0.18797 -0.2344944 -0.1318421 -0.3213551
#>             V16        V17        V18        V19          V2        V20
#> [1,] -0.3055383 -0.2034869 -0.2853326 -0.3247563 -0.01042357 -0.3183537
#>            V21        V22        V23        V24        V25        V26
#> [1,] -0.369773 -0.3770488 -0.3611752 -0.3670288 -0.3364131 -0.3335864
#>             V27        V28        V29          V3        V30        V31
#> [1,] -0.4512577 -0.4886179 -0.3691025 -0.01735249 -0.4383446 -0.3829263
#>             V32        V33        V34        V35        V36        V37
#> [1,] -0.3073244 -0.2182403 -0.2647459 -0.2084603 -0.1423051 -0.1883037
#>             V38        V39          V4        V40        V41       V42
#> [1,] -0.2486027 -0.1315762 0.008043172 -0.2926369 -0.1830786 -0.110412
#>             V43         V44        V45         V46         V47         V48
#> [1,] -0.2372402 -0.04247402 -0.1701304 -0.06274349 -0.01549283 -0.06068427
#>             V49          V5         V50          V51         V52        V53
#> [1,] 0.02885196 -0.08411325 -0.08362511 -0.007831268 -0.08813942 0.05391613
#>             V54        V55        V56        V57         V58        V59
#> [1,] 0.02008526 0.04823232 0.03414541 -0.0722642 -0.03753243 0.02654216
#>             V6         V60          V7          V8         V9
#> [1,] -0.074346 -0.03690183 -0.04355471 -0.09459307 -0.1274336
#> 
#> $W[[2]]
#>             [,1]
#> [1,] -0.05805898
#> [2,] -0.02148030
#> 
#> 
#> $vW
#> $vW[[1]]
#>                V1          V10          V11          V12          V13
#> [1,] 6.650076e-07 3.023074e-06 5.696416e-06 4.262642e-06 3.187178e-06
#>               V14          V15           V16           V17           V18
#> [1,] 1.176871e-06 1.031927e-07 -1.638904e-06 -4.914514e-06 -6.835324e-06
#>                V19           V2           V20           V21           V22
#> [1,] -2.928906e-06 6.882627e-07 -1.905886e-06 -3.936013e-06 -6.009407e-06
#>                V23           V24           V25           V26           V27
#> [1,] -8.469203e-06 -1.108369e-05 -1.367493e-05 -1.353077e-05 -1.091423e-05
#>                V28           V29           V3           V30           V31
#> [1,] -1.366781e-05 -1.808404e-05 3.902952e-07 -1.734814e-05 -1.648379e-05
#>                V32           V33           V34           V35           V36
#> [1,] -1.283398e-05 -1.541042e-05 -1.782467e-05 -2.042903e-05 -2.571408e-05
#>                V37           V38           V39           V4           V40
#> [1,] -2.343211e-05 -1.387049e-05 -9.745124e-06 9.868999e-07 -1.218054e-05
#>                V41           V42           V43           V44          V45
#> [1,] -1.109527e-05 -6.262782e-06 -2.354084e-06 -1.741631e-06 6.896043e-07
#>               V46          V47          V48          V49           V5
#> [1,] 1.788392e-06 1.052512e-06 1.065495e-06 7.038023e-07 5.589614e-07
#>                V50          V51          V52           V53           V54
#> [1,] -1.393549e-07 3.109435e-07 4.047693e-07 -1.991886e-07 -1.519386e-07
#>                V55          V56           V57           V58          V59
#> [1,] -1.063855e-07 -8.44733e-08 -2.197835e-07 -6.240412e-08 -3.80356e-08
#>                 V6           V60            V7           V8           V9
#> [1,] -1.554752e-06 -8.201741e-08 -1.086923e-06 2.603053e-07 3.006942e-06
#> 
#> $vW[[2]]
#>             [,1]
#> [1,]  0.00077322
#> [2,] -0.00077322
#> 
#> 
#> $B
#> $B[[1]]
#> [1] -0.5545973
#> 
#> $B[[2]]
#> [1]  0.12858434 -0.02769787
#> 
#> 
#> $vB
#> $vB[[1]]
#> [1] -2.646488e-05
#> 
#> $vB[[2]]
#> [1] -0.00731658  0.00731658
#> 
#> 
#> $post
#> $post[[1]]
#>           V1    V10    V11    V12    V13    V14    V15    V16    V17    V18
#>  [1,] 0.0249 0.2531 0.2855 0.2961 0.3341 0.4287 0.5205 0.6087 0.7236 0.7577
#>  [2,] 0.0587 0.2352 0.3208 0.4257 0.5201 0.4914 0.5950 0.7221 0.9039 0.9111
#>  [3,] 0.0225 0.1452 0.1442 0.0948 0.0618 0.1641 0.0708 0.0844 0.2590 0.2679
#>  [4,] 0.0715 0.4186 0.4867 0.5249 0.5959 0.6855 0.8573 0.9718 0.8693 0.8711
#>  [5,] 0.1371 0.2067 0.4257 0.5484 0.7131 0.7003 0.6777 0.7939 0.9382 0.8925
#>  [6,] 0.0293 0.0860 0.0414 0.0472 0.0835 0.0938 0.1466 0.0809 0.1179 0.2179
#>  [7,] 0.0414 0.1975 0.2309 0.3025 0.3938 0.5050 0.5872 0.6610 0.7417 0.8006
#>  [8,] 0.0291 0.1146 0.0942 0.0794 0.0252 0.1191 0.1045 0.2050 0.1556 0.2690
#>  [9,] 0.0217 0.2110 0.2343 0.2087 0.1645 0.1689 0.1650 0.1967 0.2934 0.3709
#> [10,] 0.0374 0.2597 0.3483 0.3999 0.4574 0.5950 0.7924 0.8272 0.8087 0.8977
#> [11,] 0.0272 0.3997 0.3941 0.3309 0.2926 0.1760 0.1739 0.2043 0.2088 0.2678
#> [12,] 0.1021 0.1369 0.2509 0.2631 0.2796 0.2977 0.3823 0.3129 0.3956 0.2093
#> [13,] 0.0335 0.2660 0.3188 0.3553 0.3116 0.1965 0.1780 0.2794 0.2870 0.3969
#> [14,] 0.0231 0.0347 0.0575 0.1382 0.2274 0.4038 0.5223 0.6847 0.7521 0.7760
#> [15,] 0.0516 0.1294 0.2646 0.2778 0.4432 0.3672 0.2035 0.2764 0.3252 0.1536
#> [16,] 0.0131 0.2079 0.2295 0.1990 0.1184 0.1891 0.2949 0.5343 0.6850 0.7923
#> [17,] 0.0079 0.1240 0.1097 0.1215 0.1874 0.3383 0.3227 0.2723 0.3943 0.6432
#> [18,] 0.0201 0.1097 0.0841 0.0942 0.1204 0.0420 0.0031 0.0162 0.0624 0.2127
#> [19,] 0.0099 0.1882 0.1456 0.1892 0.3176 0.1340 0.2169 0.2458 0.2589 0.2786
#> [20,] 0.0664 0.1838 0.2869 0.4129 0.3647 0.1984 0.2840 0.4039 0.5837 0.6792
#> [21,] 0.0190 0.0349 0.1459 0.3473 0.3197 0.2823 0.0166 0.0572 0.2164 0.4563
#> [22,] 0.0197 0.1695 0.1734 0.2470 0.3141 0.3297 0.2759 0.2056 0.1162 0.1884
#> [23,] 0.0336 0.0842 0.0357 0.0689 0.1705 0.3257 0.4602 0.6225 0.7327 0.7843
#> [24,] 0.0654 0.3422 0.2128 0.1377 0.4032 0.5684 0.2398 0.4331 0.5954 0.5772
#> [25,] 0.0131 0.0901 0.0750 0.0844 0.1226 0.1619 0.2317 0.2934 0.3526 0.3657
#> [26,] 0.1088 0.5761 0.4733 0.2362 0.1023 0.2904 0.4713 0.4659 0.1415 0.0849
#> [27,] 0.0274 0.1808 0.2366 0.0906 0.1749 0.4012 0.5187 0.7312 0.9062 0.9260
#> [28,] 0.0707 0.1247 0.2340 0.1764 0.2284 0.3115 0.4725 0.5543 0.5386 0.3746
#> [29,] 0.0366 0.1847 0.2222 0.2648 0.2508 0.2291 0.1555 0.1863 0.2387 0.3345
#> [30,] 0.0317 0.3513 0.1786 0.0658 0.0513 0.3752 0.5419 0.5440 0.5150 0.4262
#> [31,] 0.0195 0.1191 0.1522 0.1322 0.1434 0.1244 0.0653 0.0890 0.1226 0.1846
#> [32,] 0.0132 0.0922 0.1445 0.1475 0.2087 0.2558 0.2603 0.1985 0.2394 0.3134
#> [33,] 0.0294 0.3473 0.4231 0.5044 0.5237 0.4398 0.3236 0.2956 0.3286 0.3231
#> [34,] 0.0119 0.0864 0.2143 0.3720 0.2665 0.2113 0.1103 0.1136 0.1934 0.4142
#> [35,] 0.0094 0.5079 0.3350 0.0834 0.3004 0.3957 0.3769 0.3828 0.1247 0.1363
#> [36,] 0.0209 0.4125 0.3943 0.1334 0.4622 0.9970 0.9137 0.8292 0.6994 0.7825
#> [37,] 0.0221 0.1810 0.2549 0.2984 0.2624 0.1893 0.0668 0.2666 0.4274 0.6291
#> [38,] 0.0151 0.1205 0.0847 0.1518 0.2305 0.2793 0.3404 0.4527 0.6950 0.8807
#> [39,] 0.0090 0.1895 0.1896 0.2547 0.4073 0.2988 0.2901 0.5326 0.4022 0.1571
#> [40,] 0.0189 0.2522 0.2607 0.3710 0.3906 0.2672 0.2716 0.4183 0.6988 0.5733
#>          V19     V2    V20    V21    V22    V23    V24    V25    V26    V27
#>  [1,] 0.7726 0.0119 0.8098 0.8995 0.9247 0.9365 0.9853 0.9776 1.0000 0.9896
#>  [2,] 0.8723 0.1210 0.7686 0.7326 0.5222 0.3097 0.3172 0.2270 0.1640 0.1746
#>  [3,] 0.3094 0.0019 0.4678 0.5958 0.7245 0.8773 0.9214 0.9282 0.9942 1.0000
#>  [4,] 0.8954 0.0849 0.9922 0.8980 0.8158 0.8373 0.7541 0.5893 0.5488 0.5643
#>  [5,] 0.9146 0.1226 0.7832 0.7960 0.7983 0.7716 0.6615 0.4860 0.5572 0.4697
#>  [6,] 0.3326 0.0644 0.3258 0.2111 0.2302 0.3361 0.4259 0.4609 0.2606 0.0874
#>  [7,] 0.8456 0.0436 0.7939 0.8804 0.8384 0.7852 0.8479 0.7434 0.6433 0.5514
#>  [8,] 0.3784 0.0400 0.4024 0.3470 0.1395 0.1208 0.2827 0.1500 0.2626 0.4468
#>  [9,] 0.4309 0.0152 0.4161 0.5116 0.6501 0.7717 0.8491 0.9104 0.8912 0.8189
#> [10,] 0.9828 0.0586 0.8982 0.8890 0.9367 0.9122 0.7936 0.6718 0.6318 0.4865
#> [11,] 0.2434 0.0378 0.1839 0.2802 0.6172 0.8015 0.8313 0.8440 0.8494 0.9168
#> [12,] 0.3218 0.0830 0.3345 0.3184 0.2887 0.3610 0.2566 0.4106 0.4591 0.4722
#> [13,] 0.5599 0.0258 0.6936 0.7969 0.7452 0.8203 0.9261 0.8810 0.8814 0.9301
#> [14,] 0.7708 0.0351 0.8627 1.0000 0.8873 0.8057 0.8760 0.9066 0.9430 0.8846
#> [15,] 0.2784 0.0944 0.3508 0.5187 0.7052 0.7143 0.6814 0.5100 0.5308 0.6131
#> [16,] 0.8220 0.0201 0.7290 0.7352 0.7918 0.8057 0.4898 0.1934 0.2924 0.6255
#> [17,] 0.7271 0.0086 0.8673 0.9674 0.9847 0.9480 0.8036 0.6833 0.5136 0.3090
#> [18,] 0.3436 0.0026 0.3813 0.3825 0.4764 0.6313 0.7523 0.8675 0.8788 0.7901
#> [19,] 0.2298 0.0484 0.0656 0.1441 0.1179 0.1668 0.1783 0.2476 0.2570 0.1036
#> [20,] 0.6086 0.0575 0.4858 0.3246 0.2013 0.2082 0.1686 0.2484 0.2736 0.2984
#> [21,] 0.3819 0.0038 0.5627 0.6484 0.7235 0.8242 0.8766 1.0000 0.8582 0.6563
#> [22,] 0.3390 0.0394 0.3926 0.4282 0.5418 0.6448 0.7223 0.7853 0.7984 0.8847
#> [23,] 0.7988 0.0294 0.8261 1.0000 0.9814 0.9620 0.9601 0.9118 0.9086 0.7931
#> [24,] 0.8176 0.0649 0.8835 0.5248 0.6373 0.8375 0.6699 0.7756 0.8750 0.8300
#> [25,] 0.3221 0.0068 0.3093 0.4084 0.4285 0.4663 0.5956 0.6948 0.8386 0.8875
#> [26,] 0.3257 0.1278 0.9007 0.9312 0.4856 0.1346 0.1604 0.2737 0.5609 0.3654
#> [27,] 0.7434 0.0242 0.4463 0.5103 0.6952 0.7755 0.8364 0.7283 0.6399 0.5759
#> [28,] 0.4583 0.1252 0.5961 0.7464 0.7644 0.5711 0.6257 0.6695 0.7131 0.7567
#> [29,] 0.5233 0.0421 0.6684 0.7766 0.7928 0.7940 0.9129 0.9498 0.9835 1.0000
#> [30,] 0.2024 0.0956 0.4233 0.7723 0.9735 0.9390 0.5559 0.5268 0.6826 0.5713
#> [31,] 0.3880 0.0142 0.3658 0.2297 0.2610 0.4193 0.5848 0.5643 0.5448 0.4772
#> [32,] 0.4077 0.0080 0.4529 0.4893 0.5666 0.6234 0.6741 0.8282 0.8823 0.9196
#> [33,] 0.4528 0.0123 0.6339 0.7044 0.8314 0.8449 0.8512 0.9138 0.9985 1.0000
#> [34,] 0.3279 0.0582 0.6222 0.7468 0.7676 0.7867 0.8253 1.0000 0.9481 0.7539
#> [35,] 0.2678 0.0611 0.9188 0.9779 0.3236 0.1944 0.1874 0.0885 0.3443 0.2953
#> [36,] 0.8789 0.0261 0.8501 0.8920 0.9473 1.0000 0.8975 0.7806 0.8321 0.6502
#> [37,] 0.7782 0.0065 0.7686 0.8099 0.8493 0.9440 0.9450 0.9655 0.8045 0.4969
#> [38,] 0.9154 0.0320 0.7542 0.6736 0.7146 0.8335 0.7701 0.6993 0.6543 0.5040
#> [39,] 0.3024 0.0062 0.3907 0.3542 0.4438 0.6414 0.4601 0.6009 0.8690 0.8345
#> [40,] 0.2226 0.0308 0.2631 0.7473 0.7263 0.3393 0.2824 0.6053 0.5897 0.4967
#>          V28    V29     V3    V30    V31    V32    V33    V34    V35    V36
#>  [1,] 0.9076 0.7306 0.0277 0.5758 0.4469 0.3719 0.2079 0.0955 0.0488 0.1406
#>  [2,] 0.1835 0.2048 0.1268 0.1674 0.2767 0.3104 0.3399 0.4441 0.5046 0.2814
#>  [3,] 0.9071 0.8545 0.0075 0.7293 0.6499 0.6071 0.5588 0.5967 0.6275 0.5459
#>  [4,] 0.5406 0.4783 0.0587 0.4439 0.3698 0.2574 0.1478 0.1743 0.1229 0.1588
#>  [5,] 0.5640 0.4517 0.1385 0.3369 0.2684 0.2339 0.3052 0.3016 0.2753 0.1041
#>  [6,] 0.2862 0.5606 0.0390 0.8344 0.8096 0.7250 0.8048 0.9435 1.0000 0.8960
#>  [7,] 0.3519 0.3168 0.0447 0.3346 0.2056 0.1032 0.3168 0.4040 0.4282 0.4538
#>  [8,] 0.7520 0.9036 0.0771 0.7812 0.4766 0.2483 0.5372 0.6279 0.3647 0.4572
#>  [9,] 0.6779 0.5368 0.0346 0.5207 0.5651 0.5749 0.5250 0.4255 0.3330 0.2331
#> [10,] 0.3388 0.4832 0.0628 0.3822 0.3075 0.1267 0.0743 0.1510 0.1906 0.1817
#> [11,] 1.0000 0.7896 0.0488 0.5371 0.6472 0.6505 0.4959 0.2175 0.0990 0.0434
#> [12,] 0.7278 0.7591 0.0577 0.6579 0.7514 0.6666 0.4903 0.5962 0.6552 0.4014
#> [13,] 0.9955 0.8576 0.0398 0.6069 0.3934 0.2464 0.1645 0.1140 0.0956 0.0080
#> [14,] 0.6500 0.2970 0.0030 0.2423 0.2992 0.2285 0.2277 0.1529 0.1037 0.0352
#> [15,] 0.8388 0.9031 0.0622 0.8607 0.9656 0.9168 0.7132 0.6898 0.7310 0.4134
#> [16,] 0.8546 0.8966 0.0045 0.7821 0.5168 0.4840 0.4038 0.3411 0.2849 0.2353
#> [17,] 0.0832 0.4019 0.0055 0.2344 0.1905 0.1235 0.1717 0.2351 0.2489 0.3649
#> [18,] 0.8357 0.9631 0.0138 0.9619 0.9236 0.8903 0.9708 0.9647 0.7892 0.5307
#> [19,] 0.5356 0.7124 0.0299 0.6291 0.4756 0.6015 0.7208 0.6234 0.5725 0.7523
#> [20,] 0.4655 0.6990 0.0842 0.7474 0.7956 0.7981 0.6715 0.6942 0.7440 0.8169
#> [21,] 0.5087 0.4817 0.0642 0.4530 0.4521 0.4532 0.5385 0.5308 0.5356 0.5271
#> [22,] 0.9582 0.8990 0.0384 0.6831 0.6108 0.5480 0.5058 0.4476 0.2401 0.1405
#> [23,] 0.5877 0.3474 0.0476 0.4235 0.4633 0.3410 0.2849 0.2847 0.1742 0.0549
#> [24,] 0.6896 0.3372 0.0737 0.6405 0.7138 0.8202 0.6657 0.5254 0.2960 0.0704
#> [25,] 0.6404 0.3308 0.0308 0.3425 0.4920 0.4592 0.3034 0.4366 0.5175 0.5122
#> [26,] 0.6139 0.5470 0.0926 0.8474 0.5638 0.5443 0.5086 0.6253 0.8497 0.8406
#> [27,] 0.4146 0.3495 0.0621 0.4437 0.2665 0.2024 0.1942 0.0765 0.3725 0.5843
#> [28,] 0.8077 0.8477 0.1447 0.9289 0.9513 0.7995 0.4362 0.4048 0.4952 0.1712
#> [29,] 0.9471 0.8237 0.0504 0.6252 0.4181 0.3209 0.2658 0.2196 0.1588 0.0561
#> [30,] 0.5429 0.2177 0.1321 0.2149 0.5811 0.6323 0.2965 0.1873 0.2969 0.5163
#> [31,] 0.6897 0.9797 0.0181 1.0000 0.9546 0.8835 0.7662 0.6547 0.5447 0.4593
#> [32,] 0.8965 0.7549 0.0188 0.6736 0.6463 0.5007 0.3663 0.2298 0.1362 0.2123
#> [33,] 0.7544 0.4661 0.0117 0.3924 0.3849 0.4674 0.4245 0.3095 0.0752 0.2885
#> [34,] 0.6008 0.5437 0.0623 0.5387 0.5619 0.5141 0.6084 0.5621 0.5956 0.6078
#> [35,] 0.5908 0.4564 0.1136 0.7334 0.1969 0.2790 0.6212 0.8681 0.8621 0.9380
#> [36,] 0.4548 0.4732 0.0120 0.3391 0.2747 0.0978 0.0477 0.1403 0.1834 0.2148
#> [37,] 0.3960 0.3856 0.0164 0.5574 0.7309 0.8549 0.9425 0.8726 0.6673 0.4694
#> [38,] 0.4926 0.4992 0.0599 0.4161 0.1631 0.0404 0.0637 0.2962 0.3609 0.1866
#> [39,] 0.7669 0.5081 0.0253 0.4620 0.5380 0.5375 0.3844 0.3601 0.7402 0.7761
#> [40,] 0.8616 0.8339 0.0197 0.4084 0.2268 0.1745 0.0507 0.1588 0.3040 0.1369
#>          V37    V38    V39     V4    V40    V41    V42    V43    V44    V45
#>  [1,] 0.2554 0.2054 0.1614 0.0760 0.2232 0.1773 0.2293 0.2521 0.1464 0.0673
#>  [2,] 0.1681 0.2633 0.3198 0.1498 0.1933 0.0934 0.0443 0.0780 0.0722 0.0405
#>  [3,] 0.4786 0.3965 0.2087 0.0097 0.1651 0.1836 0.0652 0.0758 0.0486 0.0353
#>  [4,] 0.1803 0.1436 0.1667 0.0218 0.2630 0.2234 0.1239 0.0869 0.2092 0.1499
#>  [5,] 0.1757 0.3156 0.3603 0.1484 0.2736 0.1301 0.2458 0.3404 0.1753 0.0679
#>  [6,] 0.5516 0.3037 0.2338 0.0173 0.2382 0.3318 0.3821 0.1575 0.2228 0.1582
#>  [7,] 0.3704 0.3741 0.3839 0.0844 0.3494 0.4380 0.4265 0.2854 0.2808 0.2395
#>  [8,] 0.6359 0.6474 0.5520 0.0809 0.3253 0.2292 0.0653 0.0000 0.0000 0.0000
#>  [9,] 0.1451 0.1648 0.2694 0.0346 0.3730 0.4467 0.4133 0.3743 0.3021 0.2069
#> [10,] 0.1709 0.0946 0.2829 0.0534 0.3006 0.1602 0.1483 0.2875 0.2047 0.1064
#> [11,] 0.1708 0.1979 0.1880 0.0848 0.1108 0.1702 0.0585 0.0638 0.1391 0.0638
#> [12,] 0.1188 0.3245 0.3107 0.0627 0.1354 0.5109 0.7988 0.7517 0.5508 0.5858
#> [13,] 0.0702 0.0936 0.0894 0.0570 0.1127 0.0873 0.1020 0.1964 0.2256 0.1814
#> [14,] 0.1073 0.1373 0.1331 0.0304 0.1454 0.1115 0.0440 0.0762 0.1381 0.0831
#> [15,] 0.1580 0.1819 0.1381 0.0415 0.2960 0.6935 0.8246 0.5351 0.4403 0.6448
#> [16,] 0.2699 0.4442 0.4323 0.0217 0.3314 0.1195 0.1669 0.3702 0.3072 0.0945
#> [17,] 0.3382 0.1589 0.0989 0.0250 0.1089 0.1043 0.0839 0.1391 0.0819 0.0678
#> [18,] 0.2718 0.1953 0.1374 0.0062 0.3105 0.3790 0.4105 0.3355 0.2998 0.2748
#> [19,] 0.8712 0.9252 0.9709 0.0297 0.9297 0.8995 0.7911 0.5600 0.2838 0.4407
#> [20,] 0.8912 1.0000 0.8753 0.0372 0.7061 0.6803 0.5898 0.4618 0.3639 0.1492
#> [21,] 0.4260 0.2436 0.1205 0.0452 0.3845 0.4107 0.5067 0.4216 0.2479 0.1586
#> [22,] 0.1772 0.1742 0.3326 0.0076 0.4021 0.3009 0.2075 0.1206 0.0255 0.0298
#> [23,] 0.1192 0.1154 0.0855 0.0539 0.1811 0.1264 0.0799 0.0378 0.1268 0.1125
#> [24,] 0.0970 0.3941 0.6028 0.1132 0.3521 0.3924 0.4808 0.4602 0.4164 0.5438
#> [25,] 0.4746 0.4902 0.4603 0.0311 0.4460 0.4196 0.2873 0.2296 0.0949 0.0095
#> [26,] 0.8420 0.9136 0.7713 0.1234 0.4882 0.3724 0.4469 0.4586 0.4491 0.5616
#> [27,] 0.4827 0.2347 0.0999 0.0560 0.3244 0.3990 0.2975 0.1684 0.1761 0.1683
#> [28,] 0.3652 0.3763 0.2841 0.1644 0.0427 0.5331 0.6952 0.4288 0.3063 0.5835
#> [29,] 0.0948 0.1700 0.1215 0.0250 0.1282 0.0386 0.1329 0.2331 0.2468 0.1960
#> [30,] 0.6153 0.4283 0.5479 0.1408 0.6133 0.5017 0.2377 0.1957 0.1749 0.1304
#> [31,] 0.4679 0.1987 0.0699 0.0406 0.1493 0.1713 0.1654 0.2600 0.3846 0.3754
#> [32,] 0.2395 0.2673 0.2865 0.0141 0.2060 0.1659 0.2633 0.2552 0.1696 0.1467
#> [33,] 0.4072 0.3170 0.2863 0.0113 0.2634 0.0541 0.1874 0.3459 0.4646 0.4366
#> [34,] 0.5025 0.2829 0.0477 0.0600 0.2811 0.3422 0.5147 0.4372 0.2470 0.1708
#> [35,] 0.8327 0.9480 0.6721 0.1203 0.4436 0.5163 0.3809 0.1557 0.1449 0.2662
#> [36,] 0.1271 0.1912 0.3391 0.0768 0.3444 0.2369 0.1195 0.2665 0.2587 0.1393
#> [37,] 0.1546 0.1748 0.3607 0.0487 0.5208 0.5177 0.3702 0.2240 0.0816 0.0395
#> [38,] 0.0476 0.1497 0.2405 0.1050 0.1980 0.3175 0.2379 0.1716 0.1559 0.1556
#> [39,] 0.3858 0.0667 0.3684 0.0489 0.6114 0.3510 0.2312 0.2195 0.3051 0.1937
#> [40,] 0.1605 0.2061 0.0734 0.0622 0.0202 0.1638 0.1583 0.1830 0.1886 0.1008
#>          V46    V47    V48    V49     V5    V50    V51    V52    V53    V54
#>  [1,] 0.0965 0.1492 0.1128 0.0463 0.1218 0.0193 0.0140 0.0027 0.0068 0.0150
#>  [2,] 0.0553 0.1081 0.1139 0.0767 0.1436 0.0265 0.0215 0.0331 0.0111 0.0088
#>  [3,] 0.0297 0.0241 0.0379 0.0119 0.0445 0.0073 0.0051 0.0034 0.0129 0.0100
#>  [4,] 0.0676 0.0899 0.0927 0.0658 0.0862 0.0086 0.0216 0.0153 0.0121 0.0096
#>  [5,] 0.1062 0.0643 0.0532 0.0531 0.1776 0.0272 0.0171 0.0118 0.0129 0.0344
#>  [6,] 0.1433 0.1634 0.1133 0.0567 0.0476 0.0133 0.0170 0.0035 0.0052 0.0083
#>  [7,] 0.0369 0.0805 0.0541 0.0177 0.0419 0.0065 0.0222 0.0045 0.0136 0.0113
#>  [8,] 0.0000 0.0000 0.0000 0.0000 0.0521 0.0000 0.0000 0.0056 0.0237 0.0204
#>  [9,] 0.1790 0.1689 0.1341 0.0769 0.0484 0.0222 0.0205 0.0123 0.0067 0.0011
#> [10,] 0.1395 0.1065 0.0527 0.0395 0.0255 0.0183 0.0353 0.0118 0.0063 0.0237
#> [11,] 0.0581 0.0641 0.1044 0.0732 0.1127 0.0275 0.0146 0.0091 0.0045 0.0043
#> [12,] 0.7292 0.5522 0.3339 0.1608 0.0635 0.0475 0.1004 0.0709 0.0317 0.0309
#> [13,] 0.2012 0.1688 0.1037 0.0501 0.0529 0.0136 0.0130 0.0120 0.0039 0.0053
#> [14,] 0.0654 0.0844 0.0595 0.0497 0.0339 0.0313 0.0154 0.0106 0.0097 0.0022
#> [15,] 0.6214 0.3016 0.1379 0.0364 0.0995 0.0355 0.0456 0.0432 0.0274 0.0152
#> [16,] 0.1545 0.1394 0.0772 0.0615 0.0230 0.0230 0.0111 0.0168 0.0086 0.0045
#> [17,] 0.0663 0.1202 0.0692 0.0152 0.0344 0.0266 0.0174 0.0176 0.0127 0.0088
#> [18,] 0.2024 0.1043 0.0453 0.0337 0.0133 0.0122 0.0072 0.0108 0.0070 0.0063
#> [19,] 0.5507 0.4331 0.2905 0.1981 0.0652 0.0779 0.0396 0.0173 0.0149 0.0115
#> [20,] 0.1216 0.1306 0.1198 0.0578 0.0458 0.0235 0.0135 0.0141 0.0190 0.0043
#> [21,] 0.1124 0.0651 0.0789 0.0325 0.0333 0.0070 0.0026 0.0093 0.0118 0.0112
#> [22,] 0.0691 0.0781 0.0777 0.0369 0.0251 0.0057 0.0091 0.0134 0.0097 0.0042
#> [23,] 0.0505 0.0949 0.0677 0.0259 0.0794 0.0170 0.0033 0.0150 0.0111 0.0032
#> [24,] 0.5649 0.3195 0.2484 0.1299 0.2482 0.0825 0.0243 0.0210 0.0361 0.0239
#> [25,] 0.0527 0.0383 0.0107 0.0108 0.0085 0.0077 0.0109 0.0062 0.0028 0.0040
#> [26,] 0.4305 0.0945 0.0794 0.0274 0.1276 0.0154 0.0140 0.0455 0.0213 0.0082
#> [27,] 0.0729 0.1190 0.1297 0.0748 0.1129 0.0067 0.0255 0.0113 0.0108 0.0085
#> [28,] 0.5692 0.2630 0.1196 0.0983 0.1693 0.0374 0.0291 0.0156 0.0197 0.0135
#> [29,] 0.1985 0.1570 0.0921 0.0549 0.0596 0.0194 0.0166 0.0132 0.0027 0.0022
#> [30,] 0.0597 0.1124 0.1047 0.0507 0.1674 0.0159 0.0195 0.0201 0.0248 0.0131
#> [31,] 0.2414 0.1077 0.0224 0.0155 0.0391 0.0187 0.0125 0.0028 0.0067 0.0120
#> [32,] 0.1286 0.0926 0.0716 0.0325 0.0436 0.0258 0.0136 0.0044 0.0028 0.0021
#> [33,] 0.2581 0.1319 0.0505 0.0112 0.0497 0.0059 0.0041 0.0056 0.0104 0.0079
#> [34,] 0.1343 0.0838 0.0755 0.0304 0.1397 0.0074 0.0069 0.0025 0.0103 0.0074
#> [35,] 0.1806 0.1699 0.2559 0.1129 0.0403 0.0201 0.0480 0.0234 0.0175 0.0352
#> [36,] 0.1083 0.1383 0.1321 0.1069 0.1064 0.0325 0.0316 0.0057 0.0159 0.0085
#> [37,] 0.0785 0.1052 0.1034 0.0764 0.0519 0.0216 0.0167 0.0089 0.0051 0.0015
#> [38,] 0.0422 0.0493 0.0476 0.0219 0.1163 0.0059 0.0086 0.0061 0.0015 0.0084
#> [39,] 0.1570 0.0479 0.0538 0.0146 0.1197 0.0068 0.0187 0.0059 0.0095 0.0194
#> [40,] 0.0663 0.0183 0.0404 0.0108 0.0080 0.0143 0.0091 0.0038 0.0096 0.0142
#>          V55    V56    V57    V58    V59     V6    V60     V7     V8     V9
#>  [1,] 0.0012 0.0133 0.0048 0.0244 0.0077 0.1538 0.0074 0.1192 0.1229 0.2119
#>  [2,] 0.0158 0.0122 0.0038 0.0101 0.0228 0.0561 0.0124 0.0832 0.0672 0.1372
#>  [3,] 0.0044 0.0057 0.0030 0.0035 0.0021 0.0906 0.0027 0.0889 0.0655 0.1624
#>  [4,] 0.0196 0.0042 0.0066 0.0099 0.0083 0.1801 0.0124 0.1916 0.1896 0.2960
#>  [5,] 0.0065 0.0067 0.0022 0.0079 0.0146 0.1428 0.0051 0.1773 0.2161 0.1630
#>  [6,] 0.0078 0.0075 0.0105 0.0160 0.0095 0.0816 0.0011 0.0993 0.0315 0.0736
#>  [7,] 0.0053 0.0165 0.0141 0.0077 0.0246 0.1215 0.0198 0.2002 0.1516 0.0818
#>  [8,] 0.0050 0.0137 0.0164 0.0081 0.0139 0.1051 0.0111 0.0145 0.0674 0.1294
#>  [9,] 0.0026 0.0049 0.0029 0.0022 0.0022 0.0526 0.0032 0.0773 0.0862 0.1451
#> [10,] 0.0032 0.0087 0.0124 0.0113 0.0098 0.1422 0.0126 0.2072 0.2734 0.3070
#> [11,] 0.0043 0.0098 0.0054 0.0051 0.0065 0.1103 0.0103 0.1349 0.2337 0.3113
#> [12,] 0.0252 0.0087 0.0177 0.0214 0.0227 0.1328 0.0106 0.0988 0.1787 0.1199
#> [13,] 0.0062 0.0046 0.0045 0.0022 0.0005 0.1091 0.0031 0.1709 0.1684 0.1865
#> [14,] 0.0052 0.0072 0.0056 0.0038 0.0043 0.0860 0.0030 0.1738 0.1351 0.1063
#> [15,] 0.0120 0.0129 0.0020 0.0109 0.0074 0.2431 0.0078 0.1777 0.2018 0.2611
#> [16,] 0.0062 0.0065 0.0030 0.0066 0.0029 0.0481 0.0053 0.0742 0.0333 0.1369
#> [17,] 0.0098 0.0019 0.0059 0.0058 0.0059 0.0546 0.0032 0.0528 0.0958 0.1009
#> [18,] 0.0030 0.0011 0.0007 0.0024 0.0057 0.0151 0.0044 0.0541 0.0210 0.0505
#> [19,] 0.0202 0.0139 0.0029 0.0160 0.0106 0.1077 0.0134 0.2363 0.2385 0.0075
#> [20,] 0.0036 0.0026 0.0024 0.0162 0.0109 0.0771 0.0079 0.0771 0.1130 0.2353
#> [21,] 0.0094 0.0140 0.0072 0.0022 0.0055 0.0690 0.0122 0.0901 0.1454 0.0740
#> [22,] 0.0058 0.0072 0.0041 0.0045 0.0047 0.0629 0.0054 0.0747 0.0578 0.1357
#> [23,] 0.0035 0.0169 0.0137 0.0015 0.0069 0.0804 0.0051 0.1136 0.1228 0.1235
#> [24,] 0.0447 0.0394 0.0355 0.0440 0.0243 0.1257 0.0098 0.1797 0.0989 0.2460
#> [25,] 0.0075 0.0039 0.0053 0.0013 0.0052 0.0767 0.0023 0.0771 0.0640 0.0726
#> [26,] 0.0124 0.0167 0.0103 0.0205 0.0178 0.1731 0.0187 0.1948 0.4262 0.6828
#> [27,] 0.0047 0.0074 0.0104 0.0161 0.0220 0.0973 0.0173 0.1823 0.1745 0.1440
#> [28,] 0.0127 0.0138 0.0133 0.0131 0.0154 0.0844 0.0218 0.0715 0.0947 0.1583
#> [29,] 0.0059 0.0016 0.0025 0.0017 0.0027 0.0252 0.0027 0.0958 0.0991 0.1419
#> [30,] 0.0070 0.0138 0.0092 0.0143 0.0036 0.1710 0.0103 0.0731 0.1401 0.2083
#> [31,] 0.0012 0.0022 0.0058 0.0042 0.0067 0.0249 0.0012 0.0892 0.0973 0.0840
#> [32,] 0.0022 0.0048 0.0138 0.0140 0.0028 0.0668 0.0064 0.0609 0.0131 0.0899
#> [33,] 0.0014 0.0054 0.0015 0.0006 0.0081 0.0998 0.0043 0.1326 0.1117 0.2984
#> [34,] 0.0123 0.0069 0.0076 0.0073 0.0030 0.1883 0.0138 0.1422 0.1447 0.0487
#> [35,] 0.0158 0.0326 0.0201 0.0168 0.0245 0.1227 0.0154 0.2495 0.4566 0.6587
#> [36,] 0.0372 0.0101 0.0127 0.0288 0.0129 0.1680 0.0023 0.3016 0.3460 0.3314
#> [37,] 0.0075 0.0058 0.0016 0.0070 0.0074 0.0849 0.0038 0.0812 0.1833 0.2228
#> [38,] 0.0128 0.0054 0.0011 0.0019 0.0023 0.1734 0.0062 0.1679 0.1119 0.0889
#> [39,] 0.0080 0.0152 0.0158 0.0053 0.0189 0.1589 0.0102 0.1392 0.0987 0.0955
#> [40,] 0.0190 0.0140 0.0099 0.0092 0.0052 0.0789 0.0075 0.1440 0.1451 0.1789
#> 
#> $post[[2]]
#>              [,1]
#>  [1,] 0.001806236
#>  [2,] 0.013392001
#>  [3,] 0.003293800
#>  [4,] 0.002814444
#>  [5,] 0.003556990
#>  [6,] 0.014439941
#>  [7,] 0.003716153
#>  [8,] 0.017720526
#>  [9,] 0.004943686
#> [10,] 0.003552353
#> [11,] 0.006043578
#> [12,] 0.006782622
#> [13,] 0.004370648
#> [14,] 0.004565428
#> [15,] 0.002453508
#> [16,] 0.003823888
#> [17,] 0.011506323
#> [18,] 0.003221499
#> [19,] 0.009520416
#> [20,] 0.004179309
#> [21,] 0.005031542
#> [22,] 0.005315681
#> [23,] 0.003624799
#> [24,] 0.002005087
#> [25,] 0.009130999
#> [26,] 0.003420545
#> [27,] 0.005767004
#> [28,] 0.002038618
#> [29,] 0.004222869
#> [30,] 0.005437839
#> [31,] 0.007326479
#> [32,] 0.005828572
#> [33,] 0.003148795
#> [34,] 0.003579238
#> [35,] 0.006298119
#> [36,] 0.002623951
#> [37,] 0.002282889
#> [38,] 0.007380775
#> [39,] 0.005896676
#> [40,] 0.012403635
#> 
#> $post[[3]]
#>            [,1]      [,2]
#>  [1,] 0.5353374 0.4646626
#>  [2,] 0.5352365 0.4647635
#>  [3,] 0.5353245 0.4646755
#>  [4,] 0.5353286 0.4646714
#>  [5,] 0.5353222 0.4646778
#>  [6,] 0.5352273 0.4647727
#>  [7,] 0.5353208 0.4646792
#>  [8,] 0.5351987 0.4648013
#>  [9,] 0.5353101 0.4646899
#> [10,] 0.5353222 0.4646778
#> [11,] 0.5353005 0.4646995
#> [12,] 0.5352941 0.4647059
#> [13,] 0.5353151 0.4646849
#> [14,] 0.5353134 0.4646866
#> [15,] 0.5353318 0.4646682
#> [16,] 0.5353198 0.4646802
#> [17,] 0.5352529 0.4647471
#> [18,] 0.5353251 0.4646749
#> [19,] 0.5352702 0.4647298
#> [20,] 0.5353168 0.4646832
#> [21,] 0.5353093 0.4646907
#> [22,] 0.5353068 0.4646932
#> [23,] 0.5353216 0.4646784
#> [24,] 0.5353357 0.4646643
#> [25,] 0.5352736 0.4647264
#> [26,] 0.5353234 0.4646766
#> [27,] 0.5353029 0.4646971
#> [28,] 0.5353354 0.4646646
#> [29,] 0.5353164 0.4646836
#> [30,] 0.5353058 0.4646942
#> [31,] 0.5352893 0.4647107
#> [32,] 0.5353024 0.4646976
#> [33,] 0.5353257 0.4646743
#> [34,] 0.5353220 0.4646780
#> [35,] 0.5352983 0.4647017
#> [36,] 0.5353303 0.4646697
#> [37,] 0.5353333 0.4646667
#> [38,] 0.5352889 0.4647111
#> [39,] 0.5353018 0.4646982
#> [40,] 0.5352451 0.4647549
#> 
#> 
#> $pre
#> $pre[[1]]
#> NULL
#> 
#> $pre[[2]]
#>            [,1]
#>  [1,] -6.314702
#>  [2,] -4.299615
#>  [3,] -5.712414
#>  [4,] -5.870172
#>  [5,] -5.635277
#>  [6,] -4.223212
#>  [7,] -5.591343
#>  [8,] -4.015152
#>  [9,] -5.304688
#> [10,] -5.636587
#> [11,] -5.102697
#> [12,] -4.986586
#> [13,] -5.428464
#> [14,] -5.384667
#> [15,] -6.007780
#> [16,] -5.562656
#> [17,] -4.453286
#> [18,] -5.734682
#> [19,] -4.644751
#> [20,] -5.473421
#> [21,] -5.286984
#> [22,] -5.231764
#> [23,] -5.616325
#> [24,] -6.210061
#> [25,] -4.686907
#> [26,] -5.674529
#> [27,] -5.149819
#> [28,] -6.193442
#> [29,] -5.463009
#> [30,] -5.208921
#> [31,] -4.908907
#> [32,] -5.139138
#> [33,] -5.757582
#> [34,] -5.629020
#> [35,] -5.061186
#> [36,] -5.940447
#> [37,] -6.080028
#> [38,] -4.901468
#> [39,] -5.127452
#> [40,] -4.377284
#> 
#> $pre[[3]]
#>            [,1]        [,2]
#>  [1,] 0.1211643 -0.02042149
#>  [2,] 0.1205006 -0.02067931
#>  [3,] 0.1210791 -0.02045459
#>  [4,] 0.1211065 -0.02044393
#>  [5,] 0.1210640 -0.02046045
#>  [6,] 0.1204406 -0.02070263
#>  [7,] 0.1210549 -0.02046399
#>  [8,] 0.1202526 -0.02077564
#>  [9,] 0.1209846 -0.02049131
#> [10,] 0.1210643 -0.02046035
#> [11,] 0.1209215 -0.02051579
#> [12,] 0.1208792 -0.02053223
#> [13,] 0.1210174 -0.02047856
#> [14,] 0.1210062 -0.02048289
#> [15,] 0.1211272 -0.02043589
#> [16,] 0.1210487 -0.02046639
#> [17,] 0.1206086 -0.02063735
#> [18,] 0.1210832 -0.02045298
#> [19,] 0.1207224 -0.02059316
#> [20,] 0.1210283 -0.02047430
#> [21,] 0.1209795 -0.02049326
#> [22,] 0.1209632 -0.02049959
#> [23,] 0.1210601 -0.02046196
#> [24,] 0.1211529 -0.02042591
#> [25,] 0.1207447 -0.02058449
#> [26,] 0.1210718 -0.02045741
#> [27,] 0.1209374 -0.02050963
#> [28,] 0.1211510 -0.02042666
#> [29,] 0.1210258 -0.02047527
#> [30,] 0.1209562 -0.02050231
#> [31,] 0.1208481 -0.02054433
#> [32,] 0.1209339 -0.02051100
#> [33,] 0.1210874 -0.02045137
#> [34,] 0.1210627 -0.02046094
#> [35,] 0.1209070 -0.02052145
#> [36,] 0.1211174 -0.02043969
#> [37,] 0.1211370 -0.02043210
#> [38,] 0.1208449 -0.02054554
#> [39,] 0.1209300 -0.02051252
#> [40,] 0.1205572 -0.02065732
#> 
#> 
#> $e
#>             [,1]       [,2]
#>  [1,]  0.4646626 -0.4646626
#>  [2,]  0.4647635 -0.4647635
#>  [3,] -0.5353245  0.5353245
#>  [4,]  0.4646714 -0.4646714
#>  [5,]  0.4646778 -0.4646778
#>  [6,] -0.5352273  0.5352273
#>  [7,]  0.4646792 -0.4646792
#>  [8,] -0.5351987  0.5351987
#>  [9,]  0.4646899 -0.4646899
#> [10,]  0.4646778 -0.4646778
#> [11,]  0.4646995 -0.4646995
#> [12,]  0.4647059 -0.4647059
#> [13,]  0.4646849 -0.4646849
#> [14,] -0.5353134  0.5353134
#> [15,]  0.4646682 -0.4646682
#> [16,]  0.4646802 -0.4646802
#> [17,] -0.5352529  0.5352529
#> [18,] -0.5353251  0.5353251
#> [19,] -0.5352702  0.5352702
#> [20,] -0.5353168  0.5353168
#> [21,] -0.5353093  0.5353093
#> [22,]  0.4646932 -0.4646932
#> [23,] -0.5353216  0.5353216
#> [24,]  0.4646643 -0.4646643
#> [25,] -0.5352736  0.5352736
#> [26,]  0.4646766 -0.4646766
#> [27,] -0.5353029  0.5353029
#> [28,]  0.4646646 -0.4646646
#> [29,]  0.4646836 -0.4646836
#> [30,] -0.5353058  0.5353058
#> [31,] -0.5352893  0.5352893
#> [32,] -0.5353024  0.5353024
#> [33,]  0.4646743 -0.4646743
#> [34,] -0.5353220  0.5353220
#> [35,]  0.4647017 -0.4647017
#> [36,]  0.4646697 -0.4646697
#> [37,]  0.4646667 -0.4646667
#> [38,] -0.5352889  0.5352889
#> [39,] -0.5353018  0.5353018
#> [40,] -0.5352451  0.5352451
#> 
#> $L
#> [1] 0.6925164 0.6975084 0.6930055 0.7015247 0.6931351 0.6920824
#> 


# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()
#> classif.ce 
#>  0.4202899 
```
