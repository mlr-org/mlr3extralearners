# Classification Stacked Autoencoder Deep Neural Network Learner

Calls
[`deepnet::sae.dnn.train()`](https://rdrr.io/pkg/deepnet/man/sae.dnn.train.html)
from [deepnet](https://CRAN.R-project.org/package=deepnet).

## Initial parameter values

- `output` is set to `"softmax"` for probabilistic classification.

## Dictionary

This [Learner](https://mlr3.mlr-org.com/reference/Learner.html) can be
instantiated via
[lrn()](https://mlr3.mlr-org.com/reference/mlr_sugar.html):

    lrn("classif.saeDNN")

## Meta Information

- Task type: “classif”

- Predict Types: “response”, “prob”

- Feature Types: “integer”, “numeric”

- Required Packages: [mlr3](https://CRAN.R-project.org/package=mlr3),
  [deepnet](https://CRAN.R-project.org/package=deepnet)

## Parameters

|                    |           |         |                       |                  |
|--------------------|-----------|---------|-----------------------|------------------|
| Id                 | Type      | Default | Levels                | Range            |
| hidden             | untyped   | 10L     |                       | \-               |
| activationfun      | character | sigm    | sigm, linear, tanh    | \-               |
| learningrate       | numeric   | 0.8     |                       | \\\[0, \infty)\\ |
| momentum           | numeric   | 0.5     |                       | \\\[0, \infty)\\ |
| learningrate_scale | numeric   | 1       |                       | \\\[0, \infty)\\ |
| numepochs          | integer   | 3       |                       | \\\[1, \infty)\\ |
| batchsize          | integer   | 100     |                       | \\\[1, \infty)\\ |
| output             | character | \-      | sigm, linear, softmax | \-               |
| sae_output         | character | linear  | sigm, linear, softmax | \-               |
| hidden_dropout     | numeric   | 0       |                       | \\\[0, 1\]\\     |
| visible_dropout    | numeric   | 0       |                       | \\\[0, 1\]\\     |

## References

Rong, Xiao (2022). “deepnet: Deep Learning Toolkit in R.” *R package
version 0.2.1*.
[doi:10.32614/CRAN.package.deepnet](https://doi.org/10.32614/CRAN.package.deepnet)
, <https://CRAN.R-project.org/package=deepnet>.

## See also

- [Dictionary](https://mlr3misc.mlr-org.com/reference/Dictionary.html)
  of [Learners](https://mlr3.mlr-org.com/reference/Learner.html):
  [mlr3::mlr_learners](https://mlr3.mlr-org.com/reference/mlr_learners.html).

- `as.data.table(mlr_learners)` for a table of available
  [Learners](https://mlr3.mlr-org.com/reference/Learner.html) in the
  running session (depending on the loaded packages).

- Chapter in the [mlr3book](https://mlr3book.mlr-org.com/):
  <https://mlr3book.mlr-org.com/basics.html#learners>

- [mlr3learners](https://CRAN.R-project.org/package=mlr3learners) for a
  selection of recommended learners.

- [mlr3cluster](https://CRAN.R-project.org/package=mlr3cluster) for
  unsupervised clustering learners.

- [mlr3pipelines](https://CRAN.R-project.org/package=mlr3pipelines) to
  combine learners with pre- and postprocessing steps.

- [mlr3tuning](https://CRAN.R-project.org/package=mlr3tuning) for tuning
  of hyperparameters,
  [mlr3tuningspaces](https://CRAN.R-project.org/package=mlr3tuningspaces)
  for established default tuning spaces.

## Author

awinterstetter

## Super classes

[`mlr3::Learner`](https://mlr3.mlr-org.com/reference/Learner.html) -\>
[`mlr3::LearnerClassif`](https://mlr3.mlr-org.com/reference/LearnerClassif.html)
-\> `LearnerClassifSaeDNN`

## Methods

### Public methods

- [`LearnerClassifSaeDNN$new()`](#method-LearnerClassifSaeDNN-new)

- [`LearnerClassifSaeDNN$clone()`](#method-LearnerClassifSaeDNN-clone)

Inherited methods

- [`mlr3::Learner$base_learner()`](https://mlr3.mlr-org.com/reference/Learner.html#method-base_learner)
- [`mlr3::Learner$configure()`](https://mlr3.mlr-org.com/reference/Learner.html#method-configure)
- [`mlr3::Learner$encapsulate()`](https://mlr3.mlr-org.com/reference/Learner.html#method-encapsulate)
- [`mlr3::Learner$format()`](https://mlr3.mlr-org.com/reference/Learner.html#method-format)
- [`mlr3::Learner$help()`](https://mlr3.mlr-org.com/reference/Learner.html#method-help)
- [`mlr3::Learner$predict()`](https://mlr3.mlr-org.com/reference/Learner.html#method-predict)
- [`mlr3::Learner$predict_newdata()`](https://mlr3.mlr-org.com/reference/Learner.html#method-predict_newdata)
- [`mlr3::Learner$print()`](https://mlr3.mlr-org.com/reference/Learner.html#method-print)
- [`mlr3::Learner$reset()`](https://mlr3.mlr-org.com/reference/Learner.html#method-reset)
- [`mlr3::Learner$selected_features()`](https://mlr3.mlr-org.com/reference/Learner.html#method-selected_features)
- [`mlr3::Learner$train()`](https://mlr3.mlr-org.com/reference/Learner.html#method-train)
- [`mlr3::LearnerClassif$predict_newdata_fast()`](https://mlr3.mlr-org.com/reference/LearnerClassif.html#method-predict_newdata_fast)

------------------------------------------------------------------------

### Method `new()`

Creates a new instance of this
[R6](https://r6.r-lib.org/reference/R6Class.html) class.

#### Usage

    LearnerClassifSaeDNN$new()

------------------------------------------------------------------------

### Method `clone()`

The objects of this class are cloneable with this method.

#### Usage

    LearnerClassifSaeDNN$clone(deep = FALSE)

#### Arguments

- `deep`:

  Whether to make a deep clone.

## Examples

``` r
# Define the Learner
learner = lrn("classif.saeDNN")
print(learner)
#> 
#> ── <LearnerClassifSaeDNN> (classif.saeDNN): Deep neural network with weights ini
#> • Model: -
#> • Parameters: output=softmax
#> • Packages: mlr3 and deepnet
#> • Predict Types: [response] and prob
#> • Feature Types: integer and numeric
#> • Encapsulation: none (fallback: -)
#> • Properties: multiclass and twoclass
#> • Other settings: use_weights = 'error'

# Define a Task
task = tsk("sonar")

# Create train and test set
ids = partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)
#> begin to train sae ......
#> training layer 1 autoencoder ...
#> sae has been trained.
#> begin to train deep nn ......
#> deep nn has been trained.

print(learner$model)
#> $input_dim
#> [1] 60
#> 
#> $output_dim
#> [1] 2
#> 
#> $hidden
#> [1] 1
#> 
#> $size
#> [1] 60  1  2
#> 
#> $activationfun
#> [1] "sigm"
#> 
#> $learningrate
#> [1] 0.8
#> 
#> $momentum
#> [1] 0.5
#> 
#> $learningrate_scale
#> [1] 1
#> 
#> $hidden_dropout
#> [1] 0
#> 
#> $visible_dropout
#> [1] 0
#> 
#> $output
#> [1] "softmax"
#> 
#> $W
#> $W[[1]]
#>              V1        V10         V11        V12        V13        V14
#> [1,] 0.07070053 -0.1885143 -0.05593758 -0.1462522 -0.1443193 -0.2646974
#>             V15        V16        V17       V18        V19           V2
#> [1,] -0.3033504 -0.1707385 -0.2042592 -0.304267 -0.2297615 -0.001951538
#>             V20        V21        V22        V23        V24        V25
#> [1,] -0.4101771 -0.4138624 -0.3077376 -0.4237067 -0.3571061 -0.3758645
#>             V26        V27        V28        V29          V3        V30
#> [1,] -0.4807335 -0.3311516 -0.4546744 -0.4083167 -0.04908839 -0.4262604
#>             V31        V32        V33       V34        V35        V36
#> [1,] -0.2231267 -0.3478487 -0.2483773 -0.301128 -0.2818947 -0.1510976
#>             V37       V38       V39         V4        V40        V41        V42
#> [1,] -0.2013215 -0.275993 -0.128803 0.04323569 -0.2548169 -0.1866514 -0.2200303
#>             V43         V44        V45         V46       V47         V48
#> [1,] -0.1442681 -0.05367358 -0.1763796 -0.08964689 -0.160436 -0.05754451
#>              V49         V5        V50        V51         V52        V53
#> [1,] -0.09412145 -0.1286927 -0.1119335 0.07417396 -0.09624507 0.05967561
#>             V54          V55         V56        V57         V58        V59
#> [1,] 0.02440776 -0.004595961 -0.07722069 0.05929104 -0.04381382 0.02949524
#>            V6        V60          V7         V8         V9
#> [1,] -0.11923 0.05428715 -0.03721199 -0.0749425 -0.1133819
#> 
#> $W[[2]]
#>              [,1]
#> [1,] -0.000471435
#> [2,] -0.062104129
#> 
#> 
#> $vW
#> $vW[[1]]
#>                 V1           V10          V11           V12           V13
#> [1,] -9.389932e-07 -1.066296e-05 -1.68412e-05 -1.208068e-05 -7.071102e-06
#>                V14          V15          V16           V17           V18
#> [1,] -5.662978e-07 3.918472e-06 2.858668e-06 -2.648776e-07 -1.264947e-06
#>                V19            V2           V20           V21          V22
#> [1,] -4.344228e-06 -8.766198e-07 -6.092103e-06 -4.321693e-06 2.511915e-07
#>               V23          V24          V25         V26          V27
#> [1,] 6.860005e-06 8.362663e-06 1.325897e-05 1.95138e-05 1.772696e-05
#>               V28          V29            V3          V30          V31
#> [1,] 1.519455e-05 1.542993e-05 -1.375003e-06 1.456532e-05 2.189246e-05
#>               V32          V33          V34          V35          V36
#> [1,] 1.859474e-05 1.668273e-05 2.054801e-05 2.930229e-05 3.052137e-05
#>               V37          V38          V39            V4          V40
#> [1,] 2.513599e-05 1.922514e-05 1.661271e-05 -3.393622e-06 1.890615e-05
#>               V41          V42          V43           V44           V45
#> [1,] 1.723358e-05 8.949892e-06 8.077058e-07 -1.464737e-06 -2.702222e-06
#>               V46           V47           V48           V49            V5
#> [1,] -1.29921e-06 -4.077873e-07 -2.043497e-06 -5.519021e-07 -2.177147e-06
#>               V50           V51           V52          V53           V54
#> [1,] 7.157955e-07 -1.353519e-07 -1.820132e-07 2.599636e-08 -2.816002e-08
#>               V55           V56           V57           V58           V59
#> [1,] 3.308949e-08 -1.447082e-07 -8.300708e-08 -1.234491e-07 -1.889635e-07
#>                 V6          V60           V7            V8            V9
#> [1,] -8.011494e-07 1.316346e-07 7.800935e-07 -3.697642e-06 -1.068061e-05
#> 
#> $vW[[2]]
#>               [,1]
#> [1,]  0.0004812559
#> [2,] -0.0004812559
#> 
#> 
#> $B
#> $B[[1]]
#> [1] -0.5416465
#> 
#> $B[[2]]
#> [1]  0.18174824 -0.07055568
#> 
#> 
#> $vB
#> $vB[[1]]
#> [1] 3.024642e-05
#> 
#> $vB[[2]]
#> [1] -0.03864787  0.03864787
#> 
#> 
#> $post
#> $post[[1]]
#>           V1    V10    V11    V12    V13    V14    V15    V16    V17    V18
#>  [1,] 0.0100 0.1264 0.0881 0.1992 0.0184 0.2261 0.1729 0.2131 0.0693 0.2281
#>  [2,] 0.0125 0.1302 0.0888 0.0500 0.0628 0.1274 0.0801 0.0742 0.2048 0.2950
#>  [3,] 0.0228 0.3517 0.3330 0.3643 0.4020 0.4731 0.5196 0.6573 0.8426 0.8476
#>  [4,] 0.0072 0.2318 0.2472 0.2880 0.2126 0.0708 0.1194 0.2808 0.4221 0.5279
#>  [5,] 0.0423 0.2696 0.3412 0.4292 0.3682 0.3940 0.2965 0.3172 0.2825 0.3050
#>  [6,] 0.0179 0.5965 0.6254 0.4507 0.3693 0.2864 0.1635 0.0422 0.1785 0.4394
#>  [7,] 0.0294 0.3473 0.4231 0.5044 0.5237 0.4398 0.3236 0.2956 0.3286 0.3231
#>  [8,] 0.0329 0.2672 0.3056 0.3161 0.2314 0.2067 0.1804 0.2808 0.4423 0.5947
#>  [9,] 0.0216 0.0973 0.1203 0.1102 0.1192 0.1762 0.2390 0.2138 0.1929 0.1765
#> [10,] 0.0209 0.4125 0.3943 0.1334 0.4622 0.9970 0.9137 0.8292 0.6994 0.7825
#> [11,] 0.0223 0.1487 0.1156 0.1654 0.3833 0.3598 0.1713 0.1136 0.0349 0.3796
#> [12,] 0.0126 0.4284 0.3015 0.1207 0.3299 0.5707 0.6962 0.9751 1.0000 0.9293
#> [13,] 0.0664 0.1838 0.2869 0.4129 0.3647 0.1984 0.2840 0.4039 0.5837 0.6792
#> [14,] 0.0968 0.5025 0.3488 0.1700 0.2076 0.3087 0.4224 0.5312 0.2436 0.1884
#> [15,] 0.0221 0.1810 0.2549 0.2984 0.2624 0.1893 0.0668 0.2666 0.4274 0.6291
#> [16,] 0.0305 0.3127 0.2192 0.2621 0.2419 0.2179 0.1159 0.1237 0.0886 0.1755
#> [17,] 0.0260 0.1630 0.1030 0.2187 0.1542 0.2630 0.2940 0.2978 0.0699 0.1401
#> [18,] 0.0099 0.1882 0.1456 0.1892 0.3176 0.1340 0.2169 0.2458 0.2589 0.2786
#> [19,] 0.0047 0.3469 0.3265 0.3263 0.2301 0.1253 0.2102 0.2401 0.1928 0.1673
#> [20,] 0.0270 0.2122 0.2210 0.2399 0.2964 0.4061 0.5095 0.5512 0.6613 0.6804
#> [21,] 0.0116 0.1006 0.2500 0.3988 0.3809 0.4753 0.6165 0.6464 0.8024 0.9208
#> [22,] 0.0239 0.1376 0.0938 0.0259 0.1499 0.2851 0.5743 0.8278 0.8669 0.8131
#> [23,] 0.0107 0.2936 0.3104 0.3431 0.2456 0.1887 0.1184 0.2080 0.2736 0.3274
#> [24,] 0.0089 0.2119 0.3003 0.3094 0.2743 0.2547 0.1870 0.1452 0.1457 0.2429
#> [25,] 0.0135 0.1908 0.1576 0.1112 0.1197 0.1174 0.1415 0.2215 0.2658 0.2713
#> [26,] 0.0394 0.2558 0.3078 0.3404 0.3400 0.3951 0.3352 0.2252 0.2086 0.2248
#> [27,] 0.0201 0.2571 0.2931 0.3108 0.3603 0.3002 0.2718 0.2007 0.1801 0.2234
#> [28,] 0.0368 0.2544 0.2936 0.2935 0.2657 0.3187 0.2794 0.2534 0.1980 0.1929
#> [29,] 0.0430 0.7106 0.7342 0.5033 0.3000 0.1951 0.2767 0.3737 0.2507 0.2507
#> [30,] 0.0317 0.3513 0.1786 0.0658 0.0513 0.3752 0.5419 0.5440 0.5150 0.4262
#> [31,] 0.0265 0.0779 0.0327 0.2060 0.1908 0.1065 0.1457 0.2232 0.2070 0.1105
#> [32,] 0.0094 0.5079 0.3350 0.0834 0.3004 0.3957 0.3769 0.3828 0.1247 0.1363
#> [33,] 0.0056 0.1859 0.2481 0.2712 0.2934 0.2637 0.1880 0.1405 0.2028 0.2613
#> [34,] 0.0335 0.2660 0.3188 0.3553 0.3116 0.1965 0.1780 0.2794 0.2870 0.3969
#> [35,] 0.0203 0.1747 0.2198 0.2721 0.2105 0.1727 0.2040 0.1786 0.1318 0.2260
#> [36,] 0.0087 0.0818 0.1315 0.1862 0.2789 0.2579 0.2240 0.2568 0.2933 0.2991
#> [37,] 0.0188 0.1806 0.2139 0.1523 0.1975 0.4844 0.7298 0.7807 0.7906 0.6122
#> [38,] 0.0015 0.1476 0.2118 0.2575 0.2354 0.1334 0.0092 0.1951 0.3685 0.4646
#> [39,] 0.0635 0.3900 0.4674 0.5632 0.5506 0.4343 0.3052 0.3492 0.3975 0.3875
#> [40,] 0.0093 0.0640 0.0888 0.1599 0.1541 0.2768 0.2176 0.2799 0.3491 0.2824
#>          V19     V2    V20    V21    V22    V23    V24    V25    V26    V27
#>  [1,] 0.4060 0.0171 0.3973 0.2741 0.3690 0.5556 0.4846 0.3140 0.5334 0.5256
#>  [2,] 0.3193 0.0152 0.4567 0.5959 0.7101 0.8225 0.8425 0.9065 0.9802 1.0000
#>  [3,] 0.8344 0.0853 0.8453 0.7999 0.8537 0.9642 1.0000 0.9357 0.9409 0.9070
#>  [4,] 0.5857 0.0027 0.6153 0.6753 0.7873 0.8974 0.9828 1.0000 0.8460 0.6055
#>  [5,] 0.2408 0.0321 0.5420 0.6802 0.6320 0.5824 0.6805 0.5984 0.8412 0.9911
#>  [6,] 0.6950 0.0136 0.8097 0.8550 0.8717 0.8601 0.9201 0.8729 0.8084 0.8694
#>  [7,] 0.4528 0.0123 0.6339 0.7044 0.8314 0.8449 0.8512 0.9138 0.9985 1.0000
#>  [8,] 0.6601 0.0216 0.5844 0.4539 0.4789 0.5646 0.5281 0.7115 1.0000 0.9564
#>  [9,] 0.0746 0.0215 0.1265 0.2005 0.1571 0.2605 0.5386 0.8440 1.0000 0.8684
#> [10,] 0.8789 0.0261 0.8501 0.8920 0.9473 1.0000 0.8975 0.7806 0.8321 0.6502
#> [11,] 0.7401 0.0375 0.9925 0.9802 0.8890 0.6712 0.4286 0.3374 0.7366 0.9611
#> [12,] 0.6210 0.0519 0.4586 0.5001 0.5032 0.7082 0.8420 0.8109 0.7690 0.8105
#> [13,] 0.6086 0.0575 0.4858 0.3246 0.2013 0.2082 0.1686 0.2484 0.2736 0.2984
#> [14,] 0.1908 0.0821 0.8321 1.0000 0.4076 0.0960 0.1928 0.2419 0.3790 0.2893
#> [15,] 0.7782 0.0065 0.7686 0.8099 0.8493 0.9440 0.9450 0.9655 0.8045 0.4969
#> [16,] 0.1758 0.0363 0.1540 0.0512 0.1805 0.4039 0.5697 0.6577 0.7474 0.8543
#> [17,] 0.2990 0.0192 0.3915 0.3598 0.2403 0.4208 0.5675 0.6094 0.6323 0.6549
#> [18,] 0.2298 0.0484 0.0656 0.1441 0.1179 0.1668 0.1783 0.2476 0.2570 0.1036
#> [19,] 0.1228 0.0059 0.0902 0.1557 0.3291 0.5268 0.6740 0.7906 0.8938 0.9395
#> [20,] 0.6520 0.0163 0.6788 0.7811 0.8369 0.8969 0.9856 1.0000 0.9395 0.8917
#> [21,] 0.9832 0.0179 0.9634 0.8646 0.8325 0.8276 0.8007 0.6102 0.4853 0.4355
#> [22,] 0.9045 0.0189 0.9046 1.0000 0.9976 0.9872 0.9761 0.9009 0.9724 0.9675
#> [23,] 0.2344 0.0453 0.1260 0.0576 0.1241 0.3239 0.4357 0.5734 0.7825 0.9252
#> [24,] 0.3259 0.0274 0.3679 0.3355 0.3100 0.3914 0.5280 0.6409 0.7707 0.8754
#> [25,] 0.3862 0.0045 0.5717 0.6797 0.8747 1.0000 0.8948 0.8420 0.9174 0.9307
#> [26,] 0.3382 0.0420 0.4578 0.6474 0.6708 0.7007 0.7619 0.7745 0.6767 0.7373
#> [27,] 0.3568 0.0165 0.5492 0.7209 0.8318 0.8864 0.9520 0.9637 1.0000 0.9673
#> [28,] 0.2826 0.0279 0.3245 0.3504 0.3324 0.4217 0.4774 0.4808 0.6325 0.8334
#> [29,] 0.3292 0.0902 0.4871 0.6527 0.8454 0.9739 1.0000 0.6665 0.5323 0.4024
#> [30,] 0.2024 0.0956 0.4233 0.7723 0.9735 0.9390 0.5559 0.5268 0.6826 0.5713
#> [31,] 0.1078 0.0440 0.1165 0.2224 0.0689 0.2060 0.2384 0.0904 0.2278 0.5872
#> [32,] 0.2678 0.0611 0.9188 0.9779 0.3236 0.1944 0.1874 0.0885 0.3443 0.2953
#> [33,] 0.2778 0.0267 0.3346 0.3830 0.4003 0.5114 0.6860 0.7490 0.7843 0.9021
#> [34,] 0.5599 0.0258 0.6936 0.7969 0.7452 0.8203 0.9261 0.8810 0.8814 0.9301
#> [35,] 0.2358 0.0121 0.3107 0.3906 0.3631 0.4809 0.6531 0.7812 0.8395 0.9180
#> [36,] 0.3924 0.0046 0.4691 0.5665 0.6464 0.6774 0.7577 0.8856 0.9419 1.0000
#> [37,] 0.4200 0.0370 0.2807 0.5148 0.7569 0.8596 1.0000 0.8457 0.6797 0.6971
#> [38,] 0.5418 0.0186 0.6260 0.7420 0.8257 0.8609 0.8400 0.8949 0.9945 1.0000
#> [39,] 0.5280 0.0709 0.7198 0.7702 0.8562 0.8688 0.9236 1.0000 0.9662 0.9822
#> [40,] 0.2479 0.0185 0.3005 0.4300 0.4684 0.4520 0.5026 0.6217 0.6571 0.6632
#>          V28    V29     V3    V30    V31    V32    V33    V34    V35    V36
#>  [1,] 0.2520 0.2090 0.0623 0.3559 0.6260 0.7340 0.6120 0.3497 0.3953 0.3012
#>  [2,] 0.8752 0.7583 0.0218 0.6616 0.5786 0.5128 0.4776 0.4994 0.5197 0.5071
#>  [3,] 0.7104 0.6320 0.1000 0.5667 0.3501 0.2447 0.1698 0.3290 0.3674 0.2331
#>  [4,] 0.3036 0.0144 0.0089 0.2526 0.4335 0.4918 0.5409 0.5961 0.5248 0.3777
#>  [5,] 0.9187 0.8005 0.0709 0.6713 0.5632 0.7332 0.6038 0.2575 0.0349 0.1799
#>  [6,] 0.8411 0.5793 0.0408 0.3754 0.3485 0.4639 0.6495 0.6901 0.5666 0.5188
#>  [7,] 0.7544 0.4661 0.0117 0.3924 0.3849 0.4674 0.4245 0.3095 0.0752 0.2885
#>  [8,] 0.6090 0.5112 0.0386 0.4000 0.0482 0.1852 0.2186 0.1436 0.1757 0.1428
#>  [9,] 0.6742 0.5537 0.0273 0.4638 0.3609 0.2055 0.1620 0.2092 0.3100 0.2344
#> [10,] 0.4548 0.4732 0.0120 0.3391 0.2747 0.0978 0.0477 0.1403 0.1834 0.2148
#> [11,] 0.7353 0.4856 0.0484 0.1594 0.3007 0.4096 0.3170 0.3305 0.3408 0.2186
#> [12,] 0.6203 0.2356 0.0621 0.2595 0.6299 0.6762 0.2903 0.4393 0.8529 0.7180
#> [13,] 0.4655 0.6990 0.0842 0.7474 0.7956 0.7981 0.6715 0.6942 0.7440 0.8169
#> [14,] 0.3451 0.3777 0.0629 0.5213 0.2316 0.3335 0.4781 0.6116 0.6705 0.7375
#> [15,] 0.3960 0.3856 0.0164 0.5574 0.7309 0.8549 0.9425 0.8726 0.6673 0.4694
#> [16,] 0.9085 0.8668 0.0214 0.8892 0.9065 0.8522 0.7204 0.6200 0.6253 0.6848
#> [17,] 0.7673 1.0000 0.0254 0.8463 0.5509 0.4444 0.5169 0.4268 0.1802 0.0791
#> [18,] 0.5356 0.7124 0.0299 0.6291 0.4756 0.6015 0.7208 0.6234 0.5725 0.7523
#> [19,] 0.9493 0.9040 0.0080 0.9151 0.8828 0.8086 0.7180 0.6720 0.6447 0.6879
#> [20,] 0.8105 0.6828 0.0341 0.5572 0.4301 0.3339 0.2035 0.0798 0.0809 0.1525
#> [21,] 0.4307 0.4399 0.0449 0.3833 0.3032 0.3035 0.3197 0.2292 0.2131 0.2347
#> [22,] 0.7633 0.4434 0.0466 0.3822 0.4727 0.4007 0.3381 0.3172 0.2222 0.0733
#> [23,] 0.9349 0.9348 0.0289 1.0000 0.9308 0.8478 0.7605 0.7040 0.7539 0.7990
#> [24,] 1.0000 0.9806 0.0248 0.6969 0.4973 0.5020 0.5359 0.3842 0.1848 0.1149
#> [25,] 0.9050 0.8228 0.0051 0.6986 0.5831 0.4924 0.4563 0.5159 0.5670 0.5284
#> [26,] 0.7834 0.9619 0.0446 1.0000 0.8086 0.5558 0.5409 0.4988 0.3108 0.2897
#> [27,] 0.8664 0.7896 0.0344 0.6345 0.5351 0.4056 0.2563 0.2894 0.3588 0.4296
#> [28,] 0.9458 1.0000 0.0103 0.8425 0.5524 0.4795 0.5200 0.3968 0.1940 0.1519
#> [29,] 0.3444 0.4239 0.0833 0.4182 0.4393 0.1162 0.4336 0.6553 0.6172 0.4373
#> [30,] 0.5429 0.2177 0.1321 0.2149 0.5811 0.6323 0.2965 0.1873 0.2969 0.5163
#> [31,] 0.8457 0.8467 0.0137 0.7679 0.8055 0.6260 0.6545 0.8747 0.9885 0.9348
#> [32,] 0.5908 0.4564 0.1136 0.7334 0.1969 0.2790 0.6212 0.8681 0.8621 0.9380
#> [33,] 1.0000 0.8888 0.0221 0.6511 0.6083 0.4463 0.2948 0.1729 0.1488 0.0801
#> [34,] 0.9955 0.8576 0.0398 0.6069 0.3934 0.2464 0.1645 0.1140 0.0956 0.0080
#> [35,] 0.9769 0.8937 0.0380 0.7022 0.6500 0.5069 0.3903 0.3009 0.1565 0.0985
#> [36,] 0.8564 0.6790 0.0081 0.5587 0.4147 0.2946 0.2025 0.0688 0.1171 0.2157
#> [37,] 0.5843 0.4772 0.0953 0.5201 0.4241 0.1592 0.1668 0.0588 0.3967 0.7147
#> [38,] 0.9649 0.8747 0.0289 0.6257 0.2184 0.2945 0.3645 0.5012 0.7843 0.9361
#> [39,] 0.7360 0.4158 0.0453 0.2918 0.3280 0.3690 0.3450 0.2863 0.0864 0.3724
#> [40,] 0.7321 0.8534 0.0056 1.0000 0.8448 0.6354 0.6308 0.6211 0.6976 0.5868
#>          V37    V38    V39     V4    V40    V41    V42    V43    V44    V45
#>  [1,] 0.5408 0.8814 0.9857 0.0205 0.9167 0.6121 0.5006 0.3210 0.3202 0.4295
#>  [2,] 0.4577 0.3505 0.1845 0.0175 0.1890 0.1967 0.1041 0.0550 0.0492 0.0622
#>  [3,] 0.2413 0.2556 0.1892 0.0428 0.1940 0.3074 0.2785 0.0308 0.1238 0.1854
#>  [4,] 0.2369 0.1720 0.1878 0.0061 0.3250 0.2575 0.2423 0.2706 0.2323 0.1724
#>  [5,] 0.3039 0.4760 0.5756 0.0108 0.4254 0.5046 0.7179 0.6163 0.5663 0.5749
#>  [6,] 0.5060 0.3885 0.3762 0.0633 0.3738 0.2605 0.1591 0.1875 0.2267 0.1577
#>  [7,] 0.4072 0.3170 0.2863 0.0113 0.2634 0.0541 0.1874 0.3459 0.4646 0.4366
#>  [8,] 0.1644 0.3089 0.3648 0.0627 0.4441 0.3859 0.2813 0.1238 0.0953 0.1201
#>  [9,] 0.1058 0.0383 0.0528 0.0139 0.1291 0.2241 0.1915 0.1587 0.0942 0.0840
#> [10,] 0.1271 0.1912 0.3391 0.0768 0.3444 0.2369 0.1195 0.2665 0.2587 0.1393
#> [11,] 0.2463 0.2726 0.1680 0.0475 0.2792 0.2558 0.1740 0.2121 0.1099 0.0985
#> [12,] 0.4801 0.5856 0.4993 0.0518 0.2866 0.0601 0.1167 0.2737 0.2812 0.2078
#> [13,] 0.8912 1.0000 0.8753 0.0372 0.7061 0.6803 0.5898 0.4618 0.3639 0.1492
#> [14,] 0.7356 0.7792 0.6788 0.0608 0.5259 0.2762 0.1545 0.2019 0.2231 0.4221
#> [15,] 0.1546 0.1748 0.3607 0.0487 0.5208 0.5177 0.3702 0.2240 0.0816 0.0395
#> [16,] 0.7337 0.6281 0.5725 0.0227 0.6119 0.5597 0.4965 0.5027 0.5772 0.5907
#> [17,] 0.0535 0.1906 0.2561 0.0061 0.2153 0.2769 0.2841 0.1733 0.0815 0.0335
#> [18,] 0.8712 0.9252 0.9709 0.0297 0.9297 0.8995 0.7911 0.5600 0.2838 0.4407
#> [19,] 0.6241 0.4936 0.4144 0.0554 0.4240 0.4546 0.4392 0.4323 0.4921 0.4710
#> [20,] 0.2626 0.2456 0.1980 0.0247 0.2412 0.2409 0.1901 0.2077 0.1767 0.1119
#> [21,] 0.3201 0.4455 0.3655 0.1096 0.2715 0.1747 0.1781 0.2199 0.1056 0.0573
#> [22,] 0.2692 0.1888 0.0712 0.0440 0.1062 0.0694 0.0300 0.0893 0.1459 0.1348
#> [23,] 0.7673 0.5955 0.4731 0.0713 0.4840 0.4340 0.3954 0.4837 0.5379 0.4485
#> [24,] 0.1570 0.1311 0.1583 0.0237 0.2631 0.3103 0.4512 0.3785 0.1269 0.1459
#> [25,] 0.5144 0.3742 0.2282 0.0289 0.1193 0.1088 0.0431 0.1070 0.0583 0.0046
#> [26,] 0.2244 0.0960 0.2287 0.0551 0.3228 0.3454 0.3882 0.3240 0.0926 0.1173
#> [27,] 0.4773 0.4516 0.3765 0.0330 0.3051 0.1921 0.1184 0.1984 0.1570 0.0660
#> [28,] 0.2010 0.1736 0.1029 0.0566 0.2244 0.3717 0.4449 0.3939 0.2030 0.2010
#> [29,] 0.4118 0.3641 0.4572 0.0813 0.4367 0.2964 0.4312 0.4155 0.1824 0.1487
#> [30,] 0.6153 0.4283 0.5479 0.1408 0.6133 0.5017 0.2377 0.1957 0.1749 0.1304
#> [31,] 0.6960 0.5733 0.5872 0.0084 0.6663 0.5651 0.5247 0.3684 0.1997 0.1512
#> [32,] 0.8327 0.9480 0.6721 0.1203 0.4436 0.5163 0.3809 0.1557 0.1449 0.2662
#> [33,] 0.1770 0.1382 0.2404 0.0561 0.2046 0.1970 0.2778 0.1377 0.0685 0.0664
#> [34,] 0.0702 0.0936 0.0894 0.0570 0.1127 0.0873 0.1020 0.1964 0.2256 0.1814
#> [35,] 0.2200 0.2243 0.2736 0.0128 0.2152 0.2438 0.3154 0.2112 0.0991 0.0594
#> [36,] 0.2216 0.2776 0.2309 0.0230 0.1444 0.1513 0.1745 0.1756 0.1424 0.0908
#> [37,] 0.7319 0.3509 0.0589 0.0824 0.2690 0.4200 0.3874 0.2440 0.2000 0.2307
#> [38,] 0.8195 0.6207 0.4513 0.0195 0.3004 0.2674 0.2241 0.3141 0.3693 0.2986
#> [39,] 0.4649 0.3488 0.1817 0.0333 0.1142 0.1220 0.2621 0.4461 0.4726 0.3263
#> [40,] 0.4889 0.3683 0.2043 0.0064 0.1469 0.2220 0.1449 0.1490 0.1211 0.1144
#>          V46    V47    V48    V49     V5    V50    V51    V52    V53    V54
#>  [1,] 0.3654 0.2655 0.1576 0.0681 0.0205 0.0294 0.0241 0.0121 0.0036 0.0150
#>  [2,] 0.0505 0.0247 0.0219 0.0102 0.0362 0.0047 0.0019 0.0041 0.0074 0.0030
#>  [3,] 0.1753 0.1079 0.0728 0.0242 0.1117 0.0191 0.0159 0.0172 0.0191 0.0260
#>  [4,] 0.1457 0.1175 0.0868 0.0392 0.0420 0.0131 0.0092 0.0078 0.0071 0.0081
#>  [5,] 0.3593 0.2526 0.2299 0.1271 0.1070 0.0356 0.0367 0.0176 0.0035 0.0093
#>  [6,] 0.1211 0.0883 0.0850 0.0355 0.0596 0.0219 0.0086 0.0123 0.0060 0.0187
#>  [7,] 0.2581 0.1319 0.0505 0.0112 0.0497 0.0059 0.0041 0.0056 0.0104 0.0079
#>  [8,] 0.0825 0.0618 0.0141 0.0108 0.1158 0.0124 0.0104 0.0095 0.0151 0.0059
#>  [9,] 0.0670 0.0342 0.0469 0.0357 0.0357 0.0136 0.0082 0.0140 0.0044 0.0052
#> [10,] 0.1083 0.1383 0.1321 0.1069 0.1064 0.0325 0.0316 0.0057 0.0159 0.0085
#> [11,] 0.1271 0.1459 0.1164 0.0777 0.0647 0.0439 0.0061 0.0145 0.0128 0.0145
#> [12,] 0.0660 0.0491 0.0345 0.0172 0.1072 0.0287 0.0027 0.0208 0.0048 0.0199
#> [13,] 0.1216 0.1306 0.1198 0.0578 0.0458 0.0235 0.0135 0.0141 0.0190 0.0043
#> [14,] 0.3067 0.1329 0.1349 0.1057 0.0617 0.0499 0.0206 0.0073 0.0081 0.0303
#> [15,] 0.0785 0.1052 0.1034 0.0764 0.0519 0.0216 0.0167 0.0089 0.0051 0.0015
#> [16,] 0.4803 0.3877 0.2779 0.1427 0.0456 0.0424 0.0271 0.0200 0.0070 0.0070
#> [17,] 0.0933 0.1018 0.0309 0.0208 0.0352 0.0318 0.0132 0.0118 0.0120 0.0051
#> [18,] 0.5507 0.4331 0.2905 0.1981 0.0652 0.0779 0.0396 0.0173 0.0149 0.0115
#> [19,] 0.3196 0.2241 0.1806 0.0990 0.0883 0.0251 0.0129 0.0095 0.0126 0.0069
#> [20,] 0.0779 0.1344 0.0960 0.0598 0.0822 0.0330 0.0197 0.0189 0.0204 0.0085
#> [21,] 0.0307 0.0237 0.0470 0.0102 0.1913 0.0057 0.0031 0.0163 0.0099 0.0084
#> [22,] 0.0391 0.0546 0.0469 0.0201 0.0657 0.0095 0.0155 0.0091 0.0151 0.0080
#> [23,] 0.2674 0.1541 0.1359 0.0941 0.1075 0.0261 0.0079 0.0164 0.0120 0.0113
#> [24,] 0.1092 0.1485 0.1385 0.0716 0.0224 0.0176 0.0199 0.0096 0.0103 0.0093
#> [25,] 0.0473 0.0408 0.0290 0.0192 0.0561 0.0094 0.0025 0.0037 0.0084 0.0102
#> [26,] 0.0566 0.0766 0.0969 0.0588 0.0597 0.0050 0.0118 0.0146 0.0040 0.0114
#> [27,] 0.1294 0.0797 0.0052 0.0233 0.0397 0.0152 0.0125 0.0054 0.0057 0.0137
#> [28,] 0.2187 0.1840 0.1477 0.0971 0.0759 0.0224 0.0151 0.0105 0.0024 0.0018
#> [29,] 0.0138 0.1164 0.2052 0.1069 0.0165 0.0199 0.0208 0.0176 0.0197 0.0210
#> [30,] 0.0597 0.1124 0.1047 0.0507 0.1674 0.0159 0.0195 0.0201 0.0248 0.0131
#> [31,] 0.0508 0.0931 0.0982 0.0524 0.0305 0.0188 0.0100 0.0038 0.0187 0.0156
#> [32,] 0.1806 0.1699 0.2559 0.1129 0.0403 0.0201 0.0480 0.0234 0.0175 0.0352
#> [33,] 0.1665 0.1807 0.1245 0.0516 0.0936 0.0044 0.0185 0.0072 0.0055 0.0074
#> [34,] 0.2012 0.1688 0.1037 0.0501 0.0529 0.0136 0.0130 0.0120 0.0039 0.0053
#> [35,] 0.1940 0.1937 0.1082 0.0336 0.0537 0.0177 0.0209 0.0134 0.0094 0.0047
#> [36,] 0.0138 0.0469 0.0480 0.0159 0.0586 0.0045 0.0015 0.0052 0.0038 0.0079
#> [37,] 0.1886 0.1960 0.1701 0.1366 0.0249 0.0398 0.0143 0.0093 0.0033 0.0113
#> [38,] 0.2226 0.0849 0.0359 0.0289 0.0515 0.0122 0.0045 0.0108 0.0075 0.0089
#> [39,] 0.1423 0.0390 0.0406 0.0311 0.0185 0.0086 0.0154 0.0048 0.0025 0.0087
#> [40,] 0.0791 0.0365 0.0152 0.0085 0.0260 0.0120 0.0022 0.0069 0.0064 0.0129
#>          V55    V56    V57    V58    V59     V6    V60     V7     V8     V9
#>  [1,] 0.0085 0.0073 0.0050 0.0044 0.0040 0.0368 0.0117 0.1098 0.1276 0.0598
#>  [2,] 0.0050 0.0048 0.0017 0.0041 0.0086 0.0696 0.0058 0.0873 0.0616 0.1252
#>  [3,] 0.0140 0.0125 0.0116 0.0093 0.0012 0.1651 0.0036 0.1597 0.2116 0.3295
#>  [4,] 0.0034 0.0064 0.0037 0.0036 0.0012 0.0865 0.0037 0.1182 0.0999 0.1976
#>  [5,] 0.0121 0.0075 0.0056 0.0021 0.0043 0.0973 0.0017 0.0961 0.1323 0.2462
#>  [6,] 0.0111 0.0126 0.0081 0.0155 0.0160 0.0808 0.0085 0.2090 0.3465 0.5276
#>  [7,] 0.0014 0.0054 0.0015 0.0006 0.0081 0.0998 0.0043 0.1326 0.1117 0.2984
#>  [8,] 0.0015 0.0053 0.0016 0.0042 0.0053 0.1482 0.0074 0.2054 0.1605 0.2532
#>  [9,] 0.0073 0.0021 0.0047 0.0024 0.0009 0.0785 0.0017 0.0906 0.0908 0.1151
#> [10,] 0.0372 0.0101 0.0127 0.0288 0.0129 0.1680 0.0023 0.3016 0.3460 0.3314
#> [11,] 0.0058 0.0049 0.0065 0.0093 0.0059 0.0591 0.0022 0.0753 0.0098 0.0684
#> [12,] 0.0126 0.0022 0.0037 0.0034 0.0114 0.2587 0.0077 0.2304 0.2067 0.3416
#> [13,] 0.0036 0.0026 0.0024 0.0162 0.0109 0.0771 0.0079 0.0771 0.1130 0.2353
#> [14,] 0.0190 0.0212 0.0126 0.0201 0.0210 0.1207 0.0041 0.0944 0.4223 0.5744
#> [15,] 0.0075 0.0058 0.0016 0.0070 0.0074 0.0849 0.0038 0.0812 0.1833 0.2228
#> [16,] 0.0086 0.0089 0.0074 0.0042 0.0055 0.0665 0.0021 0.0939 0.0972 0.2535
#> [17,] 0.0070 0.0015 0.0035 0.0008 0.0044 0.0701 0.0077 0.1263 0.1080 0.1523
#> [18,] 0.0202 0.0139 0.0029 0.0160 0.0106 0.1077 0.0134 0.2363 0.2385 0.0075
#> [19,] 0.0039 0.0068 0.0060 0.0045 0.0002 0.1278 0.0029 0.1674 0.1373 0.2922
#> [20,] 0.0043 0.0092 0.0138 0.0094 0.0105 0.1256 0.0093 0.1323 0.1584 0.2017
#> [21,] 0.0270 0.0277 0.0097 0.0054 0.0148 0.0924 0.0092 0.0761 0.1092 0.0757
#> [22,] 0.0018 0.0078 0.0045 0.0026 0.0036 0.0742 0.0024 0.1380 0.1099 0.1384
#> [23,] 0.0021 0.0097 0.0072 0.0060 0.0017 0.1019 0.0036 0.1606 0.2119 0.3061
#> [24,] 0.0025 0.0044 0.0021 0.0069 0.0060 0.0845 0.0018 0.1488 0.1224 0.1569
#> [25,] 0.0096 0.0024 0.0037 0.0028 0.0030 0.0929 0.0030 0.1031 0.0883 0.1596
#> [26,] 0.0032 0.0062 0.0101 0.0068 0.0053 0.1416 0.0087 0.0956 0.0802 0.1618
#> [27,] 0.0109 0.0035 0.0056 0.0105 0.0082 0.0443 0.0036 0.0684 0.0903 0.1739
#> [28,] 0.0057 0.0092 0.0009 0.0086 0.0110 0.0679 0.0052 0.0970 0.1473 0.2164
#> [29,] 0.0141 0.0049 0.0027 0.0162 0.0059 0.0277 0.0021 0.0569 0.2057 0.3887
#> [30,] 0.0070 0.0138 0.0092 0.0143 0.0036 0.1710 0.0103 0.0731 0.1401 0.2083
#> [31,] 0.0068 0.0097 0.0073 0.0081 0.0086 0.0438 0.0095 0.0341 0.0780 0.0844
#> [32,] 0.0158 0.0326 0.0201 0.0168 0.0245 0.1227 0.0154 0.2495 0.4566 0.6587
#> [33,] 0.0068 0.0084 0.0037 0.0024 0.0034 0.1146 0.0007 0.0706 0.0996 0.1673
#> [34,] 0.0062 0.0046 0.0045 0.0022 0.0005 0.1091 0.0031 0.1709 0.1684 0.1865
#> [35,] 0.0045 0.0042 0.0028 0.0036 0.0013 0.0874 0.0016 0.1021 0.0852 0.1136
#> [36,] 0.0114 0.0050 0.0030 0.0064 0.0058 0.0682 0.0030 0.0993 0.0717 0.0576
#> [37,] 0.0030 0.0057 0.0090 0.0057 0.0068 0.0488 0.0024 0.1424 0.1972 0.1873
#> [38,] 0.0036 0.0029 0.0013 0.0010 0.0032 0.0817 0.0047 0.1005 0.0124 0.1168
#> [39,] 0.0072 0.0095 0.0086 0.0085 0.0040 0.1260 0.0051 0.1015 0.1918 0.3362
#> [40,] 0.0114 0.0054 0.0089 0.0050 0.0058 0.0458 0.0025 0.0470 0.0057 0.0425
#> 
#> $post[[2]]
#>              [,1]
#>  [1,] 0.009629404
#>  [2,] 0.004133900
#>  [3,] 0.001793202
#>  [4,] 0.005710873
#>  [5,] 0.002427418
#>  [6,] 0.002033733
#>  [7,] 0.003206753
#>  [8,] 0.008239660
#>  [9,] 0.021888222
#> [10,] 0.002608866
#> [11,] 0.006746722
#> [12,] 0.002408144
#> [13,] 0.004319664
#> [14,] 0.008173883
#> [15,] 0.002076677
#> [16,] 0.003116087
#> [17,] 0.010247577
#> [18,] 0.008343216
#> [19,] 0.002626831
#> [20,] 0.002703366
#> [21,] 0.004165106
#> [22,] 0.002319298
#> [23,] 0.003010765
#> [24,] 0.007383227
#> [25,] 0.003075007
#> [26,] 0.003403175
#> [27,] 0.002921847
#> [28,] 0.007253703
#> [29,] 0.005094232
#> [30,] 0.005305565
#> [31,] 0.008934606
#> [32,] 0.005204809
#> [33,] 0.008081202
#> [34,] 0.004509965
#> [35,] 0.007267753
#> [36,] 0.007127388
#> [37,] 0.003950590
#> [38,] 0.001881717
#> [39,] 0.003081980
#> [40,] 0.005748075
#> 
#> $post[[3]]
#>            [,1]      [,2]
#>  [1,] 0.5437903 0.4562097
#>  [2,] 0.5437049 0.4562951
#>  [3,] 0.5436686 0.4563314
#>  [4,] 0.5437294 0.4562706
#>  [5,] 0.5436784 0.4563216
#>  [6,] 0.5436723 0.4563277
#>  [7,] 0.5436905 0.4563095
#>  [8,] 0.5437687 0.4562313
#>  [9,] 0.5439806 0.4560194
#> [10,] 0.5436812 0.4563188
#> [11,] 0.5437455 0.4562545
#> [12,] 0.5436781 0.4563219
#> [13,] 0.5437078 0.4562922
#> [14,] 0.5437677 0.4562323
#> [15,] 0.5436730 0.4563270
#> [16,] 0.5436891 0.4563109
#> [17,] 0.5437999 0.4562001
#> [18,] 0.5437703 0.4562297
#> [19,] 0.5436815 0.4563185
#> [20,] 0.5436827 0.4563173
#> [21,] 0.5437054 0.4562946
#> [22,] 0.5436767 0.4563233
#> [23,] 0.5436875 0.4563125
#> [24,] 0.5437554 0.4562446
#> [25,] 0.5436885 0.4563115
#> [26,] 0.5436936 0.4563064
#> [27,] 0.5436861 0.4563139
#> [28,] 0.5437534 0.4562466
#> [29,] 0.5437198 0.4562802
#> [30,] 0.5437231 0.4562769
#> [31,] 0.5437795 0.4562205
#> [32,] 0.5437215 0.4562785
#> [33,] 0.5437662 0.4562338
#> [34,] 0.5437108 0.4562892
#> [35,] 0.5437536 0.4562464
#> [36,] 0.5437514 0.4562486
#> [37,] 0.5437021 0.4562979
#> [38,] 0.5436699 0.4563301
#> [39,] 0.5436886 0.4563114
#> [40,] 0.5437300 0.4562700
#> 
#> 
#> $pre
#> $pre[[1]]
#> NULL
#> 
#> $pre[[2]]
#>            [,1]
#>  [1,] -4.633258
#>  [2,] -5.484392
#>  [3,] -6.321957
#>  [4,] -5.159656
#>  [5,] -6.018497
#>  [6,] -6.195847
#>  [7,] -5.739284
#>  [8,] -4.790522
#>  [9,] -3.799675
#> [10,] -5.946227
#> [11,] -4.991929
#> [12,] -6.026488
#> [13,] -5.440249
#> [14,] -4.798604
#> [15,] -6.174907
#> [16,] -5.768056
#> [17,] -4.570414
#> [18,] -4.777928
#> [19,] -5.939347
#> [20,] -5.910551
#> [21,] -5.476840
#> [22,] -6.064169
#> [23,] -5.802546
#> [24,] -4.901134
#> [25,] -5.781368
#> [26,] -5.679638
#> [27,] -5.832613
#> [28,] -4.918963
#> [29,] -5.274539
#> [30,] -5.233679
#> [31,] -4.708848
#> [32,] -5.252954
#> [33,] -4.810101
#> [34,] -5.396946
#> [35,] -4.917014
#> [36,] -4.936658
#> [37,] -5.529932
#> [38,] -6.273687
#> [39,] -5.779096
#> [40,] -5.153126
#> 
#> $pre[[3]]
#>            [,1]        [,2]
#>  [1,] 0.1431005 -0.03251047
#>  [2,] 0.1431004 -0.03216653
#>  [3,] 0.1431004 -0.03202004
#>  [4,] 0.1431004 -0.03226523
#>  [5,] 0.1431004 -0.03205973
#>  [6,] 0.1431004 -0.03203509
#>  [7,] 0.1431004 -0.03210851
#>  [8,] 0.1431005 -0.03242349
#>  [9,] 0.1431006 -0.03327770
#> [10,] 0.1431004 -0.03207109
#> [11,] 0.1431004 -0.03233006
#> [12,] 0.1431004 -0.03205853
#> [13,] 0.1431004 -0.03217816
#> [14,] 0.1431005 -0.03241938
#> [15,] 0.1431004 -0.03203778
#> [16,] 0.1431004 -0.03210283
#> [17,] 0.1431005 -0.03254916
#> [18,] 0.1431005 -0.03242998
#> [19,] 0.1431004 -0.03207221
#> [20,] 0.1431004 -0.03207700
#> [21,] 0.1431004 -0.03216849
#> [22,] 0.1431004 -0.03205297
#> [23,] 0.1431004 -0.03209624
#> [24,] 0.1431004 -0.03236989
#> [25,] 0.1431004 -0.03210026
#> [26,] 0.1431004 -0.03212080
#> [27,] 0.1431004 -0.03209068
#> [28,] 0.1431004 -0.03236179
#> [29,] 0.1431004 -0.03222664
#> [30,] 0.1431004 -0.03223986
#> [31,] 0.1431005 -0.03246699
#> [32,] 0.1431004 -0.03223356
#> [33,] 0.1431005 -0.03241358
#> [34,] 0.1431004 -0.03219007
#> [35,] 0.1431004 -0.03236267
#> [36,] 0.1431004 -0.03235388
#> [37,] 0.1431004 -0.03215506
#> [38,] 0.1431004 -0.03202558
#> [39,] 0.1431004 -0.03210070
#> [40,] 0.1431004 -0.03226756
#> 
#> 
#> $e
#>             [,1]       [,2]
#>  [1,] -0.5437903  0.5437903
#>  [2,] -0.5437049  0.5437049
#>  [3,]  0.4563314 -0.4563314
#>  [4,]  0.4562706 -0.4562706
#>  [5,]  0.4563216 -0.4563216
#>  [6,]  0.4563277 -0.4563277
#>  [7,]  0.4563095 -0.4563095
#>  [8,]  0.4562313 -0.4562313
#>  [9,] -0.5439806  0.5439806
#> [10,]  0.4563188 -0.4563188
#> [11,] -0.5437455  0.5437455
#> [12,] -0.5436781  0.5436781
#> [13,] -0.5437078  0.5437078
#> [14,]  0.4562323 -0.4562323
#> [15,]  0.4563270 -0.4563270
#> [16,]  0.4563109 -0.4563109
#> [17,] -0.5437999  0.5437999
#> [18,] -0.5437703  0.5437703
#> [19,]  0.4563185 -0.4563185
#> [20,]  0.4563173 -0.4563173
#> [21,]  0.4562946 -0.4562946
#> [22,] -0.5436767  0.5436767
#> [23,]  0.4563125 -0.4563125
#> [24,]  0.4562446 -0.4562446
#> [25,] -0.5436885  0.5436885
#> [26,]  0.4563064 -0.4563064
#> [27,]  0.4563139 -0.4563139
#> [28,]  0.4562466 -0.4562466
#> [29,]  0.4562802 -0.4562802
#> [30,] -0.5437231  0.5437231
#> [31,] -0.5437795  0.5437795
#> [32,]  0.4562785 -0.4562785
#> [33,]  0.4562338 -0.4562338
#> [34,]  0.4562892 -0.4562892
#> [35,]  0.4562464 -0.4562464
#> [36,] -0.5437514  0.5437514
#> [37,] -0.5437021  0.5437021
#> [38,]  0.4563301 -0.4563301
#> [39,]  0.4563114 -0.4563114
#> [40,] -0.5437300  0.5437300
#> 
#> $L
#> [1] 0.6946099 0.6872916 0.6810717 0.7097038 0.6945594 0.6751063
#> 


# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()
#> classif.ce 
#>  0.5217391 
```
